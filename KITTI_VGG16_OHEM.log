+ echo Logging output to experiments/logs/faster_rcnn_alt_opt_VGG16_.txt.2016-10-27_18-24-32
Logging output to experiments/logs/faster_rcnn_alt_opt_VGG16_.txt.2016-10-27_18-24-32
+ ./tools/train_faster_rcnn_alt_opt.py --gpu 0 --net_name VGG16 --weights data/imagenet_models/VGG16.v2.caffemodel --imdb KakouTrain --cfg experiments/cfgs/faster_rcnn_alt_opt.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_alt_opt.yml', gpu_id=0, imdb_name='KakouTrain', net_name='VGG16', pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', set_cfgs=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Stage 2 Fast R-CNN, init from stage 2 RPN R-CNN model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Init model: /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_fast_rcnn_stage2_iter_30000.caffemodel
RPN proposals: /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_rpn_stage2_iter_80000_proposals.pkl
Using config:
{'ASPECT_GROUPING': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_alt_opt',
 'GPU_ID': 0,
 'PIXEL_MEANS': array([[[ 130.9801,  130.9465,  130.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/bsl/KITTI-detection',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1250,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 10,
          'RPN_NMS_THRESH': 0.5,
          'RPN_POST_NMS_TOP_N': 2000,
          'RPN_PRE_NMS_TOP_N': 12000,
          'SCALES': [382],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1250,
           'OHEM_USE_NMS': False,
           'PROPOSAL_METHOD': 'rpn',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 10,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.5,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [370],
           'SNAPSHOT_INFIX': 'stage2',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_OHEM': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `KakouTrain` for training
Set proposal method: rpn
Appending horizontally-flipped training examples...
KakouTrain gt roidb loaded from /home/bsl/KITTI-detection/data/cache/KakouTrain_gt_roidb.pkl
loading /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_rpn_stage2_iter_80000_proposals.pkl
/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2652: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.
  VisibleDeprecationWarning)
done
Preparing training data...
done
Output will be saved to `/home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain`
Computing bounding-box regression targets...
bbox target means:
[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [ -2.32409565e-10   6.45684114e-04   2.82250806e-02  -3.49971352e-03]
 [  3.12147374e-09  -2.50666588e-03  -3.27800808e-02   5.59033272e-02]
 [ -3.15291779e-09  -7.97456560e-03  -1.43337056e-02   4.04762552e-02]
 [ -1.79077330e-09  -1.34953884e-02   1.34688809e-03   3.93996667e-02]
 [ -5.66938619e-10  -8.93234437e-03   1.29104820e-02   2.76559425e-02]
 [  2.07748980e-09  -8.20524232e-03   1.18681347e-02   3.45776173e-02]
 [  3.38920831e-09  -4.60229637e-03  -8.20840930e-03   2.16716349e-02]]
[  4.06447509e-10  -6.43868840e-03  -1.38801483e-04   3.08835329e-02]
bbox target stdevs:
[[ 0.          0.          0.          0.        ]
 [ 0.1102029   0.10130374  0.19069357  0.16241562]
 [ 0.10041364  0.08721207  0.18642719  0.17170662]
 [ 0.10533605  0.09921929  0.2073627   0.17285659]
 [ 0.10849817  0.10764885  0.19128171  0.17037229]
 [ 0.10756746  0.1058412   0.19697517  0.17181396]
 [ 0.11570642  0.11005835  0.21247771  0.18005513]
 [ 0.10655628  0.10714317  0.20075945  0.17894817]]
[ 0.10775442  0.10263238  0.19799679  0.17259549]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1027 18:24:39.850126  5972 solver.cpp:54] Initializing solver from parameters: 
train_net: "models/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_ohem_train.pt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 0
snapshot_prefix: "vgg16_fast_rcnn"
average_loss: 100
I1027 18:24:39.850152  5972 solver.cpp:86] Creating training net from train_net file: models/VGG16/faster_rcnn_alt_opt/stage2_fast_rcnn_ohem_train.pt
I1027 18:24:39.851002  5972 net.cpp:50] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 8"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "roi_pool5_readonly"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5_readonly"
  propagate_down: false
  propagate_down: false
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6_readonly"
  type: "InnerProduct"
  bottom: "pool5_readonly"
  top: "fc6_readonly"
  param {
    name: "fc6_w"
  }
  param {
    name: "fc6_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6_readonly"
  type: "ReLU"
  bottom: "fc6_readonly"
  top: "fc6_readonly"
  propagate_down: false
}
layer {
  name: "drop6_readonly"
  type: "Dropout"
  bottom: "fc6_readonly"
  top: "fc6_readonly"
  propagate_down: false
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_readonly"
  type: "InnerProduct"
  bottom: "fc6_readonly"
  top: "fc7_readonly"
  param {
    name: "fc7_w"
  }
  param {
    name: "fc7_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7_readonly"
  type: "ReLU"
  bottom: "fc7_readonly"
  top: "fc7_readonly"
  propagate_down: false
}
layer {
  name: "drop7_readonly"
  type: "Dropout"
  bottom: "fc7_readonly"
  top: "fc7_readonly"
  propagate_down: false
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score_readonly"
  type: "InnerProduct"
  bottom: "fc7_readonly"
  top: "cls_score_readonly"
  param {
    name: "cls_score_w"
  }
  param {
    name: "cls_score_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred_readonly"
  type: "InnerProduct"
  bottom: "fc7_readonly"
  top: "bbox_pred_readonly"
  param {
    name: "bbox_pred_w"
  }
  param {
    name: "bbox_pred_b"
  }
  propagate_down: false
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_prob_readonly"
  type: "Softmax"
  bottom: "cls_score_readonly"
  top: "cls_prob_readonly"
  propagate_down: false
}
layer {
  name: "hard_roi_mining"
  type: "Python"
  bottom: "cls_prob_readonly"
  bottom: "bbox_pred_readonly"
  bottom: "rois"
  bottom: "labels"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "rois_hard"
  top: "labels_hard"
  top: "bbox_targets_hard"
  top: "bbox_inside_weights_hard"
  top: "bbox_outside_weights_hard"
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  propagate_down: false
  python_param {
    module: "roi_data_layer.layer"
    layer: "OHEMDataLayer"
    param_str: "\'num_classes\': 8"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois_hard"
  top: "pool5"
  propagate_down: true
  propagate_down: false
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    name: "cls_score_w"
    lr_mult: 1
  }
  param {
    name: "cls_score_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    name: "bbox_pred_w"
    lr_mult: 1
  }
  param {
    name: "bbox_pred_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 32
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels_hard"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets_hard"
  bottom: "bbox_inside_weights_hard"
  bottom: "bbox_outside_weights_hard"
  top: "loss_bbox"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  propagate_down: false
  propagate_down: false
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "silence_rpn_cls_score"
  type: "Silence"
  bottom: "rpn_cls_score"
}
layer {
  name: "silence_rpn_bbox_pred"
  type: "Silence"
  bottom: "rpn_bbox_pred"
}
I1027 18:24:39.851194  5972 layer_factory.hpp:76] Creating layer data
I1027 18:24:39.851950  5972 net.cpp:110] Creating Layer data
I1027 18:24:39.851958  5972 net.cpp:433] data -> data
I1027 18:24:39.851965  5972 net.cpp:433] data -> rois
I1027 18:24:39.851969  5972 net.cpp:433] data -> labels
I1027 18:24:39.851974  5972 net.cpp:433] data -> bbox_targets
I1027 18:24:39.851977  5972 net.cpp:433] data -> bbox_inside_weights
I1027 18:24:39.851981  5972 net.cpp:433] data -> bbox_outside_weights
RoiDataLayer: name_to_top: {'bbox_inside_weights': 4, 'labels': 2, 'rois': 1, 'bbox_targets': 3, 'bbox_outside_weights': 5, 'data': 0}
I1027 18:24:39.852366  5972 net.cpp:155] Setting up data
I1027 18:24:39.852375  5972 net.cpp:163] Top shape: 1 3 370 1250 (1387500)
I1027 18:24:39.852376  5972 net.cpp:163] Top shape: 1 5 (5)
I1027 18:24:39.852380  5972 net.cpp:163] Top shape: 1 (1)
I1027 18:24:39.852381  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:39.852383  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:39.852385  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:39.852388  5972 layer_factory.hpp:76] Creating layer rois_data_1_split
I1027 18:24:39.852396  5972 net.cpp:110] Creating Layer rois_data_1_split
I1027 18:24:39.852397  5972 net.cpp:477] rois_data_1_split <- rois
I1027 18:24:39.852401  5972 net.cpp:433] rois_data_1_split -> rois_data_1_split_0
I1027 18:24:39.852406  5972 net.cpp:433] rois_data_1_split -> rois_data_1_split_1
I1027 18:24:39.852413  5972 net.cpp:155] Setting up rois_data_1_split
I1027 18:24:39.852416  5972 net.cpp:163] Top shape: 1 5 (5)
I1027 18:24:39.852418  5972 net.cpp:163] Top shape: 1 5 (5)
I1027 18:24:39.852421  5972 layer_factory.hpp:76] Creating layer conv1_1
I1027 18:24:39.852426  5972 net.cpp:110] Creating Layer conv1_1
I1027 18:24:39.852427  5972 net.cpp:477] conv1_1 <- data
I1027 18:24:39.852430  5972 net.cpp:433] conv1_1 -> conv1_1
I1027 18:24:39.857055  5972 net.cpp:155] Setting up conv1_1
I1027 18:24:39.857074  5972 net.cpp:163] Top shape: 1 64 370 1250 (29600000)
I1027 18:24:39.857084  5972 layer_factory.hpp:76] Creating layer relu1_1
I1027 18:24:39.857091  5972 net.cpp:110] Creating Layer relu1_1
I1027 18:24:39.857095  5972 net.cpp:477] relu1_1 <- conv1_1
I1027 18:24:39.857108  5972 net.cpp:419] relu1_1 -> conv1_1 (in-place)
I1027 18:24:39.857120  5972 net.cpp:155] Setting up relu1_1
I1027 18:24:39.857122  5972 net.cpp:163] Top shape: 1 64 370 1250 (29600000)
I1027 18:24:39.857125  5972 layer_factory.hpp:76] Creating layer conv1_2
I1027 18:24:39.857130  5972 net.cpp:110] Creating Layer conv1_2
I1027 18:24:39.857131  5972 net.cpp:477] conv1_2 <- conv1_1
I1027 18:24:39.857136  5972 net.cpp:433] conv1_2 -> conv1_2
I1027 18:24:39.857933  5972 net.cpp:155] Setting up conv1_2
I1027 18:24:39.857944  5972 net.cpp:163] Top shape: 1 64 370 1250 (29600000)
I1027 18:24:39.857951  5972 layer_factory.hpp:76] Creating layer relu1_2
I1027 18:24:39.857957  5972 net.cpp:110] Creating Layer relu1_2
I1027 18:24:39.857959  5972 net.cpp:477] relu1_2 <- conv1_2
I1027 18:24:39.857972  5972 net.cpp:419] relu1_2 -> conv1_2 (in-place)
I1027 18:24:39.857977  5972 net.cpp:155] Setting up relu1_2
I1027 18:24:39.857980  5972 net.cpp:163] Top shape: 1 64 370 1250 (29600000)
I1027 18:24:39.857982  5972 layer_factory.hpp:76] Creating layer pool1
I1027 18:24:39.857986  5972 net.cpp:110] Creating Layer pool1
I1027 18:24:39.857988  5972 net.cpp:477] pool1 <- conv1_2
I1027 18:24:39.857991  5972 net.cpp:433] pool1 -> pool1
I1027 18:24:39.857997  5972 net.cpp:155] Setting up pool1
I1027 18:24:39.858000  5972 net.cpp:163] Top shape: 1 64 185 625 (7400000)
I1027 18:24:39.858002  5972 layer_factory.hpp:76] Creating layer conv2_1
I1027 18:24:39.858006  5972 net.cpp:110] Creating Layer conv2_1
I1027 18:24:39.858008  5972 net.cpp:477] conv2_1 <- pool1
I1027 18:24:39.858011  5972 net.cpp:433] conv2_1 -> conv2_1
I1027 18:24:39.858353  5972 net.cpp:155] Setting up conv2_1
I1027 18:24:39.858361  5972 net.cpp:163] Top shape: 1 128 185 625 (14800000)
I1027 18:24:39.858367  5972 layer_factory.hpp:76] Creating layer relu2_1
I1027 18:24:39.858372  5972 net.cpp:110] Creating Layer relu2_1
I1027 18:24:39.858374  5972 net.cpp:477] relu2_1 <- conv2_1
I1027 18:24:39.858378  5972 net.cpp:419] relu2_1 -> conv2_1 (in-place)
I1027 18:24:39.858392  5972 net.cpp:155] Setting up relu2_1
I1027 18:24:39.858394  5972 net.cpp:163] Top shape: 1 128 185 625 (14800000)
I1027 18:24:39.858397  5972 layer_factory.hpp:76] Creating layer conv2_2
I1027 18:24:39.858400  5972 net.cpp:110] Creating Layer conv2_2
I1027 18:24:39.858402  5972 net.cpp:477] conv2_2 <- conv2_1
I1027 18:24:39.858405  5972 net.cpp:433] conv2_2 -> conv2_2
I1027 18:24:39.858992  5972 net.cpp:155] Setting up conv2_2
I1027 18:24:39.859001  5972 net.cpp:163] Top shape: 1 128 185 625 (14800000)
I1027 18:24:39.859006  5972 layer_factory.hpp:76] Creating layer relu2_2
I1027 18:24:39.859010  5972 net.cpp:110] Creating Layer relu2_2
I1027 18:24:39.859012  5972 net.cpp:477] relu2_2 <- conv2_2
I1027 18:24:39.859016  5972 net.cpp:419] relu2_2 -> conv2_2 (in-place)
I1027 18:24:39.859019  5972 net.cpp:155] Setting up relu2_2
I1027 18:24:39.859022  5972 net.cpp:163] Top shape: 1 128 185 625 (14800000)
I1027 18:24:39.859035  5972 layer_factory.hpp:76] Creating layer pool2
I1027 18:24:39.859037  5972 net.cpp:110] Creating Layer pool2
I1027 18:24:39.859040  5972 net.cpp:477] pool2 <- conv2_2
I1027 18:24:39.859042  5972 net.cpp:433] pool2 -> pool2
I1027 18:24:39.859047  5972 net.cpp:155] Setting up pool2
I1027 18:24:39.859050  5972 net.cpp:163] Top shape: 1 128 93 313 (3725952)
I1027 18:24:39.859052  5972 layer_factory.hpp:76] Creating layer conv3_1
I1027 18:24:39.859056  5972 net.cpp:110] Creating Layer conv3_1
I1027 18:24:39.859058  5972 net.cpp:477] conv3_1 <- pool2
I1027 18:24:39.859061  5972 net.cpp:433] conv3_1 -> conv3_1
I1027 18:24:39.859484  5972 net.cpp:155] Setting up conv3_1
I1027 18:24:39.859503  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.859510  5972 layer_factory.hpp:76] Creating layer relu3_1
I1027 18:24:39.859524  5972 net.cpp:110] Creating Layer relu3_1
I1027 18:24:39.859526  5972 net.cpp:477] relu3_1 <- conv3_1
I1027 18:24:39.859529  5972 net.cpp:419] relu3_1 -> conv3_1 (in-place)
I1027 18:24:39.859544  5972 net.cpp:155] Setting up relu3_1
I1027 18:24:39.859545  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.859547  5972 layer_factory.hpp:76] Creating layer conv3_2
I1027 18:24:39.859551  5972 net.cpp:110] Creating Layer conv3_2
I1027 18:24:39.859553  5972 net.cpp:477] conv3_2 <- conv3_1
I1027 18:24:39.859556  5972 net.cpp:433] conv3_2 -> conv3_2
I1027 18:24:39.860257  5972 net.cpp:155] Setting up conv3_2
I1027 18:24:39.860265  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.860270  5972 layer_factory.hpp:76] Creating layer relu3_2
I1027 18:24:39.860273  5972 net.cpp:110] Creating Layer relu3_2
I1027 18:24:39.860275  5972 net.cpp:477] relu3_2 <- conv3_2
I1027 18:24:39.860280  5972 net.cpp:419] relu3_2 -> conv3_2 (in-place)
I1027 18:24:39.860282  5972 net.cpp:155] Setting up relu3_2
I1027 18:24:39.860294  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.860296  5972 layer_factory.hpp:76] Creating layer conv3_3
I1027 18:24:39.860302  5972 net.cpp:110] Creating Layer conv3_3
I1027 18:24:39.860306  5972 net.cpp:477] conv3_3 <- conv3_2
I1027 18:24:39.860308  5972 net.cpp:433] conv3_3 -> conv3_3
I1027 18:24:39.861011  5972 net.cpp:155] Setting up conv3_3
I1027 18:24:39.861021  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.861024  5972 layer_factory.hpp:76] Creating layer relu3_3
I1027 18:24:39.861028  5972 net.cpp:110] Creating Layer relu3_3
I1027 18:24:39.861030  5972 net.cpp:477] relu3_3 <- conv3_3
I1027 18:24:39.861033  5972 net.cpp:419] relu3_3 -> conv3_3 (in-place)
I1027 18:24:39.861038  5972 net.cpp:155] Setting up relu3_3
I1027 18:24:39.861050  5972 net.cpp:163] Top shape: 1 256 93 313 (7451904)
I1027 18:24:39.861052  5972 layer_factory.hpp:76] Creating layer pool3
I1027 18:24:39.861057  5972 net.cpp:110] Creating Layer pool3
I1027 18:24:39.861058  5972 net.cpp:477] pool3 <- conv3_3
I1027 18:24:39.861062  5972 net.cpp:433] pool3 -> pool3
I1027 18:24:39.861066  5972 net.cpp:155] Setting up pool3
I1027 18:24:39.861069  5972 net.cpp:163] Top shape: 1 256 47 157 (1889024)
I1027 18:24:39.861071  5972 layer_factory.hpp:76] Creating layer conv4_1
I1027 18:24:39.861075  5972 net.cpp:110] Creating Layer conv4_1
I1027 18:24:39.861078  5972 net.cpp:477] conv4_1 <- pool3
I1027 18:24:39.861080  5972 net.cpp:433] conv4_1 -> conv4_1
I1027 18:24:39.862874  5972 net.cpp:155] Setting up conv4_1
I1027 18:24:39.862895  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.862900  5972 layer_factory.hpp:76] Creating layer relu4_1
I1027 18:24:39.862908  5972 net.cpp:110] Creating Layer relu4_1
I1027 18:24:39.862915  5972 net.cpp:477] relu4_1 <- conv4_1
I1027 18:24:39.862929  5972 net.cpp:419] relu4_1 -> conv4_1 (in-place)
I1027 18:24:39.862936  5972 net.cpp:155] Setting up relu4_1
I1027 18:24:39.862939  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.862941  5972 layer_factory.hpp:76] Creating layer conv4_2
I1027 18:24:39.862946  5972 net.cpp:110] Creating Layer conv4_2
I1027 18:24:39.862947  5972 net.cpp:477] conv4_2 <- conv4_1
I1027 18:24:39.862951  5972 net.cpp:433] conv4_2 -> conv4_2
I1027 18:24:39.865990  5972 net.cpp:155] Setting up conv4_2
I1027 18:24:39.866016  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.866029  5972 layer_factory.hpp:76] Creating layer relu4_2
I1027 18:24:39.866036  5972 net.cpp:110] Creating Layer relu4_2
I1027 18:24:39.866039  5972 net.cpp:477] relu4_2 <- conv4_2
I1027 18:24:39.866055  5972 net.cpp:419] relu4_2 -> conv4_2 (in-place)
I1027 18:24:39.866062  5972 net.cpp:155] Setting up relu4_2
I1027 18:24:39.866065  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.866066  5972 layer_factory.hpp:76] Creating layer conv4_3
I1027 18:24:39.866071  5972 net.cpp:110] Creating Layer conv4_3
I1027 18:24:39.866073  5972 net.cpp:477] conv4_3 <- conv4_2
I1027 18:24:39.866077  5972 net.cpp:433] conv4_3 -> conv4_3
I1027 18:24:39.869158  5972 net.cpp:155] Setting up conv4_3
I1027 18:24:39.869185  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.869192  5972 layer_factory.hpp:76] Creating layer relu4_3
I1027 18:24:39.869200  5972 net.cpp:110] Creating Layer relu4_3
I1027 18:24:39.869204  5972 net.cpp:477] relu4_3 <- conv4_3
I1027 18:24:39.869210  5972 net.cpp:419] relu4_3 -> conv4_3 (in-place)
I1027 18:24:39.869227  5972 net.cpp:155] Setting up relu4_3
I1027 18:24:39.869230  5972 net.cpp:163] Top shape: 1 512 47 157 (3778048)
I1027 18:24:39.869231  5972 layer_factory.hpp:76] Creating layer pool4
I1027 18:24:39.869236  5972 net.cpp:110] Creating Layer pool4
I1027 18:24:39.869238  5972 net.cpp:477] pool4 <- conv4_3
I1027 18:24:39.869241  5972 net.cpp:433] pool4 -> pool4
I1027 18:24:39.869249  5972 net.cpp:155] Setting up pool4
I1027 18:24:39.869251  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.869254  5972 layer_factory.hpp:76] Creating layer conv5_1
I1027 18:24:39.869258  5972 net.cpp:110] Creating Layer conv5_1
I1027 18:24:39.869261  5972 net.cpp:477] conv5_1 <- pool4
I1027 18:24:39.869264  5972 net.cpp:433] conv5_1 -> conv5_1
I1027 18:24:39.872591  5972 net.cpp:155] Setting up conv5_1
I1027 18:24:39.872642  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.872654  5972 layer_factory.hpp:76] Creating layer relu5_1
I1027 18:24:39.872676  5972 net.cpp:110] Creating Layer relu5_1
I1027 18:24:39.872684  5972 net.cpp:477] relu5_1 <- conv5_1
I1027 18:24:39.872694  5972 net.cpp:419] relu5_1 -> conv5_1 (in-place)
I1027 18:24:39.872706  5972 net.cpp:155] Setting up relu5_1
I1027 18:24:39.872711  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.872716  5972 layer_factory.hpp:76] Creating layer conv5_2
I1027 18:24:39.872723  5972 net.cpp:110] Creating Layer conv5_2
I1027 18:24:39.872728  5972 net.cpp:477] conv5_2 <- conv5_1
I1027 18:24:39.872732  5972 net.cpp:433] conv5_2 -> conv5_2
I1027 18:24:39.875834  5972 net.cpp:155] Setting up conv5_2
I1027 18:24:39.875859  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.875866  5972 layer_factory.hpp:76] Creating layer relu5_2
I1027 18:24:39.875874  5972 net.cpp:110] Creating Layer relu5_2
I1027 18:24:39.875879  5972 net.cpp:477] relu5_2 <- conv5_2
I1027 18:24:39.875893  5972 net.cpp:419] relu5_2 -> conv5_2 (in-place)
I1027 18:24:39.875901  5972 net.cpp:155] Setting up relu5_2
I1027 18:24:39.875903  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.875905  5972 layer_factory.hpp:76] Creating layer conv5_3
I1027 18:24:39.875911  5972 net.cpp:110] Creating Layer conv5_3
I1027 18:24:39.875912  5972 net.cpp:477] conv5_3 <- conv5_2
I1027 18:24:39.875916  5972 net.cpp:433] conv5_3 -> conv5_3
I1027 18:24:39.879050  5972 net.cpp:155] Setting up conv5_3
I1027 18:24:39.879079  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.879087  5972 layer_factory.hpp:76] Creating layer relu5_3
I1027 18:24:39.879096  5972 net.cpp:110] Creating Layer relu5_3
I1027 18:24:39.879098  5972 net.cpp:477] relu5_3 <- conv5_3
I1027 18:24:39.879103  5972 net.cpp:419] relu5_3 -> conv5_3 (in-place)
I1027 18:24:39.879122  5972 net.cpp:155] Setting up relu5_3
I1027 18:24:39.879123  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.879125  5972 layer_factory.hpp:76] Creating layer conv5_3_relu5_3_0_split
I1027 18:24:39.879135  5972 net.cpp:110] Creating Layer conv5_3_relu5_3_0_split
I1027 18:24:39.879137  5972 net.cpp:477] conv5_3_relu5_3_0_split <- conv5_3
I1027 18:24:39.879140  5972 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I1027 18:24:39.879148  5972 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I1027 18:24:39.879151  5972 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I1027 18:24:39.879156  5972 net.cpp:155] Setting up conv5_3_relu5_3_0_split
I1027 18:24:39.879158  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.879161  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.879163  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:39.879165  5972 layer_factory.hpp:76] Creating layer roi_pool5_readonly
I1027 18:24:39.879180  5972 net.cpp:110] Creating Layer roi_pool5_readonly
I1027 18:24:39.879184  5972 net.cpp:477] roi_pool5_readonly <- conv5_3_relu5_3_0_split_0
I1027 18:24:39.879186  5972 net.cpp:477] roi_pool5_readonly <- rois_data_1_split_0
I1027 18:24:39.879189  5972 net.cpp:433] roi_pool5_readonly -> pool5_readonly
I1027 18:24:39.879194  5972 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1027 18:24:39.879206  5972 net.cpp:155] Setting up roi_pool5_readonly
I1027 18:24:39.879209  5972 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1027 18:24:39.879211  5972 layer_factory.hpp:76] Creating layer fc6_readonly
I1027 18:24:39.879217  5972 net.cpp:110] Creating Layer fc6_readonly
I1027 18:24:39.879221  5972 net.cpp:477] fc6_readonly <- pool5_readonly
I1027 18:24:39.879225  5972 net.cpp:433] fc6_readonly -> fc6_readonly
I1027 18:24:40.017621  5972 net.cpp:155] Setting up fc6_readonly
I1027 18:24:40.017648  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.017658  5972 layer_factory.hpp:76] Creating layer relu6_readonly
I1027 18:24:40.017668  5972 net.cpp:110] Creating Layer relu6_readonly
I1027 18:24:40.017671  5972 net.cpp:477] relu6_readonly <- fc6_readonly
I1027 18:24:40.017686  5972 net.cpp:419] relu6_readonly -> fc6_readonly (in-place)
I1027 18:24:40.017695  5972 net.cpp:155] Setting up relu6_readonly
I1027 18:24:40.017698  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.017699  5972 layer_factory.hpp:76] Creating layer drop6_readonly
I1027 18:24:40.017705  5972 net.cpp:110] Creating Layer drop6_readonly
I1027 18:24:40.017710  5972 net.cpp:477] drop6_readonly <- fc6_readonly
I1027 18:24:40.017714  5972 net.cpp:419] drop6_readonly -> fc6_readonly (in-place)
I1027 18:24:40.017719  5972 net.cpp:155] Setting up drop6_readonly
I1027 18:24:40.017720  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.017722  5972 layer_factory.hpp:76] Creating layer fc7_readonly
I1027 18:24:40.017729  5972 net.cpp:110] Creating Layer fc7_readonly
I1027 18:24:40.017729  5972 net.cpp:477] fc7_readonly <- fc6_readonly
I1027 18:24:40.017732  5972 net.cpp:433] fc7_readonly -> fc7_readonly
I1027 18:24:40.040423  5972 net.cpp:155] Setting up fc7_readonly
I1027 18:24:40.040449  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.040457  5972 layer_factory.hpp:76] Creating layer relu7_readonly
I1027 18:24:40.040467  5972 net.cpp:110] Creating Layer relu7_readonly
I1027 18:24:40.040472  5972 net.cpp:477] relu7_readonly <- fc7_readonly
I1027 18:24:40.040488  5972 net.cpp:419] relu7_readonly -> fc7_readonly (in-place)
I1027 18:24:40.040495  5972 net.cpp:155] Setting up relu7_readonly
I1027 18:24:40.040498  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.040500  5972 layer_factory.hpp:76] Creating layer drop7_readonly
I1027 18:24:40.040505  5972 net.cpp:110] Creating Layer drop7_readonly
I1027 18:24:40.040508  5972 net.cpp:477] drop7_readonly <- fc7_readonly
I1027 18:24:40.040509  5972 net.cpp:419] drop7_readonly -> fc7_readonly (in-place)
I1027 18:24:40.040514  5972 net.cpp:155] Setting up drop7_readonly
I1027 18:24:40.040516  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.040518  5972 layer_factory.hpp:76] Creating layer fc7_readonly_drop7_readonly_0_split
I1027 18:24:40.040523  5972 net.cpp:110] Creating Layer fc7_readonly_drop7_readonly_0_split
I1027 18:24:40.040524  5972 net.cpp:477] fc7_readonly_drop7_readonly_0_split <- fc7_readonly
I1027 18:24:40.040527  5972 net.cpp:433] fc7_readonly_drop7_readonly_0_split -> fc7_readonly_drop7_readonly_0_split_0
I1027 18:24:40.040531  5972 net.cpp:433] fc7_readonly_drop7_readonly_0_split -> fc7_readonly_drop7_readonly_0_split_1
I1027 18:24:40.040540  5972 net.cpp:155] Setting up fc7_readonly_drop7_readonly_0_split
I1027 18:24:40.040544  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.040547  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.040549  5972 layer_factory.hpp:76] Creating layer cls_score_readonly
I1027 18:24:40.040555  5972 net.cpp:110] Creating Layer cls_score_readonly
I1027 18:24:40.040558  5972 net.cpp:477] cls_score_readonly <- fc7_readonly_drop7_readonly_0_split_0
I1027 18:24:40.040562  5972 net.cpp:433] cls_score_readonly -> cls_score_readonly
I1027 18:24:40.041254  5972 net.cpp:155] Setting up cls_score_readonly
I1027 18:24:40.041259  5972 net.cpp:163] Top shape: 1 8 (8)
I1027 18:24:40.041273  5972 layer_factory.hpp:76] Creating layer bbox_pred_readonly
I1027 18:24:40.041278  5972 net.cpp:110] Creating Layer bbox_pred_readonly
I1027 18:24:40.041280  5972 net.cpp:477] bbox_pred_readonly <- fc7_readonly_drop7_readonly_0_split_1
I1027 18:24:40.041285  5972 net.cpp:433] bbox_pred_readonly -> bbox_pred_readonly
I1027 18:24:40.043903  5972 net.cpp:155] Setting up bbox_pred_readonly
I1027 18:24:40.043910  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:40.043916  5972 layer_factory.hpp:76] Creating layer cls_prob_readonly
I1027 18:24:40.043920  5972 net.cpp:110] Creating Layer cls_prob_readonly
I1027 18:24:40.043922  5972 net.cpp:477] cls_prob_readonly <- cls_score_readonly
I1027 18:24:40.043926  5972 net.cpp:433] cls_prob_readonly -> cls_prob_readonly
I1027 18:24:40.043949  5972 net.cpp:155] Setting up cls_prob_readonly
I1027 18:24:40.043952  5972 net.cpp:163] Top shape: 1 8 (8)
I1027 18:24:40.043954  5972 layer_factory.hpp:76] Creating layer hard_roi_mining
I1027 18:24:40.044004  5972 net.cpp:110] Creating Layer hard_roi_mining
I1027 18:24:40.044008  5972 net.cpp:477] hard_roi_mining <- cls_prob_readonly
I1027 18:24:40.044011  5972 net.cpp:477] hard_roi_mining <- bbox_pred_readonly
I1027 18:24:40.044013  5972 net.cpp:477] hard_roi_mining <- rois_data_1_split_1
I1027 18:24:40.044015  5972 net.cpp:477] hard_roi_mining <- labels
I1027 18:24:40.044018  5972 net.cpp:477] hard_roi_mining <- bbox_targets
I1027 18:24:40.044020  5972 net.cpp:477] hard_roi_mining <- bbox_inside_weights
I1027 18:24:40.044023  5972 net.cpp:477] hard_roi_mining <- bbox_outside_weights
I1027 18:24:40.044025  5972 net.cpp:433] hard_roi_mining -> rois_hard
I1027 18:24:40.044041  5972 net.cpp:433] hard_roi_mining -> labels_hard
I1027 18:24:40.044045  5972 net.cpp:433] hard_roi_mining -> bbox_targets_hard
I1027 18:24:40.044049  5972 net.cpp:433] hard_roi_mining -> bbox_inside_weights_hard
I1027 18:24:40.044054  5972 net.cpp:433] hard_roi_mining -> bbox_outside_weights_hard
OHEMDataLayer: name_to_top: {'bbox_outside_weights_hard': 4, 'bbox_inside_weights_hard': 3, 'labels_hard': 1, 'rois_hard': 0, 'bbox_targets_hard': 2}
I1027 18:24:40.044395  5972 net.cpp:155] Setting up hard_roi_mining
I1027 18:24:40.044402  5972 net.cpp:163] Top shape: 1 5 (5)
I1027 18:24:40.044404  5972 net.cpp:163] Top shape: 1 (1)
I1027 18:24:40.044407  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:40.044409  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:40.044411  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:40.044414  5972 layer_factory.hpp:76] Creating layer roi_pool5
I1027 18:24:40.044419  5972 net.cpp:110] Creating Layer roi_pool5
I1027 18:24:40.044420  5972 net.cpp:477] roi_pool5 <- conv5_3_relu5_3_0_split_1
I1027 18:24:40.044425  5972 net.cpp:477] roi_pool5 <- rois_hard
I1027 18:24:40.044427  5972 net.cpp:433] roi_pool5 -> pool5
I1027 18:24:40.044432  5972 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1027 18:24:40.044442  5972 net.cpp:155] Setting up roi_pool5
I1027 18:24:40.044445  5972 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1027 18:24:40.044447  5972 layer_factory.hpp:76] Creating layer fc6
I1027 18:24:40.044461  5972 net.cpp:110] Creating Layer fc6
I1027 18:24:40.044463  5972 net.cpp:477] fc6 <- pool5
I1027 18:24:40.044466  5972 net.cpp:433] fc6 -> fc6
I1027 18:24:40.181933  5972 net.cpp:155] Setting up fc6
I1027 18:24:40.181963  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.181970  5972 net.cpp:537] Sharing parameters 'fc6_w' owned by layer 'fc6_readonly', param index 0
I1027 18:24:40.181975  5972 net.cpp:537] Sharing parameters 'fc6_b' owned by layer 'fc6_readonly', param index 1
I1027 18:24:40.181977  5972 layer_factory.hpp:76] Creating layer relu6
I1027 18:24:40.181985  5972 net.cpp:110] Creating Layer relu6
I1027 18:24:40.181989  5972 net.cpp:477] relu6 <- fc6
I1027 18:24:40.181994  5972 net.cpp:419] relu6 -> fc6 (in-place)
I1027 18:24:40.182013  5972 net.cpp:155] Setting up relu6
I1027 18:24:40.182014  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.182016  5972 layer_factory.hpp:76] Creating layer drop6
I1027 18:24:40.182023  5972 net.cpp:110] Creating Layer drop6
I1027 18:24:40.182024  5972 net.cpp:477] drop6 <- fc6
I1027 18:24:40.182027  5972 net.cpp:419] drop6 -> fc6 (in-place)
I1027 18:24:40.182031  5972 net.cpp:155] Setting up drop6
I1027 18:24:40.182034  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.182035  5972 layer_factory.hpp:76] Creating layer fc7
I1027 18:24:40.182040  5972 net.cpp:110] Creating Layer fc7
I1027 18:24:40.182042  5972 net.cpp:477] fc7 <- fc6
I1027 18:24:40.182046  5972 net.cpp:433] fc7 -> fc7
I1027 18:24:40.204627  5972 net.cpp:155] Setting up fc7
I1027 18:24:40.204654  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.204661  5972 net.cpp:537] Sharing parameters 'fc7_w' owned by layer 'fc7_readonly', param index 0
I1027 18:24:40.204665  5972 net.cpp:537] Sharing parameters 'fc7_b' owned by layer 'fc7_readonly', param index 1
I1027 18:24:40.204668  5972 layer_factory.hpp:76] Creating layer relu7
I1027 18:24:40.204675  5972 net.cpp:110] Creating Layer relu7
I1027 18:24:40.204680  5972 net.cpp:477] relu7 <- fc7
I1027 18:24:40.204695  5972 net.cpp:419] relu7 -> fc7 (in-place)
I1027 18:24:40.204707  5972 net.cpp:155] Setting up relu7
I1027 18:24:40.204710  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.204711  5972 layer_factory.hpp:76] Creating layer drop7
I1027 18:24:40.204717  5972 net.cpp:110] Creating Layer drop7
I1027 18:24:40.204720  5972 net.cpp:477] drop7 <- fc7
I1027 18:24:40.204721  5972 net.cpp:419] drop7 -> fc7 (in-place)
I1027 18:24:40.204725  5972 net.cpp:155] Setting up drop7
I1027 18:24:40.204727  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.204730  5972 layer_factory.hpp:76] Creating layer fc7_drop7_0_split
I1027 18:24:40.204733  5972 net.cpp:110] Creating Layer fc7_drop7_0_split
I1027 18:24:40.204735  5972 net.cpp:477] fc7_drop7_0_split <- fc7
I1027 18:24:40.204738  5972 net.cpp:433] fc7_drop7_0_split -> fc7_drop7_0_split_0
I1027 18:24:40.204743  5972 net.cpp:433] fc7_drop7_0_split -> fc7_drop7_0_split_1
I1027 18:24:40.204747  5972 net.cpp:155] Setting up fc7_drop7_0_split
I1027 18:24:40.204749  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.204752  5972 net.cpp:163] Top shape: 1 4096 (4096)
I1027 18:24:40.204754  5972 layer_factory.hpp:76] Creating layer cls_score
I1027 18:24:40.204759  5972 net.cpp:110] Creating Layer cls_score
I1027 18:24:40.204762  5972 net.cpp:477] cls_score <- fc7_drop7_0_split_0
I1027 18:24:40.204766  5972 net.cpp:433] cls_score -> cls_score
I1027 18:24:40.205453  5972 net.cpp:155] Setting up cls_score
I1027 18:24:40.205458  5972 net.cpp:163] Top shape: 1 8 (8)
I1027 18:24:40.205461  5972 net.cpp:537] Sharing parameters 'cls_score_w' owned by layer 'cls_score_readonly', param index 0
I1027 18:24:40.205464  5972 net.cpp:537] Sharing parameters 'cls_score_b' owned by layer 'cls_score_readonly', param index 1
I1027 18:24:40.205466  5972 layer_factory.hpp:76] Creating layer bbox_pred
I1027 18:24:40.205471  5972 net.cpp:110] Creating Layer bbox_pred
I1027 18:24:40.205473  5972 net.cpp:477] bbox_pred <- fc7_drop7_0_split_1
I1027 18:24:40.205477  5972 net.cpp:433] bbox_pred -> bbox_pred
I1027 18:24:40.208390  5972 net.cpp:155] Setting up bbox_pred
I1027 18:24:40.208398  5972 net.cpp:163] Top shape: 1 32 (32)
I1027 18:24:40.208401  5972 net.cpp:537] Sharing parameters 'bbox_pred_w' owned by layer 'bbox_pred_readonly', param index 0
I1027 18:24:40.208405  5972 net.cpp:537] Sharing parameters 'bbox_pred_b' owned by layer 'bbox_pred_readonly', param index 1
I1027 18:24:40.208406  5972 layer_factory.hpp:76] Creating layer loss_cls
I1027 18:24:40.208411  5972 net.cpp:110] Creating Layer loss_cls
I1027 18:24:40.208413  5972 net.cpp:477] loss_cls <- cls_score
I1027 18:24:40.208417  5972 net.cpp:477] loss_cls <- labels_hard
I1027 18:24:40.208431  5972 net.cpp:433] loss_cls -> loss_cls
I1027 18:24:40.208442  5972 layer_factory.hpp:76] Creating layer loss_cls
I1027 18:24:40.208482  5972 net.cpp:155] Setting up loss_cls
I1027 18:24:40.208485  5972 net.cpp:163] Top shape: (1)
I1027 18:24:40.208487  5972 net.cpp:168]     with loss weight 1
I1027 18:24:40.208495  5972 layer_factory.hpp:76] Creating layer loss_bbox
I1027 18:24:40.208503  5972 net.cpp:110] Creating Layer loss_bbox
I1027 18:24:40.208504  5972 net.cpp:477] loss_bbox <- bbox_pred
I1027 18:24:40.208518  5972 net.cpp:477] loss_bbox <- bbox_targets_hard
I1027 18:24:40.208519  5972 net.cpp:477] loss_bbox <- bbox_inside_weights_hard
I1027 18:24:40.208523  5972 net.cpp:477] loss_bbox <- bbox_outside_weights_hard
I1027 18:24:40.208525  5972 net.cpp:433] loss_bbox -> loss_bbox
I1027 18:24:40.208559  5972 net.cpp:155] Setting up loss_bbox
I1027 18:24:40.208562  5972 net.cpp:163] Top shape: (1)
I1027 18:24:40.208564  5972 net.cpp:168]     with loss weight 1
I1027 18:24:40.208569  5972 layer_factory.hpp:76] Creating layer rpn_conv/3x3
I1027 18:24:40.208573  5972 net.cpp:110] Creating Layer rpn_conv/3x3
I1027 18:24:40.208576  5972 net.cpp:477] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_2
I1027 18:24:40.208580  5972 net.cpp:433] rpn_conv/3x3 -> rpn/output
I1027 18:24:40.256438  5972 net.cpp:155] Setting up rpn_conv/3x3
I1027 18:24:40.256461  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:40.256469  5972 layer_factory.hpp:76] Creating layer rpn_relu/3x3
I1027 18:24:40.256476  5972 net.cpp:110] Creating Layer rpn_relu/3x3
I1027 18:24:40.256480  5972 net.cpp:477] rpn_relu/3x3 <- rpn/output
I1027 18:24:40.256495  5972 net.cpp:419] rpn_relu/3x3 -> rpn/output (in-place)
I1027 18:24:40.256505  5972 net.cpp:155] Setting up rpn_relu/3x3
I1027 18:24:40.256506  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:40.256508  5972 layer_factory.hpp:76] Creating layer rpn/output_rpn_relu/3x3_0_split
I1027 18:24:40.256512  5972 net.cpp:110] Creating Layer rpn/output_rpn_relu/3x3_0_split
I1027 18:24:40.256515  5972 net.cpp:477] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I1027 18:24:40.256517  5972 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I1027 18:24:40.256521  5972 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I1027 18:24:40.256526  5972 net.cpp:155] Setting up rpn/output_rpn_relu/3x3_0_split
I1027 18:24:40.256530  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:40.256531  5972 net.cpp:163] Top shape: 1 512 24 79 (970752)
I1027 18:24:40.256533  5972 layer_factory.hpp:76] Creating layer rpn_cls_score
I1027 18:24:40.256538  5972 net.cpp:110] Creating Layer rpn_cls_score
I1027 18:24:40.256541  5972 net.cpp:477] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I1027 18:24:40.256543  5972 net.cpp:433] rpn_cls_score -> rpn_cls_score
I1027 18:24:40.256786  5972 net.cpp:155] Setting up rpn_cls_score
I1027 18:24:40.256791  5972 net.cpp:163] Top shape: 1 18 24 79 (34128)
I1027 18:24:40.256794  5972 layer_factory.hpp:76] Creating layer rpn_bbox_pred
I1027 18:24:40.256799  5972 net.cpp:110] Creating Layer rpn_bbox_pred
I1027 18:24:40.256801  5972 net.cpp:477] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I1027 18:24:40.256805  5972 net.cpp:433] rpn_bbox_pred -> rpn_bbox_pred
I1027 18:24:40.257222  5972 net.cpp:155] Setting up rpn_bbox_pred
I1027 18:24:40.257227  5972 net.cpp:163] Top shape: 1 36 24 79 (68256)
I1027 18:24:40.257230  5972 layer_factory.hpp:76] Creating layer silence_rpn_cls_score
I1027 18:24:40.257235  5972 net.cpp:110] Creating Layer silence_rpn_cls_score
I1027 18:24:40.257238  5972 net.cpp:477] silence_rpn_cls_score <- rpn_cls_score
I1027 18:24:40.257241  5972 net.cpp:155] Setting up silence_rpn_cls_score
I1027 18:24:40.257243  5972 layer_factory.hpp:76] Creating layer silence_rpn_bbox_pred
I1027 18:24:40.257246  5972 net.cpp:110] Creating Layer silence_rpn_bbox_pred
I1027 18:24:40.257258  5972 net.cpp:477] silence_rpn_bbox_pred <- rpn_bbox_pred
I1027 18:24:40.257261  5972 net.cpp:155] Setting up silence_rpn_bbox_pred
I1027 18:24:40.257262  5972 net.cpp:240] silence_rpn_bbox_pred does not need backward computation.
I1027 18:24:40.257264  5972 net.cpp:240] silence_rpn_cls_score does not need backward computation.
I1027 18:24:40.257266  5972 net.cpp:240] rpn_bbox_pred does not need backward computation.
I1027 18:24:40.257268  5972 net.cpp:240] rpn_cls_score does not need backward computation.
I1027 18:24:40.257271  5972 net.cpp:240] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I1027 18:24:40.257272  5972 net.cpp:240] rpn_relu/3x3 does not need backward computation.
I1027 18:24:40.257273  5972 net.cpp:240] rpn_conv/3x3 does not need backward computation.
I1027 18:24:40.257277  5972 net.cpp:236] loss_bbox needs backward computation.
I1027 18:24:40.257279  5972 net.cpp:236] loss_cls needs backward computation.
I1027 18:24:40.257282  5972 net.cpp:236] bbox_pred needs backward computation.
I1027 18:24:40.257285  5972 net.cpp:236] cls_score needs backward computation.
I1027 18:24:40.257288  5972 net.cpp:236] fc7_drop7_0_split needs backward computation.
I1027 18:24:40.257290  5972 net.cpp:236] drop7 needs backward computation.
I1027 18:24:40.257292  5972 net.cpp:236] relu7 needs backward computation.
I1027 18:24:40.257294  5972 net.cpp:236] fc7 needs backward computation.
I1027 18:24:40.257297  5972 net.cpp:236] drop6 needs backward computation.
I1027 18:24:40.257299  5972 net.cpp:236] relu6 needs backward computation.
I1027 18:24:40.257302  5972 net.cpp:236] fc6 needs backward computation.
I1027 18:24:40.257303  5972 net.cpp:236] roi_pool5 needs backward computation.
I1027 18:24:40.257308  5972 net.cpp:240] hard_roi_mining does not need backward computation.
I1027 18:24:40.257313  5972 net.cpp:240] cls_prob_readonly does not need backward computation.
I1027 18:24:40.257315  5972 net.cpp:240] bbox_pred_readonly does not need backward computation.
I1027 18:24:40.257318  5972 net.cpp:240] cls_score_readonly does not need backward computation.
I1027 18:24:40.257321  5972 net.cpp:240] fc7_readonly_drop7_readonly_0_split does not need backward computation.
I1027 18:24:40.257324  5972 net.cpp:240] drop7_readonly does not need backward computation.
I1027 18:24:40.257326  5972 net.cpp:240] relu7_readonly does not need backward computation.
I1027 18:24:40.257328  5972 net.cpp:240] fc7_readonly does not need backward computation.
I1027 18:24:40.257331  5972 net.cpp:240] drop6_readonly does not need backward computation.
I1027 18:24:40.257333  5972 net.cpp:240] relu6_readonly does not need backward computation.
I1027 18:24:40.257335  5972 net.cpp:240] fc6_readonly does not need backward computation.
I1027 18:24:40.257339  5972 net.cpp:240] roi_pool5_readonly does not need backward computation.
I1027 18:24:40.257342  5972 net.cpp:240] conv5_3_relu5_3_0_split does not need backward computation.
I1027 18:24:40.257344  5972 net.cpp:240] relu5_3 does not need backward computation.
I1027 18:24:40.257347  5972 net.cpp:240] conv5_3 does not need backward computation.
I1027 18:24:40.257349  5972 net.cpp:240] relu5_2 does not need backward computation.
I1027 18:24:40.257352  5972 net.cpp:240] conv5_2 does not need backward computation.
I1027 18:24:40.257354  5972 net.cpp:240] relu5_1 does not need backward computation.
I1027 18:24:40.257356  5972 net.cpp:240] conv5_1 does not need backward computation.
I1027 18:24:40.257359  5972 net.cpp:240] pool4 does not need backward computation.
I1027 18:24:40.257362  5972 net.cpp:240] relu4_3 does not need backward computation.
I1027 18:24:40.257364  5972 net.cpp:240] conv4_3 does not need backward computation.
I1027 18:24:40.257367  5972 net.cpp:240] relu4_2 does not need backward computation.
I1027 18:24:40.257369  5972 net.cpp:240] conv4_2 does not need backward computation.
I1027 18:24:40.257372  5972 net.cpp:240] relu4_1 does not need backward computation.
I1027 18:24:40.257375  5972 net.cpp:240] conv4_1 does not need backward computation.
I1027 18:24:40.257377  5972 net.cpp:240] pool3 does not need backward computation.
I1027 18:24:40.257380  5972 net.cpp:240] relu3_3 does not need backward computation.
I1027 18:24:40.257382  5972 net.cpp:240] conv3_3 does not need backward computation.
I1027 18:24:40.257385  5972 net.cpp:240] relu3_2 does not need backward computation.
I1027 18:24:40.257387  5972 net.cpp:240] conv3_2 does not need backward computation.
I1027 18:24:40.257390  5972 net.cpp:240] relu3_1 does not need backward computation.
I1027 18:24:40.257392  5972 net.cpp:240] conv3_1 does not need backward computation.
I1027 18:24:40.257395  5972 net.cpp:240] pool2 does not need backward computation.
I1027 18:24:40.257397  5972 net.cpp:240] relu2_2 does not need backward computation.
I1027 18:24:40.257400  5972 net.cpp:240] conv2_2 does not need backward computation.
I1027 18:24:40.257402  5972 net.cpp:240] relu2_1 does not need backward computation.
I1027 18:24:40.257405  5972 net.cpp:240] conv2_1 does not need backward computation.
I1027 18:24:40.257407  5972 net.cpp:240] pool1 does not need backward computation.
I1027 18:24:40.257411  5972 net.cpp:240] relu1_2 does not need backward computation.
I1027 18:24:40.257412  5972 net.cpp:240] conv1_2 does not need backward computation.
I1027 18:24:40.257416  5972 net.cpp:240] relu1_1 does not need backward computation.
I1027 18:24:40.257417  5972 net.cpp:240] conv1_1 does not need backward computation.
I1027 18:24:40.257421  5972 net.cpp:240] rois_data_1_split does not need backward computation.
I1027 18:24:40.257424  5972 net.cpp:240] data does not need backward computation.
I1027 18:24:40.257426  5972 net.cpp:283] This network produces output loss_bbox
I1027 18:24:40.257428  5972 net.cpp:283] This network produces output loss_cls
I1027 18:24:40.295238  5972 net.cpp:297] Network initialization done.
I1027 18:24:40.295258  5972 net.cpp:298] Memory required for data: 1092764464
I1027 18:24:40.295619  5972 solver.cpp:65] Solver scaffolding done.
Loading pretrained model weights from /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_fast_rcnn_stage2_iter_30000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 1026092617
Solving...
/home/bsl/KITTI-detection/tools/../lib/roi_data_layer/minibatch.py:316: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
/home/bsl/KITTI-detection/tools/../lib/roi_data_layer/minibatch.py:317: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_inside_weights[ind, start:end] = cfg.TRAIN.BBOX_INSIDE_WEIGHTS
/home/bsl/KITTI-detection/tools/../lib/roi_data_layer/layer.py:282: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  for x in [cls_prob[i,label] for i, label in enumerate(labels)]]
I1027 18:24:41.866377  5972 solver.cpp:242] Iteration 0, loss = 0.202269
I1027 18:24:41.866403  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0941966 (* 1 = 0.0941966 loss)
I1027 18:24:41.866408  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.108073 (* 1 = 0.108073 loss)
I1027 18:24:41.866417  5972 solver.cpp:571] Iteration 0, lr = 0.001
I1027 18:24:48.677386  5972 solver.cpp:242] Iteration 20, loss = 0.0208439
I1027 18:24:48.677413  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.015998 (* 1 = 0.015998 loss)
I1027 18:24:48.677418  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00484597 (* 1 = 0.00484597 loss)
I1027 18:24:48.677423  5972 solver.cpp:571] Iteration 20, lr = 0.001
I1027 18:24:55.223443  5972 solver.cpp:242] Iteration 40, loss = 0.017781
I1027 18:24:55.223471  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00590768 (* 1 = 0.00590768 loss)
I1027 18:24:55.223476  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0118733 (* 1 = 0.0118733 loss)
I1027 18:24:55.223481  5972 solver.cpp:571] Iteration 40, lr = 0.001
I1027 18:25:01.840916  5972 solver.cpp:242] Iteration 60, loss = 0.329924
I1027 18:25:01.840945  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.180473 (* 1 = 0.180473 loss)
I1027 18:25:01.840948  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149451 (* 1 = 0.149451 loss)
I1027 18:25:01.840955  5972 solver.cpp:571] Iteration 60, lr = 0.001
I1027 18:25:08.110119  5972 solver.cpp:242] Iteration 80, loss = 0.00983577
I1027 18:25:08.110146  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00177395 (* 1 = 0.00177395 loss)
I1027 18:25:08.110152  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00806182 (* 1 = 0.00806182 loss)
I1027 18:25:08.110157  5972 solver.cpp:571] Iteration 80, lr = 0.001
I1027 18:25:14.872202  5972 solver.cpp:242] Iteration 100, loss = 0.389815
I1027 18:25:14.872239  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.202419 (* 1 = 0.202419 loss)
I1027 18:25:14.872244  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.187396 (* 1 = 0.187396 loss)
I1027 18:25:14.872249  5972 solver.cpp:571] Iteration 100, lr = 0.001
I1027 18:25:21.800288  5972 solver.cpp:242] Iteration 120, loss = 0.370195
I1027 18:25:21.800318  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0925872 (* 1 = 0.0925872 loss)
I1027 18:25:21.800323  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.277608 (* 1 = 0.277608 loss)
I1027 18:25:21.800328  5972 solver.cpp:571] Iteration 120, lr = 0.001
I1027 18:25:29.172884  5972 solver.cpp:242] Iteration 140, loss = 0.388857
I1027 18:25:29.172911  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.181435 (* 1 = 0.181435 loss)
I1027 18:25:29.172916  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.207422 (* 1 = 0.207422 loss)
I1027 18:25:29.172920  5972 solver.cpp:571] Iteration 140, lr = 0.001
I1027 18:25:36.351891  5972 solver.cpp:242] Iteration 160, loss = 0.167846
I1027 18:25:36.351917  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.102033 (* 1 = 0.102033 loss)
I1027 18:25:36.351922  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0658127 (* 1 = 0.0658127 loss)
I1027 18:25:36.351927  5972 solver.cpp:571] Iteration 160, lr = 0.001
I1027 18:25:43.309483  5972 solver.cpp:242] Iteration 180, loss = 0.218621
I1027 18:25:43.309509  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.114762 (* 1 = 0.114762 loss)
I1027 18:25:43.309514  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.103859 (* 1 = 0.103859 loss)
I1027 18:25:43.309517  5972 solver.cpp:571] Iteration 180, lr = 0.001
speed: 0.343s / iter
I1027 18:25:50.493849  5972 solver.cpp:242] Iteration 200, loss = 0.568337
I1027 18:25:50.493876  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.209174 (* 1 = 0.209174 loss)
I1027 18:25:50.493880  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.359163 (* 1 = 0.359163 loss)
I1027 18:25:50.493885  5972 solver.cpp:571] Iteration 200, lr = 0.001
I1027 18:25:57.418072  5972 solver.cpp:242] Iteration 220, loss = 0.603634
I1027 18:25:57.418097  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.291485 (* 1 = 0.291485 loss)
I1027 18:25:57.418102  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.312149 (* 1 = 0.312149 loss)
I1027 18:25:57.418107  5972 solver.cpp:571] Iteration 220, lr = 0.001
I1027 18:26:04.097090  5972 solver.cpp:242] Iteration 240, loss = 0.0323535
I1027 18:26:04.097117  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00476356 (* 1 = 0.00476356 loss)
I1027 18:26:04.097121  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0275899 (* 1 = 0.0275899 loss)
I1027 18:26:04.097126  5972 solver.cpp:571] Iteration 240, lr = 0.001
I1027 18:26:10.812873  5972 solver.cpp:242] Iteration 260, loss = 0.332853
I1027 18:26:10.812901  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.168518 (* 1 = 0.168518 loss)
I1027 18:26:10.812906  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.164335 (* 1 = 0.164335 loss)
I1027 18:26:10.812911  5972 solver.cpp:571] Iteration 260, lr = 0.001
I1027 18:26:17.669425  5972 solver.cpp:242] Iteration 280, loss = 0.105454
I1027 18:26:17.669466  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0263414 (* 1 = 0.0263414 loss)
I1027 18:26:17.669471  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0791126 (* 1 = 0.0791126 loss)
I1027 18:26:17.669476  5972 solver.cpp:571] Iteration 280, lr = 0.001
I1027 18:26:24.394184  5972 solver.cpp:242] Iteration 300, loss = 0.21765
I1027 18:26:24.394210  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.07569 (* 1 = 0.07569 loss)
I1027 18:26:24.394215  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.14196 (* 1 = 0.14196 loss)
I1027 18:26:24.394222  5972 solver.cpp:571] Iteration 300, lr = 0.001
I1027 18:26:30.858316  5972 solver.cpp:242] Iteration 320, loss = 0.0337963
I1027 18:26:30.858356  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0063474 (* 1 = 0.0063474 loss)
I1027 18:26:30.858361  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0274489 (* 1 = 0.0274489 loss)
I1027 18:26:30.858366  5972 solver.cpp:571] Iteration 320, lr = 0.001
I1027 18:26:37.422461  5972 solver.cpp:242] Iteration 340, loss = 0.121912
I1027 18:26:37.422500  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0793107 (* 1 = 0.0793107 loss)
I1027 18:26:37.422505  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0426013 (* 1 = 0.0426013 loss)
I1027 18:26:37.422510  5972 solver.cpp:571] Iteration 340, lr = 0.001
I1027 18:26:48.459653  5972 solver.cpp:242] Iteration 360, loss = 0.556396
I1027 18:26:48.459730  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.269708 (* 1 = 0.269708 loss)
I1027 18:26:48.459741  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.286689 (* 1 = 0.286689 loss)
I1027 18:26:48.459756  5972 solver.cpp:571] Iteration 360, lr = 0.001
I1027 18:27:00.609866  5972 solver.cpp:242] Iteration 380, loss = 0.209822
I1027 18:27:00.609897  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0721515 (* 1 = 0.0721515 loss)
I1027 18:27:00.609905  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.13767 (* 1 = 0.13767 loss)
I1027 18:27:00.609921  5972 solver.cpp:571] Iteration 380, lr = 0.001
speed: 0.377s / iter
I1027 18:27:12.866840  5972 solver.cpp:242] Iteration 400, loss = 0.0975761
I1027 18:27:12.866884  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0413331 (* 1 = 0.0413331 loss)
I1027 18:27:12.866892  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.056243 (* 1 = 0.056243 loss)
I1027 18:27:12.866899  5972 solver.cpp:571] Iteration 400, lr = 0.001
I1027 18:27:25.235956  5972 solver.cpp:242] Iteration 420, loss = 0.289063
I1027 18:27:25.235991  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.165152 (* 1 = 0.165152 loss)
I1027 18:27:25.236001  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.123911 (* 1 = 0.123911 loss)
I1027 18:27:25.236007  5972 solver.cpp:571] Iteration 420, lr = 0.001
I1027 18:27:34.074659  5972 solver.cpp:242] Iteration 440, loss = 0.279378
I1027 18:27:34.074689  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.114872 (* 1 = 0.114872 loss)
I1027 18:27:34.074697  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.164506 (* 1 = 0.164506 loss)
I1027 18:27:34.074703  5972 solver.cpp:571] Iteration 440, lr = 0.001
I1027 18:27:40.751762  5972 solver.cpp:242] Iteration 460, loss = 0.326518
I1027 18:27:40.751811  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.17532 (* 1 = 0.17532 loss)
I1027 18:27:40.751818  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.151199 (* 1 = 0.151199 loss)
I1027 18:27:40.751826  5972 solver.cpp:571] Iteration 460, lr = 0.001
I1027 18:27:47.805130  5972 solver.cpp:242] Iteration 480, loss = 0.0686769
I1027 18:27:47.805160  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0361006 (* 1 = 0.0361006 loss)
I1027 18:27:47.805166  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0325763 (* 1 = 0.0325763 loss)
I1027 18:27:47.805173  5972 solver.cpp:571] Iteration 480, lr = 0.001
I1027 18:27:54.285909  5972 solver.cpp:242] Iteration 500, loss = 0.368328
I1027 18:27:54.285938  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.118436 (* 1 = 0.118436 loss)
I1027 18:27:54.285946  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.249892 (* 1 = 0.249892 loss)
I1027 18:27:54.285953  5972 solver.cpp:571] Iteration 500, lr = 0.001
I1027 18:28:01.106981  5972 solver.cpp:242] Iteration 520, loss = 0.142091
I1027 18:28:01.107010  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0564972 (* 1 = 0.0564972 loss)
I1027 18:28:01.107018  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0855935 (* 1 = 0.0855935 loss)
I1027 18:28:01.107025  5972 solver.cpp:571] Iteration 520, lr = 0.001
I1027 18:28:08.134486  5972 solver.cpp:242] Iteration 540, loss = 0.279666
I1027 18:28:08.134526  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.127936 (* 1 = 0.127936 loss)
I1027 18:28:08.134533  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.15173 (* 1 = 0.15173 loss)
I1027 18:28:08.134541  5972 solver.cpp:571] Iteration 540, lr = 0.001
I1027 18:28:16.373884  5972 solver.cpp:242] Iteration 560, loss = 0.0786156
I1027 18:28:16.373934  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0197315 (* 1 = 0.0197315 loss)
I1027 18:28:16.373945  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0588841 (* 1 = 0.0588841 loss)
I1027 18:28:16.373953  5972 solver.cpp:571] Iteration 560, lr = 0.001
I1027 18:28:28.606070  5972 solver.cpp:242] Iteration 580, loss = 0.594908
I1027 18:28:28.606098  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.294286 (* 1 = 0.294286 loss)
I1027 18:28:28.606103  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.300622 (* 1 = 0.300622 loss)
I1027 18:28:28.606107  5972 solver.cpp:571] Iteration 580, lr = 0.001
speed: 0.398s / iter
I1027 18:28:40.804638  5972 solver.cpp:242] Iteration 600, loss = 0.109725
I1027 18:28:40.804680  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0397377 (* 1 = 0.0397377 loss)
I1027 18:28:40.804687  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0699877 (* 1 = 0.0699877 loss)
I1027 18:28:40.804692  5972 solver.cpp:571] Iteration 600, lr = 0.001
I1027 18:28:54.761095  5972 solver.cpp:242] Iteration 620, loss = 0.327305
I1027 18:28:54.761142  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.126556 (* 1 = 0.126556 loss)
I1027 18:28:54.761150  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.200749 (* 1 = 0.200749 loss)
I1027 18:28:54.761157  5972 solver.cpp:571] Iteration 620, lr = 0.001
I1027 18:29:07.027621  5972 solver.cpp:242] Iteration 640, loss = 0.222992
I1027 18:29:07.027659  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0726019 (* 1 = 0.0726019 loss)
I1027 18:29:07.027667  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.15039 (* 1 = 0.15039 loss)
I1027 18:29:07.027673  5972 solver.cpp:571] Iteration 640, lr = 0.001
I1027 18:29:20.383657  5972 solver.cpp:242] Iteration 660, loss = 0.125177
I1027 18:29:20.383687  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0603443 (* 1 = 0.0603443 loss)
I1027 18:29:20.383694  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.064833 (* 1 = 0.064833 loss)
I1027 18:29:20.383702  5972 solver.cpp:571] Iteration 660, lr = 0.001
I1027 18:29:36.059902  5972 solver.cpp:242] Iteration 680, loss = 0.329614
I1027 18:29:36.059938  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.177258 (* 1 = 0.177258 loss)
I1027 18:29:36.059943  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.152356 (* 1 = 0.152356 loss)
I1027 18:29:36.059947  5972 solver.cpp:571] Iteration 680, lr = 0.001
I1027 18:29:48.465250  5972 solver.cpp:242] Iteration 700, loss = 0.207994
I1027 18:29:48.465288  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.110468 (* 1 = 0.110468 loss)
I1027 18:29:48.465294  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0975257 (* 1 = 0.0975257 loss)
I1027 18:29:48.465298  5972 solver.cpp:571] Iteration 700, lr = 0.001
I1027 18:30:00.754776  5972 solver.cpp:242] Iteration 720, loss = 0.178512
I1027 18:30:00.754834  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0695694 (* 1 = 0.0695694 loss)
I1027 18:30:00.754847  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.108943 (* 1 = 0.108943 loss)
I1027 18:30:00.754854  5972 solver.cpp:571] Iteration 720, lr = 0.001
I1027 18:30:12.906888  5972 solver.cpp:242] Iteration 740, loss = 0.0226435
I1027 18:30:12.906977  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0192234 (* 1 = 0.0192234 loss)
I1027 18:30:12.906985  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00342017 (* 1 = 0.00342017 loss)
I1027 18:30:12.906991  5972 solver.cpp:571] Iteration 740, lr = 0.001
I1027 18:30:25.098460  5972 solver.cpp:242] Iteration 760, loss = 0.138432
I1027 18:30:25.098505  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0407836 (* 1 = 0.0407836 loss)
I1027 18:30:25.098512  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0976481 (* 1 = 0.0976481 loss)
I1027 18:30:25.098517  5972 solver.cpp:571] Iteration 760, lr = 0.001
I1027 18:30:37.308101  5972 solver.cpp:242] Iteration 780, loss = 0.0880446
I1027 18:30:37.308142  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0481371 (* 1 = 0.0481371 loss)
I1027 18:30:37.308148  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0399075 (* 1 = 0.0399075 loss)
I1027 18:30:37.308153  5972 solver.cpp:571] Iteration 780, lr = 0.001
speed: 0.460s / iter
I1027 18:30:49.689577  5972 solver.cpp:242] Iteration 800, loss = 0.256555
I1027 18:30:49.689617  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0903147 (* 1 = 0.0903147 loss)
I1027 18:30:49.689622  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.16624 (* 1 = 0.16624 loss)
I1027 18:30:49.689628  5972 solver.cpp:571] Iteration 800, lr = 0.001
I1027 18:31:01.892206  5972 solver.cpp:242] Iteration 820, loss = 0.105143
I1027 18:31:01.892246  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0380274 (* 1 = 0.0380274 loss)
I1027 18:31:01.892251  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0671151 (* 1 = 0.0671151 loss)
I1027 18:31:01.892256  5972 solver.cpp:571] Iteration 820, lr = 0.001
I1027 18:31:14.128186  5972 solver.cpp:242] Iteration 840, loss = 0.334476
I1027 18:31:14.128224  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.172589 (* 1 = 0.172589 loss)
I1027 18:31:14.128229  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.161887 (* 1 = 0.161887 loss)
I1027 18:31:14.128233  5972 solver.cpp:571] Iteration 840, lr = 0.001
I1027 18:31:26.100903  5972 solver.cpp:242] Iteration 860, loss = 0.298602
I1027 18:31:26.100946  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.111211 (* 1 = 0.111211 loss)
I1027 18:31:26.100951  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.187391 (* 1 = 0.187391 loss)
I1027 18:31:26.100956  5972 solver.cpp:571] Iteration 860, lr = 0.001
I1027 18:31:38.309221  5972 solver.cpp:242] Iteration 880, loss = 0.272085
I1027 18:31:38.309267  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.15942 (* 1 = 0.15942 loss)
I1027 18:31:38.309273  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.112665 (* 1 = 0.112665 loss)
I1027 18:31:38.309278  5972 solver.cpp:571] Iteration 880, lr = 0.001
I1027 18:31:50.640022  5972 solver.cpp:242] Iteration 900, loss = 0.285216
I1027 18:31:50.640061  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.160953 (* 1 = 0.160953 loss)
I1027 18:31:50.640067  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.124263 (* 1 = 0.124263 loss)
I1027 18:31:50.640072  5972 solver.cpp:571] Iteration 900, lr = 0.001
I1027 18:32:02.789134  5972 solver.cpp:242] Iteration 920, loss = 0.539026
I1027 18:32:02.789193  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.265495 (* 1 = 0.265495 loss)
I1027 18:32:02.789203  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.273531 (* 1 = 0.273531 loss)
I1027 18:32:02.789213  5972 solver.cpp:571] Iteration 920, lr = 0.001
I1027 18:32:15.133018  5972 solver.cpp:242] Iteration 940, loss = 0.460005
I1027 18:32:15.133059  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.237087 (* 1 = 0.237087 loss)
I1027 18:32:15.133065  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.222918 (* 1 = 0.222918 loss)
I1027 18:32:15.133070  5972 solver.cpp:571] Iteration 940, lr = 0.001
I1027 18:32:27.420740  5972 solver.cpp:242] Iteration 960, loss = 0.506048
I1027 18:32:27.420781  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.25368 (* 1 = 0.25368 loss)
I1027 18:32:27.420786  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.252368 (* 1 = 0.252368 loss)
I1027 18:32:27.420791  5972 solver.cpp:571] Iteration 960, lr = 0.001
I1027 18:32:39.722931  5972 solver.cpp:242] Iteration 980, loss = 0.257037
I1027 18:32:39.722980  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11884 (* 1 = 0.11884 loss)
I1027 18:32:39.722985  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.138197 (* 1 = 0.138197 loss)
I1027 18:32:39.722990  5972 solver.cpp:571] Iteration 980, lr = 0.001
speed: 0.490s / iter
I1027 18:32:51.926187  5972 solver.cpp:242] Iteration 1000, loss = 0.0432248
I1027 18:32:51.926270  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0135581 (* 1 = 0.0135581 loss)
I1027 18:32:51.926276  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0296667 (* 1 = 0.0296667 loss)
I1027 18:32:51.926283  5972 solver.cpp:571] Iteration 1000, lr = 0.001
I1027 18:33:04.162261  5972 solver.cpp:242] Iteration 1020, loss = 0.114529
I1027 18:33:04.162292  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0454663 (* 1 = 0.0454663 loss)
I1027 18:33:04.162298  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0690628 (* 1 = 0.0690628 loss)
I1027 18:33:04.162303  5972 solver.cpp:571] Iteration 1020, lr = 0.001
I1027 18:33:16.606513  5972 solver.cpp:242] Iteration 1040, loss = 0.168823
I1027 18:33:16.606556  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0632581 (* 1 = 0.0632581 loss)
I1027 18:33:16.606561  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.105565 (* 1 = 0.105565 loss)
I1027 18:33:16.606566  5972 solver.cpp:571] Iteration 1040, lr = 0.001
I1027 18:33:28.760191  5972 solver.cpp:242] Iteration 1060, loss = 0.239905
I1027 18:33:28.760274  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0920178 (* 1 = 0.0920178 loss)
I1027 18:33:28.760280  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.147887 (* 1 = 0.147887 loss)
I1027 18:33:28.760288  5972 solver.cpp:571] Iteration 1060, lr = 0.001
I1027 18:33:41.061044  5972 solver.cpp:242] Iteration 1080, loss = 0.165216
I1027 18:33:41.061089  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0738801 (* 1 = 0.0738801 loss)
I1027 18:33:41.061094  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0913358 (* 1 = 0.0913358 loss)
I1027 18:33:41.061100  5972 solver.cpp:571] Iteration 1080, lr = 0.001
I1027 18:33:53.571415  5972 solver.cpp:242] Iteration 1100, loss = 0.0450148
I1027 18:33:53.571458  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0110222 (* 1 = 0.0110222 loss)
I1027 18:33:53.571463  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0339926 (* 1 = 0.0339926 loss)
I1027 18:33:53.571468  5972 solver.cpp:571] Iteration 1100, lr = 0.001
I1027 18:34:05.906273  5972 solver.cpp:242] Iteration 1120, loss = 0.301419
I1027 18:34:05.906311  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.116811 (* 1 = 0.116811 loss)
I1027 18:34:05.906316  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.184608 (* 1 = 0.184608 loss)
I1027 18:34:05.906322  5972 solver.cpp:571] Iteration 1120, lr = 0.001
I1027 18:34:18.418788  5972 solver.cpp:242] Iteration 1140, loss = 0.3144
I1027 18:34:18.418833  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.133224 (* 1 = 0.133224 loss)
I1027 18:34:18.418840  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.181177 (* 1 = 0.181177 loss)
I1027 18:34:18.418846  5972 solver.cpp:571] Iteration 1140, lr = 0.001
I1027 18:34:30.922844  5972 solver.cpp:242] Iteration 1160, loss = 0.123381
I1027 18:34:30.922881  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0670795 (* 1 = 0.0670795 loss)
I1027 18:34:30.922886  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0563011 (* 1 = 0.0563011 loss)
I1027 18:34:30.922890  5972 solver.cpp:571] Iteration 1160, lr = 0.001
I1027 18:34:43.131455  5972 solver.cpp:242] Iteration 1180, loss = 0.385406
I1027 18:34:43.131490  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.210452 (* 1 = 0.210452 loss)
I1027 18:34:43.131495  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.174954 (* 1 = 0.174954 loss)
I1027 18:34:43.131500  5972 solver.cpp:571] Iteration 1180, lr = 0.001
speed: 0.511s / iter
I1027 18:34:55.344621  5972 solver.cpp:242] Iteration 1200, loss = 0.00656512
I1027 18:34:55.344655  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00433382 (* 1 = 0.00433382 loss)
I1027 18:34:55.344660  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0022313 (* 1 = 0.0022313 loss)
I1027 18:34:55.344665  5972 solver.cpp:571] Iteration 1200, lr = 0.001
I1027 18:35:07.747170  5972 solver.cpp:242] Iteration 1220, loss = 0.038014
I1027 18:35:07.747208  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0159819 (* 1 = 0.0159819 loss)
I1027 18:35:07.747212  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0220321 (* 1 = 0.0220321 loss)
I1027 18:35:07.747217  5972 solver.cpp:571] Iteration 1220, lr = 0.001
I1027 18:35:20.166415  5972 solver.cpp:242] Iteration 1240, loss = 0.064508
I1027 18:35:20.166442  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0314404 (* 1 = 0.0314404 loss)
I1027 18:35:20.166447  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0330677 (* 1 = 0.0330677 loss)
I1027 18:35:20.166452  5972 solver.cpp:571] Iteration 1240, lr = 0.001
I1027 18:35:32.371261  5972 solver.cpp:242] Iteration 1260, loss = 0.028368
I1027 18:35:32.371299  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00344131 (* 1 = 0.00344131 loss)
I1027 18:35:32.371304  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0249267 (* 1 = 0.0249267 loss)
I1027 18:35:32.371309  5972 solver.cpp:571] Iteration 1260, lr = 0.001
I1027 18:35:44.720268  5972 solver.cpp:242] Iteration 1280, loss = 0.231764
I1027 18:35:44.720321  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.112833 (* 1 = 0.112833 loss)
I1027 18:35:44.720326  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.118931 (* 1 = 0.118931 loss)
I1027 18:35:44.720332  5972 solver.cpp:571] Iteration 1280, lr = 0.001
I1027 18:35:56.970178  5972 solver.cpp:242] Iteration 1300, loss = 0.227795
I1027 18:35:56.970209  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.151409 (* 1 = 0.151409 loss)
I1027 18:35:56.970214  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0763858 (* 1 = 0.0763858 loss)
I1027 18:35:56.970219  5972 solver.cpp:571] Iteration 1300, lr = 0.001
I1027 18:36:09.278758  5972 solver.cpp:242] Iteration 1320, loss = 0.188438
I1027 18:36:09.278796  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0984788 (* 1 = 0.0984788 loss)
I1027 18:36:09.278801  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0899594 (* 1 = 0.0899594 loss)
I1027 18:36:09.278806  5972 solver.cpp:571] Iteration 1320, lr = 0.001
I1027 18:36:21.486496  5972 solver.cpp:242] Iteration 1340, loss = 0.675864
I1027 18:36:21.486534  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.384958 (* 1 = 0.384958 loss)
I1027 18:36:21.486538  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.290906 (* 1 = 0.290906 loss)
I1027 18:36:21.486543  5972 solver.cpp:571] Iteration 1340, lr = 0.001
I1027 18:36:33.727267  5972 solver.cpp:242] Iteration 1360, loss = 0.0437702
I1027 18:36:33.727303  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0315499 (* 1 = 0.0315499 loss)
I1027 18:36:33.727308  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0122202 (* 1 = 0.0122202 loss)
I1027 18:36:33.727313  5972 solver.cpp:571] Iteration 1360, lr = 0.001
I1027 18:36:45.908838  5972 solver.cpp:242] Iteration 1380, loss = 0.265906
I1027 18:36:45.908875  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.101399 (* 1 = 0.101399 loss)
I1027 18:36:45.908881  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.164507 (* 1 = 0.164507 loss)
I1027 18:36:45.908885  5972 solver.cpp:571] Iteration 1380, lr = 0.001
speed: 0.526s / iter
I1027 18:36:58.040204  5972 solver.cpp:242] Iteration 1400, loss = 0.114007
I1027 18:36:58.040241  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0405369 (* 1 = 0.0405369 loss)
I1027 18:36:58.040246  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0734705 (* 1 = 0.0734705 loss)
I1027 18:36:58.040251  5972 solver.cpp:571] Iteration 1400, lr = 0.001
I1027 18:37:10.376669  5972 solver.cpp:242] Iteration 1420, loss = 0.0142677
I1027 18:37:10.376708  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00864464 (* 1 = 0.00864464 loss)
I1027 18:37:10.376713  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00562303 (* 1 = 0.00562303 loss)
I1027 18:37:10.376718  5972 solver.cpp:571] Iteration 1420, lr = 0.001
I1027 18:37:22.738432  5972 solver.cpp:242] Iteration 1440, loss = 0.0584545
I1027 18:37:22.738472  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0265361 (* 1 = 0.0265361 loss)
I1027 18:37:22.738477  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0319184 (* 1 = 0.0319184 loss)
I1027 18:37:22.738482  5972 solver.cpp:571] Iteration 1440, lr = 0.001
I1027 18:37:34.913905  5972 solver.cpp:242] Iteration 1460, loss = 0.283378
I1027 18:37:34.913946  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.156929 (* 1 = 0.156929 loss)
I1027 18:37:34.913951  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.126448 (* 1 = 0.126448 loss)
I1027 18:37:34.913956  5972 solver.cpp:571] Iteration 1460, lr = 0.001
I1027 18:37:47.086176  5972 solver.cpp:242] Iteration 1480, loss = 0.507303
I1027 18:37:47.086216  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.251157 (* 1 = 0.251157 loss)
I1027 18:37:47.086222  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.256146 (* 1 = 0.256146 loss)
I1027 18:37:47.086227  5972 solver.cpp:571] Iteration 1480, lr = 0.001
I1027 18:37:59.303714  5972 solver.cpp:242] Iteration 1500, loss = 0.23777
I1027 18:37:59.303752  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0855013 (* 1 = 0.0855013 loss)
I1027 18:37:59.303757  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.152269 (* 1 = 0.152269 loss)
I1027 18:37:59.303762  5972 solver.cpp:571] Iteration 1500, lr = 0.001
I1027 18:38:11.561954  5972 solver.cpp:242] Iteration 1520, loss = 0.0241309
I1027 18:38:11.561992  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0127499 (* 1 = 0.0127499 loss)
I1027 18:38:11.561997  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0113811 (* 1 = 0.0113811 loss)
I1027 18:38:11.562001  5972 solver.cpp:571] Iteration 1520, lr = 0.001
I1027 18:38:23.833325  5972 solver.cpp:242] Iteration 1540, loss = 0.27477
I1027 18:38:23.833364  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.123033 (* 1 = 0.123033 loss)
I1027 18:38:23.833369  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.151737 (* 1 = 0.151737 loss)
I1027 18:38:23.833372  5972 solver.cpp:571] Iteration 1540, lr = 0.001
I1027 18:38:36.129142  5972 solver.cpp:242] Iteration 1560, loss = 0.08139
I1027 18:38:36.129181  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0151298 (* 1 = 0.0151298 loss)
I1027 18:38:36.129186  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0662602 (* 1 = 0.0662602 loss)
I1027 18:38:36.129190  5972 solver.cpp:571] Iteration 1560, lr = 0.001
I1027 18:38:48.397912  5972 solver.cpp:242] Iteration 1580, loss = 0.366566
I1027 18:38:48.397948  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.155849 (* 1 = 0.155849 loss)
I1027 18:38:48.397953  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.210717 (* 1 = 0.210717 loss)
I1027 18:38:48.397958  5972 solver.cpp:571] Iteration 1580, lr = 0.001
speed: 0.537s / iter
I1027 18:39:00.524174  5972 solver.cpp:242] Iteration 1600, loss = 0.0588266
I1027 18:39:00.524212  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0253875 (* 1 = 0.0253875 loss)
I1027 18:39:00.524216  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0334391 (* 1 = 0.0334391 loss)
I1027 18:39:00.524221  5972 solver.cpp:571] Iteration 1600, lr = 0.001
I1027 18:39:12.609482  5972 solver.cpp:242] Iteration 1620, loss = 0.289548
I1027 18:39:12.609519  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.120365 (* 1 = 0.120365 loss)
I1027 18:39:12.609524  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.169183 (* 1 = 0.169183 loss)
I1027 18:39:12.609529  5972 solver.cpp:571] Iteration 1620, lr = 0.001
I1027 18:39:24.893724  5972 solver.cpp:242] Iteration 1640, loss = 0.464994
I1027 18:39:24.893764  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.175701 (* 1 = 0.175701 loss)
I1027 18:39:24.893769  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.289293 (* 1 = 0.289293 loss)
I1027 18:39:24.893774  5972 solver.cpp:571] Iteration 1640, lr = 0.001
I1027 18:39:37.164559  5972 solver.cpp:242] Iteration 1660, loss = 0.143802
I1027 18:39:37.164598  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0534016 (* 1 = 0.0534016 loss)
I1027 18:39:37.164603  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0904003 (* 1 = 0.0904003 loss)
I1027 18:39:37.164608  5972 solver.cpp:571] Iteration 1660, lr = 0.001
I1027 18:39:49.471456  5972 solver.cpp:242] Iteration 1680, loss = 0.00949644
I1027 18:39:49.471493  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00263373 (* 1 = 0.00263373 loss)
I1027 18:39:49.471496  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00686272 (* 1 = 0.00686272 loss)
I1027 18:39:49.471501  5972 solver.cpp:571] Iteration 1680, lr = 0.001
I1027 18:40:01.796700  5972 solver.cpp:242] Iteration 1700, loss = 0.329754
I1027 18:40:01.796743  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.17831 (* 1 = 0.17831 loss)
I1027 18:40:01.796748  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.151444 (* 1 = 0.151444 loss)
I1027 18:40:01.796752  5972 solver.cpp:571] Iteration 1700, lr = 0.001
I1027 18:40:14.159209  5972 solver.cpp:242] Iteration 1720, loss = 0.346972
I1027 18:40:14.159246  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.17143 (* 1 = 0.17143 loss)
I1027 18:40:14.159251  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.175542 (* 1 = 0.175542 loss)
I1027 18:40:14.159255  5972 solver.cpp:571] Iteration 1720, lr = 0.001
I1027 18:40:26.320956  5972 solver.cpp:242] Iteration 1740, loss = 0.115759
I1027 18:40:26.320993  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0684639 (* 1 = 0.0684639 loss)
I1027 18:40:26.320998  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0472952 (* 1 = 0.0472952 loss)
I1027 18:40:26.321003  5972 solver.cpp:571] Iteration 1740, lr = 0.001
I1027 18:40:38.502588  5972 solver.cpp:242] Iteration 1760, loss = 0.198224
I1027 18:40:38.502624  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0728744 (* 1 = 0.0728744 loss)
I1027 18:40:38.502629  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.12535 (* 1 = 0.12535 loss)
I1027 18:40:38.502635  5972 solver.cpp:571] Iteration 1760, lr = 0.001
I1027 18:40:50.868190  5972 solver.cpp:242] Iteration 1780, loss = 0.105665
I1027 18:40:50.868230  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0407701 (* 1 = 0.0407701 loss)
I1027 18:40:50.868235  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.064895 (* 1 = 0.064895 loss)
I1027 18:40:50.868239  5972 solver.cpp:571] Iteration 1780, lr = 0.001
speed: 0.545s / iter
I1027 18:41:03.113653  5972 solver.cpp:242] Iteration 1800, loss = 0.0724647
I1027 18:41:03.113695  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.018525 (* 1 = 0.018525 loss)
I1027 18:41:03.113701  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0539397 (* 1 = 0.0539397 loss)
I1027 18:41:03.113705  5972 solver.cpp:571] Iteration 1800, lr = 0.001
I1027 18:41:15.365803  5972 solver.cpp:242] Iteration 1820, loss = 0.00984158
I1027 18:41:15.365842  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00527927 (* 1 = 0.00527927 loss)
I1027 18:41:15.365847  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00456231 (* 1 = 0.00456231 loss)
I1027 18:41:15.365851  5972 solver.cpp:571] Iteration 1820, lr = 0.001
I1027 18:41:27.747571  5972 solver.cpp:242] Iteration 1840, loss = 0.0762414
I1027 18:41:27.747608  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0123652 (* 1 = 0.0123652 loss)
I1027 18:41:27.747613  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0638762 (* 1 = 0.0638762 loss)
I1027 18:41:27.747618  5972 solver.cpp:571] Iteration 1840, lr = 0.001
I1027 18:41:40.081182  5972 solver.cpp:242] Iteration 1860, loss = 0.155922
I1027 18:41:40.081218  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0441833 (* 1 = 0.0441833 loss)
I1027 18:41:40.081224  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.111739 (* 1 = 0.111739 loss)
I1027 18:41:40.081229  5972 solver.cpp:571] Iteration 1860, lr = 0.001
I1027 18:41:52.250026  5972 solver.cpp:242] Iteration 1880, loss = 0.028912
I1027 18:41:52.250063  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00813799 (* 1 = 0.00813799 loss)
I1027 18:41:52.250068  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.020774 (* 1 = 0.020774 loss)
I1027 18:41:52.250072  5972 solver.cpp:571] Iteration 1880, lr = 0.001
I1027 18:42:04.502761  5972 solver.cpp:242] Iteration 1900, loss = 0.510553
I1027 18:42:04.502797  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.253267 (* 1 = 0.253267 loss)
I1027 18:42:04.502802  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.257286 (* 1 = 0.257286 loss)
I1027 18:42:04.502806  5972 solver.cpp:571] Iteration 1900, lr = 0.001
I1027 18:42:16.717991  5972 solver.cpp:242] Iteration 1920, loss = 0.0401922
I1027 18:42:16.718031  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0172408 (* 1 = 0.0172408 loss)
I1027 18:42:16.718036  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0229514 (* 1 = 0.0229514 loss)
I1027 18:42:16.718042  5972 solver.cpp:571] Iteration 1920, lr = 0.001
I1027 18:42:28.889562  5972 solver.cpp:242] Iteration 1940, loss = 0.768655
I1027 18:42:28.889602  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.290781 (* 1 = 0.290781 loss)
I1027 18:42:28.889608  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.477874 (* 1 = 0.477874 loss)
I1027 18:42:28.889612  5972 solver.cpp:571] Iteration 1940, lr = 0.001
I1027 18:42:41.287834  5972 solver.cpp:242] Iteration 1960, loss = 0.145625
I1027 18:42:41.287871  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0630073 (* 1 = 0.0630073 loss)
I1027 18:42:41.287876  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0826173 (* 1 = 0.0826173 loss)
I1027 18:42:41.287881  5972 solver.cpp:571] Iteration 1960, lr = 0.001
I1027 18:42:53.386759  5972 solver.cpp:242] Iteration 1980, loss = 0.361158
I1027 18:42:53.386797  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.194392 (* 1 = 0.194392 loss)
I1027 18:42:53.386802  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.166765 (* 1 = 0.166765 loss)
I1027 18:42:53.386806  5972 solver.cpp:571] Iteration 1980, lr = 0.001
speed: 0.552s / iter
I1027 18:43:05.644587  5972 solver.cpp:242] Iteration 2000, loss = 0.0916446
I1027 18:43:05.644625  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0279415 (* 1 = 0.0279415 loss)
I1027 18:43:05.644630  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.063703 (* 1 = 0.063703 loss)
I1027 18:43:05.644634  5972 solver.cpp:571] Iteration 2000, lr = 0.001
I1027 18:43:17.950947  5972 solver.cpp:242] Iteration 2020, loss = 0.0435833
I1027 18:43:17.950985  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0079942 (* 1 = 0.0079942 loss)
I1027 18:43:17.950990  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0355891 (* 1 = 0.0355891 loss)
I1027 18:43:17.950995  5972 solver.cpp:571] Iteration 2020, lr = 0.001
I1027 18:43:30.293985  5972 solver.cpp:242] Iteration 2040, loss = 0.166393
I1027 18:43:30.294020  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557555 (* 1 = 0.0557555 loss)
I1027 18:43:30.294034  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.110637 (* 1 = 0.110637 loss)
I1027 18:43:30.294039  5972 solver.cpp:571] Iteration 2040, lr = 0.001
I1027 18:43:42.599412  5972 solver.cpp:242] Iteration 2060, loss = 0.255985
I1027 18:43:42.599453  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.1011 (* 1 = 0.1011 loss)
I1027 18:43:42.599458  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.154885 (* 1 = 0.154885 loss)
I1027 18:43:42.599463  5972 solver.cpp:571] Iteration 2060, lr = 0.001
I1027 18:43:54.795814  5972 solver.cpp:242] Iteration 2080, loss = 0.675065
I1027 18:43:54.795853  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.301974 (* 1 = 0.301974 loss)
I1027 18:43:54.795858  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.373091 (* 1 = 0.373091 loss)
I1027 18:43:54.795864  5972 solver.cpp:571] Iteration 2080, lr = 0.001
I1027 18:44:06.910681  5972 solver.cpp:242] Iteration 2100, loss = 0.170022
I1027 18:44:06.910719  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.052441 (* 1 = 0.052441 loss)
I1027 18:44:06.910724  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.117581 (* 1 = 0.117581 loss)
I1027 18:44:06.910729  5972 solver.cpp:571] Iteration 2100, lr = 0.001
I1027 18:44:19.275925  5972 solver.cpp:242] Iteration 2120, loss = 0.232903
I1027 18:44:19.275962  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0994803 (* 1 = 0.0994803 loss)
I1027 18:44:19.275967  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.133423 (* 1 = 0.133423 loss)
I1027 18:44:19.275972  5972 solver.cpp:571] Iteration 2120, lr = 0.001
I1027 18:44:31.566294  5972 solver.cpp:242] Iteration 2140, loss = 0.269081
I1027 18:44:31.566332  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0944557 (* 1 = 0.0944557 loss)
I1027 18:44:31.566337  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.174625 (* 1 = 0.174625 loss)
I1027 18:44:31.566341  5972 solver.cpp:571] Iteration 2140, lr = 0.001
I1027 18:44:43.600044  5972 solver.cpp:242] Iteration 2160, loss = 0.111765
I1027 18:44:43.600083  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0676901 (* 1 = 0.0676901 loss)
I1027 18:44:43.600087  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0440753 (* 1 = 0.0440753 loss)
I1027 18:44:43.600092  5972 solver.cpp:571] Iteration 2160, lr = 0.001
I1027 18:44:55.831493  5972 solver.cpp:242] Iteration 2180, loss = 0.0391154
I1027 18:44:55.831532  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00780606 (* 1 = 0.00780606 loss)
I1027 18:44:55.831537  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0313093 (* 1 = 0.0313093 loss)
I1027 18:44:55.831542  5972 solver.cpp:571] Iteration 2180, lr = 0.001
speed: 0.557s / iter
I1027 18:45:08.098522  5972 solver.cpp:242] Iteration 2200, loss = 0.201186
I1027 18:45:08.098561  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.071454 (* 1 = 0.071454 loss)
I1027 18:45:08.098565  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.129732 (* 1 = 0.129732 loss)
I1027 18:45:08.098570  5972 solver.cpp:571] Iteration 2200, lr = 0.001
I1027 18:45:20.485919  5972 solver.cpp:242] Iteration 2220, loss = 0.597343
I1027 18:45:20.485963  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.27046 (* 1 = 0.27046 loss)
I1027 18:45:20.485968  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.326883 (* 1 = 0.326883 loss)
I1027 18:45:20.485973  5972 solver.cpp:571] Iteration 2220, lr = 0.001
I1027 18:45:32.848994  5972 solver.cpp:242] Iteration 2240, loss = 0.239254
I1027 18:45:32.849031  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0736502 (* 1 = 0.0736502 loss)
I1027 18:45:32.849036  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.165604 (* 1 = 0.165604 loss)
I1027 18:45:32.849041  5972 solver.cpp:571] Iteration 2240, lr = 0.001
I1027 18:45:45.316752  5972 solver.cpp:242] Iteration 2260, loss = 0.0581804
I1027 18:45:45.316789  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0267806 (* 1 = 0.0267806 loss)
I1027 18:45:45.316794  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0313998 (* 1 = 0.0313998 loss)
I1027 18:45:45.316799  5972 solver.cpp:571] Iteration 2260, lr = 0.001
I1027 18:45:57.611814  5972 solver.cpp:242] Iteration 2280, loss = 0.116882
I1027 18:45:57.611860  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0426189 (* 1 = 0.0426189 loss)
I1027 18:45:57.611865  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0742633 (* 1 = 0.0742633 loss)
I1027 18:45:57.611871  5972 solver.cpp:571] Iteration 2280, lr = 0.001
I1027 18:46:09.848681  5972 solver.cpp:242] Iteration 2300, loss = 0.0508055
I1027 18:46:09.848717  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0102318 (* 1 = 0.0102318 loss)
I1027 18:46:09.848722  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0405737 (* 1 = 0.0405737 loss)
I1027 18:46:09.848727  5972 solver.cpp:571] Iteration 2300, lr = 0.001
I1027 18:46:22.128435  5972 solver.cpp:242] Iteration 2320, loss = 0.226796
I1027 18:46:22.128475  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0559408 (* 1 = 0.0559408 loss)
I1027 18:46:22.128480  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.170855 (* 1 = 0.170855 loss)
I1027 18:46:22.128485  5972 solver.cpp:571] Iteration 2320, lr = 0.001
I1027 18:46:34.337889  5972 solver.cpp:242] Iteration 2340, loss = 0.160979
I1027 18:46:34.337921  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0680902 (* 1 = 0.0680902 loss)
I1027 18:46:34.337927  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0928889 (* 1 = 0.0928889 loss)
I1027 18:46:34.337931  5972 solver.cpp:571] Iteration 2340, lr = 0.001
I1027 18:46:46.477385  5972 solver.cpp:242] Iteration 2360, loss = 0.360272
I1027 18:46:46.477428  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.116908 (* 1 = 0.116908 loss)
I1027 18:46:46.477443  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.243365 (* 1 = 0.243365 loss)
I1027 18:46:46.477449  5972 solver.cpp:571] Iteration 2360, lr = 0.001
I1027 18:46:58.623975  5972 solver.cpp:242] Iteration 2380, loss = 0.188923
I1027 18:46:58.624013  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0797648 (* 1 = 0.0797648 loss)
I1027 18:46:58.624018  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.109158 (* 1 = 0.109158 loss)
I1027 18:46:58.624023  5972 solver.cpp:571] Iteration 2380, lr = 0.001
speed: 0.562s / iter
I1027 18:47:10.850174  5972 solver.cpp:242] Iteration 2400, loss = 0.137791
I1027 18:47:10.850214  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0333973 (* 1 = 0.0333973 loss)
I1027 18:47:10.850219  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.104394 (* 1 = 0.104394 loss)
I1027 18:47:10.850222  5972 solver.cpp:571] Iteration 2400, lr = 0.001
I1027 18:47:23.178462  5972 solver.cpp:242] Iteration 2420, loss = 0.220839
I1027 18:47:23.178496  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.133683 (* 1 = 0.133683 loss)
I1027 18:47:23.178501  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0871557 (* 1 = 0.0871557 loss)
I1027 18:47:23.178506  5972 solver.cpp:571] Iteration 2420, lr = 0.001
I1027 18:47:35.200599  5972 solver.cpp:242] Iteration 2440, loss = 0.0505932
I1027 18:47:35.200637  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00694694 (* 1 = 0.00694694 loss)
I1027 18:47:35.200642  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0436462 (* 1 = 0.0436462 loss)
I1027 18:47:35.200646  5972 solver.cpp:571] Iteration 2440, lr = 0.001
I1027 18:47:47.276154  5972 solver.cpp:242] Iteration 2460, loss = 0.123813
I1027 18:47:47.276191  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0281338 (* 1 = 0.0281338 loss)
I1027 18:47:47.276196  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0956787 (* 1 = 0.0956787 loss)
I1027 18:47:47.276201  5972 solver.cpp:571] Iteration 2460, lr = 0.001
I1027 18:47:59.432072  5972 solver.cpp:242] Iteration 2480, loss = 0.0747807
I1027 18:47:59.432109  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0286034 (* 1 = 0.0286034 loss)
I1027 18:47:59.432114  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0461773 (* 1 = 0.0461773 loss)
I1027 18:47:59.432118  5972 solver.cpp:571] Iteration 2480, lr = 0.001
I1027 18:48:11.616024  5972 solver.cpp:242] Iteration 2500, loss = 0.264183
I1027 18:48:11.616061  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.101725 (* 1 = 0.101725 loss)
I1027 18:48:11.616066  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.162458 (* 1 = 0.162458 loss)
I1027 18:48:11.616070  5972 solver.cpp:571] Iteration 2500, lr = 0.001
I1027 18:48:23.778519  5972 solver.cpp:242] Iteration 2520, loss = 0.101905
I1027 18:48:23.778556  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0398744 (* 1 = 0.0398744 loss)
I1027 18:48:23.778561  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0620303 (* 1 = 0.0620303 loss)
I1027 18:48:23.778566  5972 solver.cpp:571] Iteration 2520, lr = 0.001
I1027 18:48:35.996875  5972 solver.cpp:242] Iteration 2540, loss = 0.236693
I1027 18:48:35.996917  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.087236 (* 1 = 0.087236 loss)
I1027 18:48:35.996922  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149457 (* 1 = 0.149457 loss)
I1027 18:48:35.996927  5972 solver.cpp:571] Iteration 2540, lr = 0.001
I1027 18:48:48.054209  5972 solver.cpp:242] Iteration 2560, loss = 0.319191
I1027 18:48:48.054251  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.145095 (* 1 = 0.145095 loss)
I1027 18:48:48.054256  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.174097 (* 1 = 0.174097 loss)
I1027 18:48:48.054260  5972 solver.cpp:571] Iteration 2560, lr = 0.001
I1027 18:49:00.250437  5972 solver.cpp:242] Iteration 2580, loss = 0.164957
I1027 18:49:00.250479  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0913556 (* 1 = 0.0913556 loss)
I1027 18:49:00.250484  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.073601 (* 1 = 0.073601 loss)
I1027 18:49:00.250489  5972 solver.cpp:571] Iteration 2580, lr = 0.001
speed: 0.566s / iter
I1027 18:49:12.536216  5972 solver.cpp:242] Iteration 2600, loss = 0.0459598
I1027 18:49:12.536254  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0156462 (* 1 = 0.0156462 loss)
I1027 18:49:12.536259  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0303136 (* 1 = 0.0303136 loss)
I1027 18:49:12.536263  5972 solver.cpp:571] Iteration 2600, lr = 0.001
I1027 18:49:24.760066  5972 solver.cpp:242] Iteration 2620, loss = 0.201255
I1027 18:49:24.760104  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0881381 (* 1 = 0.0881381 loss)
I1027 18:49:24.760109  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113117 (* 1 = 0.113117 loss)
I1027 18:49:24.760114  5972 solver.cpp:571] Iteration 2620, lr = 0.001
I1027 18:49:37.070242  5972 solver.cpp:242] Iteration 2640, loss = 0.262586
I1027 18:49:37.070279  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.114409 (* 1 = 0.114409 loss)
I1027 18:49:37.070284  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.148177 (* 1 = 0.148177 loss)
I1027 18:49:37.070299  5972 solver.cpp:571] Iteration 2640, lr = 0.001
I1027 18:49:49.422821  5972 solver.cpp:242] Iteration 2660, loss = 0.547967
I1027 18:49:49.422858  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.265877 (* 1 = 0.265877 loss)
I1027 18:49:49.422863  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.28209 (* 1 = 0.28209 loss)
I1027 18:49:49.422868  5972 solver.cpp:571] Iteration 2660, lr = 0.001
I1027 18:50:01.516233  5972 solver.cpp:242] Iteration 2680, loss = 0.0957487
I1027 18:50:01.516268  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0314254 (* 1 = 0.0314254 loss)
I1027 18:50:01.516273  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0643234 (* 1 = 0.0643234 loss)
I1027 18:50:01.516278  5972 solver.cpp:571] Iteration 2680, lr = 0.001
I1027 18:50:13.684159  5972 solver.cpp:242] Iteration 2700, loss = 0.347938
I1027 18:50:13.684195  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.138861 (* 1 = 0.138861 loss)
I1027 18:50:13.684200  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.209077 (* 1 = 0.209077 loss)
I1027 18:50:13.684203  5972 solver.cpp:571] Iteration 2700, lr = 0.001
I1027 18:50:25.980782  5972 solver.cpp:242] Iteration 2720, loss = 0.0923969
I1027 18:50:25.980872  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0203639 (* 1 = 0.0203639 loss)
I1027 18:50:25.980878  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0720331 (* 1 = 0.0720331 loss)
I1027 18:50:25.980883  5972 solver.cpp:571] Iteration 2720, lr = 0.001
I1027 18:50:38.309774  5972 solver.cpp:242] Iteration 2740, loss = 0.289871
I1027 18:50:38.309814  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.146085 (* 1 = 0.146085 loss)
I1027 18:50:38.309819  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.143787 (* 1 = 0.143787 loss)
I1027 18:50:38.309824  5972 solver.cpp:571] Iteration 2740, lr = 0.001
I1027 18:50:50.500010  5972 solver.cpp:242] Iteration 2760, loss = 0.249638
I1027 18:50:50.500051  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0609637 (* 1 = 0.0609637 loss)
I1027 18:50:50.500056  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.188674 (* 1 = 0.188674 loss)
I1027 18:50:50.500061  5972 solver.cpp:571] Iteration 2760, lr = 0.001
I1027 18:51:02.741757  5972 solver.cpp:242] Iteration 2780, loss = 0.0849194
I1027 18:51:02.741796  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0392083 (* 1 = 0.0392083 loss)
I1027 18:51:02.741801  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0457111 (* 1 = 0.0457111 loss)
I1027 18:51:02.741806  5972 solver.cpp:571] Iteration 2780, lr = 0.001
speed: 0.569s / iter
I1027 18:51:15.083921  5972 solver.cpp:242] Iteration 2800, loss = 0.12741
I1027 18:51:15.083958  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0611747 (* 1 = 0.0611747 loss)
I1027 18:51:15.083963  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0662355 (* 1 = 0.0662355 loss)
I1027 18:51:15.083968  5972 solver.cpp:571] Iteration 2800, lr = 0.001
I1027 18:51:27.481902  5972 solver.cpp:242] Iteration 2820, loss = 0.251803
I1027 18:51:27.481940  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0981991 (* 1 = 0.0981991 loss)
I1027 18:51:27.481945  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.153604 (* 1 = 0.153604 loss)
I1027 18:51:27.481950  5972 solver.cpp:571] Iteration 2820, lr = 0.001
I1027 18:51:39.730026  5972 solver.cpp:242] Iteration 2840, loss = 0.226019
I1027 18:51:39.730062  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.110243 (* 1 = 0.110243 loss)
I1027 18:51:39.730067  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.115776 (* 1 = 0.115776 loss)
I1027 18:51:39.730072  5972 solver.cpp:571] Iteration 2840, lr = 0.001
I1027 18:51:52.094717  5972 solver.cpp:242] Iteration 2860, loss = 0.534853
I1027 18:51:52.094758  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.252151 (* 1 = 0.252151 loss)
I1027 18:51:52.094763  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.282702 (* 1 = 0.282702 loss)
I1027 18:51:52.094768  5972 solver.cpp:571] Iteration 2860, lr = 0.001
I1027 18:52:04.281175  5972 solver.cpp:242] Iteration 2880, loss = 0.0343091
I1027 18:52:04.281216  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0258195 (* 1 = 0.0258195 loss)
I1027 18:52:04.281221  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00848956 (* 1 = 0.00848956 loss)
I1027 18:52:04.281226  5972 solver.cpp:571] Iteration 2880, lr = 0.001
I1027 18:52:16.506348  5972 solver.cpp:242] Iteration 2900, loss = 0.171414
I1027 18:52:16.506386  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0512476 (* 1 = 0.0512476 loss)
I1027 18:52:16.506391  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.120167 (* 1 = 0.120167 loss)
I1027 18:52:16.506394  5972 solver.cpp:571] Iteration 2900, lr = 0.001
I1027 18:52:28.831113  5972 solver.cpp:242] Iteration 2920, loss = 0.0169632
I1027 18:52:28.831151  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00638277 (* 1 = 0.00638277 loss)
I1027 18:52:28.831156  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0105804 (* 1 = 0.0105804 loss)
I1027 18:52:28.831161  5972 solver.cpp:571] Iteration 2920, lr = 0.001
I1027 18:52:41.060508  5972 solver.cpp:242] Iteration 2940, loss = 0.170857
I1027 18:52:41.060546  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0546201 (* 1 = 0.0546201 loss)
I1027 18:52:41.060551  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.116237 (* 1 = 0.116237 loss)
I1027 18:52:41.060555  5972 solver.cpp:571] Iteration 2940, lr = 0.001
I1027 18:52:53.253350  5972 solver.cpp:242] Iteration 2960, loss = 0.307365
I1027 18:52:53.253386  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.108492 (* 1 = 0.108492 loss)
I1027 18:52:53.253391  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.198873 (* 1 = 0.198873 loss)
I1027 18:52:53.253396  5972 solver.cpp:571] Iteration 2960, lr = 0.001
I1027 18:53:05.453373  5972 solver.cpp:242] Iteration 2980, loss = 0.293096
I1027 18:53:05.453411  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.106428 (* 1 = 0.106428 loss)
I1027 18:53:05.453416  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.186668 (* 1 = 0.186668 loss)
I1027 18:53:05.453420  5972 solver.cpp:571] Iteration 2980, lr = 0.001
speed: 0.572s / iter
I1027 18:53:17.695348  5972 solver.cpp:242] Iteration 3000, loss = 0.255157
I1027 18:53:17.695384  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0830658 (* 1 = 0.0830658 loss)
I1027 18:53:17.695389  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.172091 (* 1 = 0.172091 loss)
I1027 18:53:17.695394  5972 solver.cpp:571] Iteration 3000, lr = 0.001
I1027 18:53:29.914108  5972 solver.cpp:242] Iteration 3020, loss = 0.269667
I1027 18:53:29.914152  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.121066 (* 1 = 0.121066 loss)
I1027 18:53:29.914160  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.148602 (* 1 = 0.148602 loss)
I1027 18:53:29.914165  5972 solver.cpp:571] Iteration 3020, lr = 0.001
I1027 18:53:42.204493  5972 solver.cpp:242] Iteration 3040, loss = 0.0999839
I1027 18:53:42.204535  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0275708 (* 1 = 0.0275708 loss)
I1027 18:53:42.204541  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0724131 (* 1 = 0.0724131 loss)
I1027 18:53:42.204546  5972 solver.cpp:571] Iteration 3040, lr = 0.001
I1027 18:53:54.483127  5972 solver.cpp:242] Iteration 3060, loss = 0.0654211
I1027 18:53:54.483165  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0377265 (* 1 = 0.0377265 loss)
I1027 18:53:54.483171  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0276946 (* 1 = 0.0276946 loss)
I1027 18:53:54.483176  5972 solver.cpp:571] Iteration 3060, lr = 0.001
I1027 18:54:06.672026  5972 solver.cpp:242] Iteration 3080, loss = 0.298425
I1027 18:54:06.672065  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.10567 (* 1 = 0.10567 loss)
I1027 18:54:06.672070  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.192755 (* 1 = 0.192755 loss)
I1027 18:54:06.672075  5972 solver.cpp:571] Iteration 3080, lr = 0.001
I1027 18:54:18.875227  5972 solver.cpp:242] Iteration 3100, loss = 0.0748609
I1027 18:54:18.875265  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0379089 (* 1 = 0.0379089 loss)
I1027 18:54:18.875270  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.036952 (* 1 = 0.036952 loss)
I1027 18:54:18.875275  5972 solver.cpp:571] Iteration 3100, lr = 0.001
I1027 18:54:31.078660  5972 solver.cpp:242] Iteration 3120, loss = 0.168014
I1027 18:54:31.078698  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0684965 (* 1 = 0.0684965 loss)
I1027 18:54:31.078703  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.099518 (* 1 = 0.099518 loss)
I1027 18:54:31.078708  5972 solver.cpp:571] Iteration 3120, lr = 0.001
I1027 18:54:43.263770  5972 solver.cpp:242] Iteration 3140, loss = 0.153389
I1027 18:54:43.263806  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0566775 (* 1 = 0.0566775 loss)
I1027 18:54:43.263811  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0967115 (* 1 = 0.0967115 loss)
I1027 18:54:43.263816  5972 solver.cpp:571] Iteration 3140, lr = 0.001
I1027 18:54:55.458870  5972 solver.cpp:242] Iteration 3160, loss = 0.113141
I1027 18:54:55.458909  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.028721 (* 1 = 0.028721 loss)
I1027 18:54:55.458914  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0844199 (* 1 = 0.0844199 loss)
I1027 18:54:55.458917  5972 solver.cpp:571] Iteration 3160, lr = 0.001
I1027 18:55:07.716295  5972 solver.cpp:242] Iteration 3180, loss = 0.366518
I1027 18:55:07.716330  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.1556 (* 1 = 0.1556 loss)
I1027 18:55:07.716334  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.210918 (* 1 = 0.210918 loss)
I1027 18:55:07.716338  5972 solver.cpp:571] Iteration 3180, lr = 0.001
speed: 0.574s / iter
I1027 18:55:19.933071  5972 solver.cpp:242] Iteration 3200, loss = 0.297416
I1027 18:55:19.933107  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.131075 (* 1 = 0.131075 loss)
I1027 18:55:19.933112  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.166342 (* 1 = 0.166342 loss)
I1027 18:55:19.933117  5972 solver.cpp:571] Iteration 3200, lr = 0.001
I1027 18:55:32.149518  5972 solver.cpp:242] Iteration 3220, loss = 0.382181
I1027 18:55:32.149556  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.153442 (* 1 = 0.153442 loss)
I1027 18:55:32.149561  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.228739 (* 1 = 0.228739 loss)
I1027 18:55:32.149565  5972 solver.cpp:571] Iteration 3220, lr = 0.001
I1027 18:55:44.428786  5972 solver.cpp:242] Iteration 3240, loss = 0.191667
I1027 18:55:44.428827  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0969804 (* 1 = 0.0969804 loss)
I1027 18:55:44.428831  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0946868 (* 1 = 0.0946868 loss)
I1027 18:55:44.428836  5972 solver.cpp:571] Iteration 3240, lr = 0.001
I1027 18:55:56.765009  5972 solver.cpp:242] Iteration 3260, loss = 0.231083
I1027 18:55:56.765051  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0978042 (* 1 = 0.0978042 loss)
I1027 18:55:56.765056  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.133279 (* 1 = 0.133279 loss)
I1027 18:55:56.765061  5972 solver.cpp:571] Iteration 3260, lr = 0.001
I1027 18:56:08.801811  5972 solver.cpp:242] Iteration 3280, loss = 0.313049
I1027 18:56:08.801854  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.124001 (* 1 = 0.124001 loss)
I1027 18:56:08.801862  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.189048 (* 1 = 0.189048 loss)
I1027 18:56:08.801868  5972 solver.cpp:571] Iteration 3280, lr = 0.001
I1027 18:56:21.170616  5972 solver.cpp:242] Iteration 3300, loss = 0.132769
I1027 18:56:21.170653  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0204503 (* 1 = 0.0204503 loss)
I1027 18:56:21.170658  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.112319 (* 1 = 0.112319 loss)
I1027 18:56:21.170662  5972 solver.cpp:571] Iteration 3300, lr = 0.001
I1027 18:56:33.527235  5972 solver.cpp:242] Iteration 3320, loss = 0.0481383
I1027 18:56:33.527272  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0116851 (* 1 = 0.0116851 loss)
I1027 18:56:33.527277  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0364533 (* 1 = 0.0364533 loss)
I1027 18:56:33.527282  5972 solver.cpp:571] Iteration 3320, lr = 0.001
I1027 18:56:45.823935  5972 solver.cpp:242] Iteration 3340, loss = 0.0398443
I1027 18:56:45.823972  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0144225 (* 1 = 0.0144225 loss)
I1027 18:56:45.823977  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0254218 (* 1 = 0.0254218 loss)
I1027 18:56:45.823982  5972 solver.cpp:571] Iteration 3340, lr = 0.001
I1027 18:56:58.023108  5972 solver.cpp:242] Iteration 3360, loss = 0.43357
I1027 18:56:58.023144  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.115425 (* 1 = 0.115425 loss)
I1027 18:56:58.023149  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.318145 (* 1 = 0.318145 loss)
I1027 18:56:58.023154  5972 solver.cpp:571] Iteration 3360, lr = 0.001
I1027 18:57:10.301256  5972 solver.cpp:242] Iteration 3380, loss = 0.246826
I1027 18:57:10.301293  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0787734 (* 1 = 0.0787734 loss)
I1027 18:57:10.301298  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.168053 (* 1 = 0.168053 loss)
I1027 18:57:10.301303  5972 solver.cpp:571] Iteration 3380, lr = 0.001
speed: 0.577s / iter
I1027 18:57:22.508337  5972 solver.cpp:242] Iteration 3400, loss = 0.195869
I1027 18:57:22.508378  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0676628 (* 1 = 0.0676628 loss)
I1027 18:57:22.508383  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.128207 (* 1 = 0.128207 loss)
I1027 18:57:22.508388  5972 solver.cpp:571] Iteration 3400, lr = 0.001
I1027 18:57:34.726038  5972 solver.cpp:242] Iteration 3420, loss = 0.737771
I1027 18:57:34.726081  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.256221 (* 1 = 0.256221 loss)
I1027 18:57:34.726086  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.48155 (* 1 = 0.48155 loss)
I1027 18:57:34.726091  5972 solver.cpp:571] Iteration 3420, lr = 0.001
I1027 18:57:47.119484  5972 solver.cpp:242] Iteration 3440, loss = 0.153634
I1027 18:57:47.119524  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0621635 (* 1 = 0.0621635 loss)
I1027 18:57:47.119529  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.091471 (* 1 = 0.091471 loss)
I1027 18:57:47.119534  5972 solver.cpp:571] Iteration 3440, lr = 0.001
I1027 18:57:59.564774  5972 solver.cpp:242] Iteration 3460, loss = 0.504118
I1027 18:57:59.564811  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.283042 (* 1 = 0.283042 loss)
I1027 18:57:59.564815  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.221076 (* 1 = 0.221076 loss)
I1027 18:57:59.564821  5972 solver.cpp:571] Iteration 3460, lr = 0.001
I1027 18:58:11.860229  5972 solver.cpp:242] Iteration 3480, loss = 0.307173
I1027 18:58:11.860270  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0859431 (* 1 = 0.0859431 loss)
I1027 18:58:11.860275  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.22123 (* 1 = 0.22123 loss)
I1027 18:58:11.860280  5972 solver.cpp:571] Iteration 3480, lr = 0.001
I1027 18:58:24.224128  5972 solver.cpp:242] Iteration 3500, loss = 0.114078
I1027 18:58:24.224169  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0298601 (* 1 = 0.0298601 loss)
I1027 18:58:24.224174  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0842174 (* 1 = 0.0842174 loss)
I1027 18:58:24.224177  5972 solver.cpp:571] Iteration 3500, lr = 0.001
I1027 18:58:36.385335  5972 solver.cpp:242] Iteration 3520, loss = 0.243723
I1027 18:58:36.385375  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.116398 (* 1 = 0.116398 loss)
I1027 18:58:36.385380  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.127325 (* 1 = 0.127325 loss)
I1027 18:58:36.385383  5972 solver.cpp:571] Iteration 3520, lr = 0.001
I1027 18:58:48.576023  5972 solver.cpp:242] Iteration 3540, loss = 0.283204
I1027 18:58:48.576071  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.109528 (* 1 = 0.109528 loss)
I1027 18:58:48.576076  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.173676 (* 1 = 0.173676 loss)
I1027 18:58:48.576079  5972 solver.cpp:571] Iteration 3540, lr = 0.001
I1027 18:59:00.944177  5972 solver.cpp:242] Iteration 3560, loss = 0.216279
I1027 18:59:00.944206  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.103227 (* 1 = 0.103227 loss)
I1027 18:59:00.944211  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113052 (* 1 = 0.113052 loss)
I1027 18:59:00.944216  5972 solver.cpp:571] Iteration 3560, lr = 0.001
I1027 18:59:13.254509  5972 solver.cpp:242] Iteration 3580, loss = 0.732655
I1027 18:59:13.254535  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.380128 (* 1 = 0.380128 loss)
I1027 18:59:13.254540  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.352527 (* 1 = 0.352527 loss)
I1027 18:59:13.254544  5972 solver.cpp:571] Iteration 3580, lr = 0.001
speed: 0.579s / iter
I1027 18:59:25.434206  5972 solver.cpp:242] Iteration 3600, loss = 0.0178328
I1027 18:59:25.434243  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00684185 (* 1 = 0.00684185 loss)
I1027 18:59:25.434247  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0109909 (* 1 = 0.0109909 loss)
I1027 18:59:25.434252  5972 solver.cpp:571] Iteration 3600, lr = 0.001
I1027 18:59:37.689688  5972 solver.cpp:242] Iteration 3620, loss = 0.200667
I1027 18:59:37.689725  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0727083 (* 1 = 0.0727083 loss)
I1027 18:59:37.689730  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.127958 (* 1 = 0.127958 loss)
I1027 18:59:37.689735  5972 solver.cpp:571] Iteration 3620, lr = 0.001
I1027 18:59:49.946734  5972 solver.cpp:242] Iteration 3640, loss = 0.138763
I1027 18:59:49.946777  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0249026 (* 1 = 0.0249026 loss)
I1027 18:59:49.946784  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113861 (* 1 = 0.113861 loss)
I1027 18:59:49.946787  5972 solver.cpp:571] Iteration 3640, lr = 0.001
I1027 19:00:02.331384  5972 solver.cpp:242] Iteration 3660, loss = 0.00739632
I1027 19:00:02.331424  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00104145 (* 1 = 0.00104145 loss)
I1027 19:00:02.331429  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00635486 (* 1 = 0.00635486 loss)
I1027 19:00:02.331434  5972 solver.cpp:571] Iteration 3660, lr = 0.001
I1027 19:00:14.483186  5972 solver.cpp:242] Iteration 3680, loss = 0.0636665
I1027 19:00:14.483227  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0431164 (* 1 = 0.0431164 loss)
I1027 19:00:14.483232  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0205501 (* 1 = 0.0205501 loss)
I1027 19:00:14.483237  5972 solver.cpp:571] Iteration 3680, lr = 0.001
I1027 19:00:26.683239  5972 solver.cpp:242] Iteration 3700, loss = 0.125529
I1027 19:00:26.683277  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0362905 (* 1 = 0.0362905 loss)
I1027 19:00:26.683282  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0892389 (* 1 = 0.0892389 loss)
I1027 19:00:26.683286  5972 solver.cpp:571] Iteration 3700, lr = 0.001
I1027 19:00:38.949375  5972 solver.cpp:242] Iteration 3720, loss = 0.274857
I1027 19:00:38.949414  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0963512 (* 1 = 0.0963512 loss)
I1027 19:00:38.949419  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.178506 (* 1 = 0.178506 loss)
I1027 19:00:38.949424  5972 solver.cpp:571] Iteration 3720, lr = 0.001
I1027 19:00:51.059689  5972 solver.cpp:242] Iteration 3740, loss = 0.0897779
I1027 19:00:51.059726  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0491879 (* 1 = 0.0491879 loss)
I1027 19:00:51.059731  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.04059 (* 1 = 0.04059 loss)
I1027 19:00:51.059736  5972 solver.cpp:571] Iteration 3740, lr = 0.001
I1027 19:01:03.347050  5972 solver.cpp:242] Iteration 3760, loss = 0.0143748
I1027 19:01:03.347087  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00872274 (* 1 = 0.00872274 loss)
I1027 19:01:03.347092  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00565202 (* 1 = 0.00565202 loss)
I1027 19:01:03.347096  5972 solver.cpp:571] Iteration 3760, lr = 0.001
I1027 19:01:15.684144  5972 solver.cpp:242] Iteration 3780, loss = 0.479896
I1027 19:01:15.684185  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.208734 (* 1 = 0.208734 loss)
I1027 19:01:15.684190  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.271161 (* 1 = 0.271161 loss)
I1027 19:01:15.684195  5972 solver.cpp:571] Iteration 3780, lr = 0.001
speed: 0.580s / iter
I1027 19:01:27.948071  5972 solver.cpp:242] Iteration 3800, loss = 0.0271161
I1027 19:01:27.948112  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.012358 (* 1 = 0.012358 loss)
I1027 19:01:27.948118  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0147581 (* 1 = 0.0147581 loss)
I1027 19:01:27.948123  5972 solver.cpp:571] Iteration 3800, lr = 0.001
I1027 19:01:40.181381  5972 solver.cpp:242] Iteration 3820, loss = 0.159322
I1027 19:01:40.181421  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0662286 (* 1 = 0.0662286 loss)
I1027 19:01:40.181426  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0930932 (* 1 = 0.0930932 loss)
I1027 19:01:40.181430  5972 solver.cpp:571] Iteration 3820, lr = 0.001
I1027 19:01:52.415735  5972 solver.cpp:242] Iteration 3840, loss = 0.0491922
I1027 19:01:52.415772  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0128418 (* 1 = 0.0128418 loss)
I1027 19:01:52.415777  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0363504 (* 1 = 0.0363504 loss)
I1027 19:01:52.415781  5972 solver.cpp:571] Iteration 3840, lr = 0.001
I1027 19:02:04.474776  5972 solver.cpp:242] Iteration 3860, loss = 0.0747128
I1027 19:02:04.474814  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0188683 (* 1 = 0.0188683 loss)
I1027 19:02:04.474819  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0558446 (* 1 = 0.0558446 loss)
I1027 19:02:04.474824  5972 solver.cpp:571] Iteration 3860, lr = 0.001
I1027 19:02:16.562495  5972 solver.cpp:242] Iteration 3880, loss = 0.0576583
I1027 19:02:16.562532  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0218635 (* 1 = 0.0218635 loss)
I1027 19:02:16.562537  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0357948 (* 1 = 0.0357948 loss)
I1027 19:02:16.562541  5972 solver.cpp:571] Iteration 3880, lr = 0.001
I1027 19:02:28.675741  5972 solver.cpp:242] Iteration 3900, loss = 0.179762
I1027 19:02:28.675781  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834337 (* 1 = 0.0834337 loss)
I1027 19:02:28.675786  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0963283 (* 1 = 0.0963283 loss)
I1027 19:02:28.675789  5972 solver.cpp:571] Iteration 3900, lr = 0.001
I1027 19:02:41.044793  5972 solver.cpp:242] Iteration 3920, loss = 0.065729
I1027 19:02:41.044831  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0331922 (* 1 = 0.0331922 loss)
I1027 19:02:41.044836  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0325368 (* 1 = 0.0325368 loss)
I1027 19:02:41.044842  5972 solver.cpp:571] Iteration 3920, lr = 0.001
I1027 19:02:53.243849  5972 solver.cpp:242] Iteration 3940, loss = 0.317248
I1027 19:02:53.243885  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.149436 (* 1 = 0.149436 loss)
I1027 19:02:53.243890  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.167812 (* 1 = 0.167812 loss)
I1027 19:02:53.243893  5972 solver.cpp:571] Iteration 3940, lr = 0.001
I1027 19:03:05.430444  5972 solver.cpp:242] Iteration 3960, loss = 0.0218572
I1027 19:03:05.430480  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00313884 (* 1 = 0.00313884 loss)
I1027 19:03:05.430485  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0187183 (* 1 = 0.0187183 loss)
I1027 19:03:05.430490  5972 solver.cpp:571] Iteration 3960, lr = 0.001
I1027 19:03:17.751024  5972 solver.cpp:242] Iteration 3980, loss = 0.197801
I1027 19:03:17.751065  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0795305 (* 1 = 0.0795305 loss)
I1027 19:03:17.751070  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.11827 (* 1 = 0.11827 loss)
I1027 19:03:17.751075  5972 solver.cpp:571] Iteration 3980, lr = 0.001
speed: 0.582s / iter
I1027 19:03:29.990222  5972 solver.cpp:242] Iteration 4000, loss = 0.171126
I1027 19:03:29.990263  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0915465 (* 1 = 0.0915465 loss)
I1027 19:03:29.990268  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.079579 (* 1 = 0.079579 loss)
I1027 19:03:29.990273  5972 solver.cpp:571] Iteration 4000, lr = 0.001
I1027 19:03:42.281189  5972 solver.cpp:242] Iteration 4020, loss = 0.138359
I1027 19:03:42.281227  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.026321 (* 1 = 0.026321 loss)
I1027 19:03:42.281232  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.112038 (* 1 = 0.112038 loss)
I1027 19:03:42.281237  5972 solver.cpp:571] Iteration 4020, lr = 0.001
I1027 19:03:54.590411  5972 solver.cpp:242] Iteration 4040, loss = 0.00769723
I1027 19:03:54.590450  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00217057 (* 1 = 0.00217057 loss)
I1027 19:03:54.590464  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00552666 (* 1 = 0.00552666 loss)
I1027 19:03:54.590468  5972 solver.cpp:571] Iteration 4040, lr = 0.001
I1027 19:04:06.879835  5972 solver.cpp:242] Iteration 4060, loss = 0.0664959
I1027 19:04:06.879884  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00929968 (* 1 = 0.00929968 loss)
I1027 19:04:06.879890  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0571962 (* 1 = 0.0571962 loss)
I1027 19:04:06.879894  5972 solver.cpp:571] Iteration 4060, lr = 0.001
I1027 19:04:19.013128  5972 solver.cpp:242] Iteration 4080, loss = 0.709812
I1027 19:04:19.013166  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.333281 (* 1 = 0.333281 loss)
I1027 19:04:19.013171  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.376531 (* 1 = 0.376531 loss)
I1027 19:04:19.013175  5972 solver.cpp:571] Iteration 4080, lr = 0.001
I1027 19:04:31.229169  5972 solver.cpp:242] Iteration 4100, loss = 0.677334
I1027 19:04:31.229207  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.266175 (* 1 = 0.266175 loss)
I1027 19:04:31.229212  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.411159 (* 1 = 0.411159 loss)
I1027 19:04:31.229216  5972 solver.cpp:571] Iteration 4100, lr = 0.001
I1027 19:04:43.582149  5972 solver.cpp:242] Iteration 4120, loss = 0.0717366
I1027 19:04:43.582190  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0219981 (* 1 = 0.0219981 loss)
I1027 19:04:43.582196  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0497386 (* 1 = 0.0497386 loss)
I1027 19:04:43.582201  5972 solver.cpp:571] Iteration 4120, lr = 0.001
I1027 19:04:55.904976  5972 solver.cpp:242] Iteration 4140, loss = 0.213552
I1027 19:04:55.905015  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.087297 (* 1 = 0.087297 loss)
I1027 19:04:55.905020  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.126255 (* 1 = 0.126255 loss)
I1027 19:04:55.905025  5972 solver.cpp:571] Iteration 4140, lr = 0.001
I1027 19:05:08.383749  5972 solver.cpp:242] Iteration 4160, loss = 0.207378
I1027 19:05:08.383787  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.105855 (* 1 = 0.105855 loss)
I1027 19:05:08.383792  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.101523 (* 1 = 0.101523 loss)
I1027 19:05:08.383796  5972 solver.cpp:571] Iteration 4160, lr = 0.001
I1027 19:05:20.482990  5972 solver.cpp:242] Iteration 4180, loss = 0.00885566
I1027 19:05:20.483026  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00114866 (* 1 = 0.00114866 loss)
I1027 19:05:20.483031  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.007707 (* 1 = 0.007707 loss)
I1027 19:05:20.483036  5972 solver.cpp:571] Iteration 4180, lr = 0.001
speed: 0.583s / iter
I1027 19:05:32.593418  5972 solver.cpp:242] Iteration 4200, loss = 0.160135
I1027 19:05:32.593456  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0523212 (* 1 = 0.0523212 loss)
I1027 19:05:32.593461  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.107813 (* 1 = 0.107813 loss)
I1027 19:05:32.593466  5972 solver.cpp:571] Iteration 4200, lr = 0.001
I1027 19:05:44.734340  5972 solver.cpp:242] Iteration 4220, loss = 0.216365
I1027 19:05:44.734380  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0614398 (* 1 = 0.0614398 loss)
I1027 19:05:44.734385  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.154926 (* 1 = 0.154926 loss)
I1027 19:05:44.734388  5972 solver.cpp:571] Iteration 4220, lr = 0.001
I1027 19:05:56.953160  5972 solver.cpp:242] Iteration 4240, loss = 0.603023
I1027 19:05:56.953197  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.296458 (* 1 = 0.296458 loss)
I1027 19:05:56.953202  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.306565 (* 1 = 0.306565 loss)
I1027 19:05:56.953207  5972 solver.cpp:571] Iteration 4240, lr = 0.001
I1027 19:06:09.133447  5972 solver.cpp:242] Iteration 4260, loss = 0.117376
I1027 19:06:09.133486  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0454234 (* 1 = 0.0454234 loss)
I1027 19:06:09.133491  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0719524 (* 1 = 0.0719524 loss)
I1027 19:06:09.133494  5972 solver.cpp:571] Iteration 4260, lr = 0.001
I1027 19:06:21.436168  5972 solver.cpp:242] Iteration 4280, loss = 0.126731
I1027 19:06:21.436219  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0369575 (* 1 = 0.0369575 loss)
I1027 19:06:21.436224  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0897737 (* 1 = 0.0897737 loss)
I1027 19:06:21.436230  5972 solver.cpp:571] Iteration 4280, lr = 0.001
I1027 19:06:33.807890  5972 solver.cpp:242] Iteration 4300, loss = 0.0556404
I1027 19:06:33.807931  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.025886 (* 1 = 0.025886 loss)
I1027 19:06:33.807937  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0297544 (* 1 = 0.0297544 loss)
I1027 19:06:33.807941  5972 solver.cpp:571] Iteration 4300, lr = 0.001
I1027 19:06:46.005861  5972 solver.cpp:242] Iteration 4320, loss = 0.154361
I1027 19:06:46.005898  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0753074 (* 1 = 0.0753074 loss)
I1027 19:06:46.005903  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0790534 (* 1 = 0.0790534 loss)
I1027 19:06:46.005909  5972 solver.cpp:571] Iteration 4320, lr = 0.001
I1027 19:06:58.170505  5972 solver.cpp:242] Iteration 4340, loss = 0.182903
I1027 19:06:58.170542  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.056315 (* 1 = 0.056315 loss)
I1027 19:06:58.170547  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.126588 (* 1 = 0.126588 loss)
I1027 19:06:58.170552  5972 solver.cpp:571] Iteration 4340, lr = 0.001
I1027 19:07:10.619719  5972 solver.cpp:242] Iteration 4360, loss = 0.100501
I1027 19:07:10.619756  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0518376 (* 1 = 0.0518376 loss)
I1027 19:07:10.619761  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0486634 (* 1 = 0.0486634 loss)
I1027 19:07:10.619765  5972 solver.cpp:571] Iteration 4360, lr = 0.001
I1027 19:07:22.891175  5972 solver.cpp:242] Iteration 4380, loss = 0.272584
I1027 19:07:22.891212  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11972 (* 1 = 0.11972 loss)
I1027 19:07:22.891217  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.152863 (* 1 = 0.152863 loss)
I1027 19:07:22.891222  5972 solver.cpp:571] Iteration 4380, lr = 0.001
speed: 0.585s / iter
I1027 19:07:35.151024  5972 solver.cpp:242] Iteration 4400, loss = 0.0946256
I1027 19:07:35.151062  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0381223 (* 1 = 0.0381223 loss)
I1027 19:07:35.151067  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0565033 (* 1 = 0.0565033 loss)
I1027 19:07:35.151070  5972 solver.cpp:571] Iteration 4400, lr = 0.001
I1027 19:07:47.473444  5972 solver.cpp:242] Iteration 4420, loss = 0.0245146
I1027 19:07:47.473527  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00566224 (* 1 = 0.00566224 loss)
I1027 19:07:47.473533  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0188524 (* 1 = 0.0188524 loss)
I1027 19:07:47.473541  5972 solver.cpp:571] Iteration 4420, lr = 0.001
I1027 19:07:59.819912  5972 solver.cpp:242] Iteration 4440, loss = 0.142333
I1027 19:07:59.819954  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0527332 (* 1 = 0.0527332 loss)
I1027 19:07:59.819959  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0895997 (* 1 = 0.0895997 loss)
I1027 19:07:59.819964  5972 solver.cpp:571] Iteration 4440, lr = 0.001
I1027 19:08:12.042320  5972 solver.cpp:242] Iteration 4460, loss = 0.140727
I1027 19:08:12.042358  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0433689 (* 1 = 0.0433689 loss)
I1027 19:08:12.042362  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0973584 (* 1 = 0.0973584 loss)
I1027 19:08:12.042367  5972 solver.cpp:571] Iteration 4460, lr = 0.001
I1027 19:08:24.388356  5972 solver.cpp:242] Iteration 4480, loss = 0.0114987
I1027 19:08:24.388394  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00462186 (* 1 = 0.00462186 loss)
I1027 19:08:24.388399  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00687689 (* 1 = 0.00687689 loss)
I1027 19:08:24.388404  5972 solver.cpp:571] Iteration 4480, lr = 0.001
I1027 19:08:36.695725  5972 solver.cpp:242] Iteration 4500, loss = 0.466044
I1027 19:08:36.695765  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.154782 (* 1 = 0.154782 loss)
I1027 19:08:36.695770  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.311261 (* 1 = 0.311261 loss)
I1027 19:08:36.695775  5972 solver.cpp:571] Iteration 4500, lr = 0.001
I1027 19:08:49.041167  5972 solver.cpp:242] Iteration 4520, loss = 0.269643
I1027 19:08:49.041205  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.145821 (* 1 = 0.145821 loss)
I1027 19:08:49.041210  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.123822 (* 1 = 0.123822 loss)
I1027 19:08:49.041215  5972 solver.cpp:571] Iteration 4520, lr = 0.001
I1027 19:09:01.439872  5972 solver.cpp:242] Iteration 4540, loss = 0.016448
I1027 19:09:01.439914  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00698048 (* 1 = 0.00698048 loss)
I1027 19:09:01.439920  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00946753 (* 1 = 0.00946753 loss)
I1027 19:09:01.439925  5972 solver.cpp:571] Iteration 4540, lr = 0.001
I1027 19:09:13.759778  5972 solver.cpp:242] Iteration 4560, loss = 0.0946675
I1027 19:09:13.759817  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0439152 (* 1 = 0.0439152 loss)
I1027 19:09:13.759822  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0507523 (* 1 = 0.0507523 loss)
I1027 19:09:13.759826  5972 solver.cpp:571] Iteration 4560, lr = 0.001
I1027 19:09:25.920959  5972 solver.cpp:242] Iteration 4580, loss = 0.445778
I1027 19:09:25.920997  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.170358 (* 1 = 0.170358 loss)
I1027 19:09:25.921002  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.27542 (* 1 = 0.27542 loss)
I1027 19:09:25.921006  5972 solver.cpp:571] Iteration 4580, lr = 0.001
speed: 0.586s / iter
I1027 19:09:38.036453  5972 solver.cpp:242] Iteration 4600, loss = 0.419153
I1027 19:09:38.036490  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.194278 (* 1 = 0.194278 loss)
I1027 19:09:38.036495  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.224875 (* 1 = 0.224875 loss)
I1027 19:09:38.036509  5972 solver.cpp:571] Iteration 4600, lr = 0.001
I1027 19:09:50.265480  5972 solver.cpp:242] Iteration 4620, loss = 0.15746
I1027 19:09:50.265518  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.081242 (* 1 = 0.081242 loss)
I1027 19:09:50.265523  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0762181 (* 1 = 0.0762181 loss)
I1027 19:09:50.265527  5972 solver.cpp:571] Iteration 4620, lr = 0.001
I1027 19:10:02.631729  5972 solver.cpp:242] Iteration 4640, loss = 0.334489
I1027 19:10:02.631767  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.160081 (* 1 = 0.160081 loss)
I1027 19:10:02.631772  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.174408 (* 1 = 0.174408 loss)
I1027 19:10:02.631775  5972 solver.cpp:571] Iteration 4640, lr = 0.001
I1027 19:10:14.930594  5972 solver.cpp:242] Iteration 4660, loss = 0.283046
I1027 19:10:14.930631  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.133138 (* 1 = 0.133138 loss)
I1027 19:10:14.930636  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149908 (* 1 = 0.149908 loss)
I1027 19:10:14.930640  5972 solver.cpp:571] Iteration 4660, lr = 0.001
I1027 19:10:27.179888  5972 solver.cpp:242] Iteration 4680, loss = 0.0580528
I1027 19:10:27.179934  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0349074 (* 1 = 0.0349074 loss)
I1027 19:10:27.179939  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0231454 (* 1 = 0.0231454 loss)
I1027 19:10:27.179944  5972 solver.cpp:571] Iteration 4680, lr = 0.001
I1027 19:10:39.276551  5972 solver.cpp:242] Iteration 4700, loss = 0.164995
I1027 19:10:39.276587  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0524157 (* 1 = 0.0524157 loss)
I1027 19:10:39.276592  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.112579 (* 1 = 0.112579 loss)
I1027 19:10:39.276597  5972 solver.cpp:571] Iteration 4700, lr = 0.001
I1027 19:10:51.420197  5972 solver.cpp:242] Iteration 4720, loss = 0.117648
I1027 19:10:51.420234  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.029763 (* 1 = 0.029763 loss)
I1027 19:10:51.420239  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0878845 (* 1 = 0.0878845 loss)
I1027 19:10:51.420243  5972 solver.cpp:571] Iteration 4720, lr = 0.001
I1027 19:11:03.641628  5972 solver.cpp:242] Iteration 4740, loss = 0.20878
I1027 19:11:03.641695  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.077058 (* 1 = 0.077058 loss)
I1027 19:11:03.641700  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.131722 (* 1 = 0.131722 loss)
I1027 19:11:03.641705  5972 solver.cpp:571] Iteration 4740, lr = 0.001
I1027 19:11:15.800524  5972 solver.cpp:242] Iteration 4760, loss = 0.562279
I1027 19:11:15.800565  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.257766 (* 1 = 0.257766 loss)
I1027 19:11:15.800571  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.304513 (* 1 = 0.304513 loss)
I1027 19:11:15.800575  5972 solver.cpp:571] Iteration 4760, lr = 0.001
I1027 19:11:28.160805  5972 solver.cpp:242] Iteration 4780, loss = 0.0697026
I1027 19:11:28.160845  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0352395 (* 1 = 0.0352395 loss)
I1027 19:11:28.160850  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0344631 (* 1 = 0.0344631 loss)
I1027 19:11:28.160854  5972 solver.cpp:571] Iteration 4780, lr = 0.001
speed: 0.587s / iter
I1027 19:11:40.404043  5972 solver.cpp:242] Iteration 4800, loss = 0.519806
I1027 19:11:40.404080  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.23644 (* 1 = 0.23644 loss)
I1027 19:11:40.404085  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.283367 (* 1 = 0.283367 loss)
I1027 19:11:40.404089  5972 solver.cpp:571] Iteration 4800, lr = 0.001
I1027 19:11:52.833230  5972 solver.cpp:242] Iteration 4820, loss = 0.14565
I1027 19:11:52.833268  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0524377 (* 1 = 0.0524377 loss)
I1027 19:11:52.833273  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0932122 (* 1 = 0.0932122 loss)
I1027 19:11:52.833278  5972 solver.cpp:571] Iteration 4820, lr = 0.001
I1027 19:12:05.037075  5972 solver.cpp:242] Iteration 4840, loss = 0.118268
I1027 19:12:05.037112  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0691278 (* 1 = 0.0691278 loss)
I1027 19:12:05.037118  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0491404 (* 1 = 0.0491404 loss)
I1027 19:12:05.037122  5972 solver.cpp:571] Iteration 4840, lr = 0.001
I1027 19:12:17.313650  5972 solver.cpp:242] Iteration 4860, loss = 0.358075
I1027 19:12:17.313688  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.126425 (* 1 = 0.126425 loss)
I1027 19:12:17.313693  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.23165 (* 1 = 0.23165 loss)
I1027 19:12:17.313697  5972 solver.cpp:571] Iteration 4860, lr = 0.001
I1027 19:12:29.500069  5972 solver.cpp:242] Iteration 4880, loss = 0.245
I1027 19:12:29.500107  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.124212 (* 1 = 0.124212 loss)
I1027 19:12:29.500111  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.120788 (* 1 = 0.120788 loss)
I1027 19:12:29.500115  5972 solver.cpp:571] Iteration 4880, lr = 0.001
I1027 19:12:41.933672  5972 solver.cpp:242] Iteration 4900, loss = 0.0651135
I1027 19:12:41.933714  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0331665 (* 1 = 0.0331665 loss)
I1027 19:12:41.933720  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.031947 (* 1 = 0.031947 loss)
I1027 19:12:41.933725  5972 solver.cpp:571] Iteration 4900, lr = 0.001
I1027 19:12:54.254745  5972 solver.cpp:242] Iteration 4920, loss = 0.38867
I1027 19:12:54.254783  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.164479 (* 1 = 0.164479 loss)
I1027 19:12:54.254788  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.224191 (* 1 = 0.224191 loss)
I1027 19:12:54.254792  5972 solver.cpp:571] Iteration 4920, lr = 0.001
I1027 19:13:06.623472  5972 solver.cpp:242] Iteration 4940, loss = 0.141163
I1027 19:13:06.623509  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.039303 (* 1 = 0.039303 loss)
I1027 19:13:06.623514  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.10186 (* 1 = 0.10186 loss)
I1027 19:13:06.623519  5972 solver.cpp:571] Iteration 4940, lr = 0.001
I1027 19:13:18.877677  5972 solver.cpp:242] Iteration 4960, loss = 0.196243
I1027 19:13:18.877714  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0642328 (* 1 = 0.0642328 loss)
I1027 19:13:18.877719  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.13201 (* 1 = 0.13201 loss)
I1027 19:13:18.877723  5972 solver.cpp:571] Iteration 4960, lr = 0.001
I1027 19:13:31.097050  5972 solver.cpp:242] Iteration 4980, loss = 0.103491
I1027 19:13:31.097090  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0278782 (* 1 = 0.0278782 loss)
I1027 19:13:31.097095  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0756126 (* 1 = 0.0756126 loss)
I1027 19:13:31.097100  5972 solver.cpp:571] Iteration 4980, lr = 0.001
speed: 0.588s / iter
I1027 19:13:43.427193  5972 solver.cpp:242] Iteration 5000, loss = 0.328045
I1027 19:13:43.427248  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.163079 (* 1 = 0.163079 loss)
I1027 19:13:43.427253  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.164966 (* 1 = 0.164966 loss)
I1027 19:13:43.427258  5972 solver.cpp:571] Iteration 5000, lr = 0.001
I1027 19:13:55.579463  5972 solver.cpp:242] Iteration 5020, loss = 0.150584
I1027 19:13:55.579507  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0371917 (* 1 = 0.0371917 loss)
I1027 19:13:55.579514  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113392 (* 1 = 0.113392 loss)
I1027 19:13:55.579521  5972 solver.cpp:571] Iteration 5020, lr = 0.001
I1027 19:14:07.751252  5972 solver.cpp:242] Iteration 5040, loss = 0.276268
I1027 19:14:07.751286  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11843 (* 1 = 0.11843 loss)
I1027 19:14:07.751293  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.157839 (* 1 = 0.157839 loss)
I1027 19:14:07.751301  5972 solver.cpp:571] Iteration 5040, lr = 0.001
I1027 19:14:20.024122  5972 solver.cpp:242] Iteration 5060, loss = 0.144984
I1027 19:14:20.024181  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0717991 (* 1 = 0.0717991 loss)
I1027 19:14:20.024188  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0731853 (* 1 = 0.0731853 loss)
I1027 19:14:20.024194  5972 solver.cpp:571] Iteration 5060, lr = 0.001
I1027 19:14:32.379995  5972 solver.cpp:242] Iteration 5080, loss = 0.130304
I1027 19:14:32.380023  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0620707 (* 1 = 0.0620707 loss)
I1027 19:14:32.380031  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0682333 (* 1 = 0.0682333 loss)
I1027 19:14:32.380038  5972 solver.cpp:571] Iteration 5080, lr = 0.001
I1027 19:14:44.733003  5972 solver.cpp:242] Iteration 5100, loss = 0.0185483
I1027 19:14:44.733032  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00462436 (* 1 = 0.00462436 loss)
I1027 19:14:44.733039  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0139239 (* 1 = 0.0139239 loss)
I1027 19:14:44.733045  5972 solver.cpp:571] Iteration 5100, lr = 0.001
I1027 19:14:57.001433  5972 solver.cpp:242] Iteration 5120, loss = 0.26165
I1027 19:14:57.001462  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.076667 (* 1 = 0.076667 loss)
I1027 19:14:57.001471  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.184983 (* 1 = 0.184983 loss)
I1027 19:14:57.001477  5972 solver.cpp:571] Iteration 5120, lr = 0.001
I1027 19:15:09.240206  5972 solver.cpp:242] Iteration 5140, loss = 0.126904
I1027 19:15:09.240242  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0699404 (* 1 = 0.0699404 loss)
I1027 19:15:09.240250  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0569639 (* 1 = 0.0569639 loss)
I1027 19:15:09.240257  5972 solver.cpp:571] Iteration 5140, lr = 0.001
I1027 19:15:21.672400  5972 solver.cpp:242] Iteration 5160, loss = 0.202166
I1027 19:15:21.672430  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.109925 (* 1 = 0.109925 loss)
I1027 19:15:21.672437  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.092241 (* 1 = 0.092241 loss)
I1027 19:15:21.672444  5972 solver.cpp:571] Iteration 5160, lr = 0.001
I1027 19:15:33.902483  5972 solver.cpp:242] Iteration 5180, loss = 0.0121203
I1027 19:15:33.902513  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00681457 (* 1 = 0.00681457 loss)
I1027 19:15:33.902520  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00530576 (* 1 = 0.00530576 loss)
I1027 19:15:33.902528  5972 solver.cpp:571] Iteration 5180, lr = 0.001
speed: 0.589s / iter
I1027 19:15:46.259213  5972 solver.cpp:242] Iteration 5200, loss = 0.191323
I1027 19:15:46.259243  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11172 (* 1 = 0.11172 loss)
I1027 19:15:46.259251  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0796031 (* 1 = 0.0796031 loss)
I1027 19:15:46.259258  5972 solver.cpp:571] Iteration 5200, lr = 0.001
I1027 19:15:58.537689  5972 solver.cpp:242] Iteration 5220, loss = 0.239075
I1027 19:15:58.537719  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.10674 (* 1 = 0.10674 loss)
I1027 19:15:58.537725  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.132335 (* 1 = 0.132335 loss)
I1027 19:15:58.537730  5972 solver.cpp:571] Iteration 5220, lr = 0.001
I1027 19:16:10.801782  5972 solver.cpp:242] Iteration 5240, loss = 0.1488
I1027 19:16:10.801811  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0629576 (* 1 = 0.0629576 loss)
I1027 19:16:10.801820  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0858426 (* 1 = 0.0858426 loss)
I1027 19:16:10.801825  5972 solver.cpp:571] Iteration 5240, lr = 0.001
I1027 19:16:23.090005  5972 solver.cpp:242] Iteration 5260, loss = 0.171114
I1027 19:16:23.090052  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0908023 (* 1 = 0.0908023 loss)
I1027 19:16:23.090060  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0803115 (* 1 = 0.0803115 loss)
I1027 19:16:23.090068  5972 solver.cpp:571] Iteration 5260, lr = 0.001
I1027 19:16:35.345505  5972 solver.cpp:242] Iteration 5280, loss = 0.248671
I1027 19:16:35.345540  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0723935 (* 1 = 0.0723935 loss)
I1027 19:16:35.345547  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.176277 (* 1 = 0.176277 loss)
I1027 19:16:35.345554  5972 solver.cpp:571] Iteration 5280, lr = 0.001
I1027 19:16:47.577998  5972 solver.cpp:242] Iteration 5300, loss = 0.0826797
I1027 19:16:47.578027  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0260513 (* 1 = 0.0260513 loss)
I1027 19:16:47.578035  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0566284 (* 1 = 0.0566284 loss)
I1027 19:16:47.578042  5972 solver.cpp:571] Iteration 5300, lr = 0.001
I1027 19:16:59.974285  5972 solver.cpp:242] Iteration 5320, loss = 0.214713
I1027 19:16:59.974315  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0777892 (* 1 = 0.0777892 loss)
I1027 19:16:59.974323  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.136923 (* 1 = 0.136923 loss)
I1027 19:16:59.974328  5972 solver.cpp:571] Iteration 5320, lr = 0.001
I1027 19:17:12.282395  5972 solver.cpp:242] Iteration 5340, loss = 0.0889562
I1027 19:17:12.282423  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0260307 (* 1 = 0.0260307 loss)
I1027 19:17:12.282431  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0629256 (* 1 = 0.0629256 loss)
I1027 19:17:12.282438  5972 solver.cpp:571] Iteration 5340, lr = 0.001
I1027 19:17:24.591974  5972 solver.cpp:242] Iteration 5360, loss = 0.0768011
I1027 19:17:24.592002  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0462073 (* 1 = 0.0462073 loss)
I1027 19:17:24.592010  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0305938 (* 1 = 0.0305938 loss)
I1027 19:17:24.592015  5972 solver.cpp:571] Iteration 5360, lr = 0.001
I1027 19:17:36.840001  5972 solver.cpp:242] Iteration 5380, loss = 0.282352
I1027 19:17:36.840035  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.149774 (* 1 = 0.149774 loss)
I1027 19:17:36.840042  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.132579 (* 1 = 0.132579 loss)
I1027 19:17:36.840049  5972 solver.cpp:571] Iteration 5380, lr = 0.001
speed: 0.590s / iter
I1027 19:17:48.978266  5972 solver.cpp:242] Iteration 5400, loss = 0.458568
I1027 19:17:48.978297  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.172367 (* 1 = 0.172367 loss)
I1027 19:17:48.978304  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.286201 (* 1 = 0.286201 loss)
I1027 19:17:48.978312  5972 solver.cpp:571] Iteration 5400, lr = 0.001
I1027 19:18:01.167001  5972 solver.cpp:242] Iteration 5420, loss = 0.117985
I1027 19:18:01.167034  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0471162 (* 1 = 0.0471162 loss)
I1027 19:18:01.167042  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0708689 (* 1 = 0.0708689 loss)
I1027 19:18:01.167048  5972 solver.cpp:571] Iteration 5420, lr = 0.001
I1027 19:18:13.417821  5972 solver.cpp:242] Iteration 5440, loss = 0.371207
I1027 19:18:13.417861  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.15728 (* 1 = 0.15728 loss)
I1027 19:18:13.417868  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.213927 (* 1 = 0.213927 loss)
I1027 19:18:13.417875  5972 solver.cpp:571] Iteration 5440, lr = 0.001
I1027 19:18:25.640450  5972 solver.cpp:242] Iteration 5460, loss = 0.319149
I1027 19:18:25.640480  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.135754 (* 1 = 0.135754 loss)
I1027 19:18:25.640486  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.183394 (* 1 = 0.183394 loss)
I1027 19:18:25.640492  5972 solver.cpp:571] Iteration 5460, lr = 0.001
I1027 19:18:37.856513  5972 solver.cpp:242] Iteration 5480, loss = 0.0938764
I1027 19:18:37.856544  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0293499 (* 1 = 0.0293499 loss)
I1027 19:18:37.856550  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0645265 (* 1 = 0.0645265 loss)
I1027 19:18:37.856557  5972 solver.cpp:571] Iteration 5480, lr = 0.001
I1027 19:18:50.112949  5972 solver.cpp:242] Iteration 5500, loss = 0.233276
I1027 19:18:50.112979  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0870522 (* 1 = 0.0870522 loss)
I1027 19:18:50.112987  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.146224 (* 1 = 0.146224 loss)
I1027 19:18:50.112993  5972 solver.cpp:571] Iteration 5500, lr = 0.001
I1027 19:19:02.282812  5972 solver.cpp:242] Iteration 5520, loss = 0.0399571
I1027 19:19:02.282842  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0102782 (* 1 = 0.0102782 loss)
I1027 19:19:02.282850  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0296789 (* 1 = 0.0296789 loss)
I1027 19:19:02.282855  5972 solver.cpp:571] Iteration 5520, lr = 0.001
I1027 19:19:14.474862  5972 solver.cpp:242] Iteration 5540, loss = 0.418977
I1027 19:19:14.474891  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.17772 (* 1 = 0.17772 loss)
I1027 19:19:14.474898  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.241257 (* 1 = 0.241257 loss)
I1027 19:19:14.474905  5972 solver.cpp:571] Iteration 5540, lr = 0.001
I1027 19:19:26.847208  5972 solver.cpp:242] Iteration 5560, loss = 0.110174
I1027 19:19:26.847240  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0547658 (* 1 = 0.0547658 loss)
I1027 19:19:26.847249  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0554082 (* 1 = 0.0554082 loss)
I1027 19:19:26.847265  5972 solver.cpp:571] Iteration 5560, lr = 0.001
I1027 19:19:39.134744  5972 solver.cpp:242] Iteration 5580, loss = 0.228466
I1027 19:19:39.134776  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0624527 (* 1 = 0.0624527 loss)
I1027 19:19:39.134784  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.166014 (* 1 = 0.166014 loss)
I1027 19:19:39.134790  5972 solver.cpp:571] Iteration 5580, lr = 0.001
speed: 0.591s / iter
I1027 19:19:51.293301  5972 solver.cpp:242] Iteration 5600, loss = 0.184059
I1027 19:19:51.293331  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0591345 (* 1 = 0.0591345 loss)
I1027 19:19:51.293339  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.124925 (* 1 = 0.124925 loss)
I1027 19:19:51.293344  5972 solver.cpp:571] Iteration 5600, lr = 0.001
I1027 19:20:03.823765  5972 solver.cpp:242] Iteration 5620, loss = 0.0164198
I1027 19:20:03.823793  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00665313 (* 1 = 0.00665313 loss)
I1027 19:20:03.823801  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0097667 (* 1 = 0.0097667 loss)
I1027 19:20:03.823807  5972 solver.cpp:571] Iteration 5620, lr = 0.001
I1027 19:20:16.138475  5972 solver.cpp:242] Iteration 5640, loss = 0.435599
I1027 19:20:16.138501  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.216143 (* 1 = 0.216143 loss)
I1027 19:20:16.138509  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.219456 (* 1 = 0.219456 loss)
I1027 19:20:16.138514  5972 solver.cpp:571] Iteration 5640, lr = 0.001
I1027 19:20:28.348343  5972 solver.cpp:242] Iteration 5660, loss = 0.0958425
I1027 19:20:28.348372  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0401427 (* 1 = 0.0401427 loss)
I1027 19:20:28.348379  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0556998 (* 1 = 0.0556998 loss)
I1027 19:20:28.348387  5972 solver.cpp:571] Iteration 5660, lr = 0.001
I1027 19:20:40.382949  5972 solver.cpp:242] Iteration 5680, loss = 0.11787
I1027 19:20:40.382978  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.054421 (* 1 = 0.054421 loss)
I1027 19:20:40.382985  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0634492 (* 1 = 0.0634492 loss)
I1027 19:20:40.383002  5972 solver.cpp:571] Iteration 5680, lr = 0.001
I1027 19:20:52.688622  5972 solver.cpp:242] Iteration 5700, loss = 0.44849
I1027 19:20:52.688654  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.197376 (* 1 = 0.197376 loss)
I1027 19:20:52.688663  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.251114 (* 1 = 0.251114 loss)
I1027 19:20:52.688678  5972 solver.cpp:571] Iteration 5700, lr = 0.001
I1027 19:21:05.081266  5972 solver.cpp:242] Iteration 5720, loss = 0.168611
I1027 19:21:05.081296  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0524566 (* 1 = 0.0524566 loss)
I1027 19:21:05.081305  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.116155 (* 1 = 0.116155 loss)
I1027 19:21:05.081310  5972 solver.cpp:571] Iteration 5720, lr = 0.001
I1027 19:21:17.241663  5972 solver.cpp:242] Iteration 5740, loss = 0.205953
I1027 19:21:17.241693  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0586042 (* 1 = 0.0586042 loss)
I1027 19:21:17.241700  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.147349 (* 1 = 0.147349 loss)
I1027 19:21:17.241706  5972 solver.cpp:571] Iteration 5740, lr = 0.001
I1027 19:21:29.360476  5972 solver.cpp:242] Iteration 5760, loss = 0.21732
I1027 19:21:29.360507  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0804821 (* 1 = 0.0804821 loss)
I1027 19:21:29.360513  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.136838 (* 1 = 0.136838 loss)
I1027 19:21:29.360519  5972 solver.cpp:571] Iteration 5760, lr = 0.001
I1027 19:21:41.486713  5972 solver.cpp:242] Iteration 5780, loss = 0.402513
I1027 19:21:41.486753  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.133453 (* 1 = 0.133453 loss)
I1027 19:21:41.486760  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.26906 (* 1 = 0.26906 loss)
I1027 19:21:41.486766  5972 solver.cpp:571] Iteration 5780, lr = 0.001
speed: 0.592s / iter
I1027 19:21:53.644870  5972 solver.cpp:242] Iteration 5800, loss = 0.282918
I1027 19:21:53.644899  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0653535 (* 1 = 0.0653535 loss)
I1027 19:21:53.644906  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.217565 (* 1 = 0.217565 loss)
I1027 19:21:53.644912  5972 solver.cpp:571] Iteration 5800, lr = 0.001
I1027 19:22:05.816792  5972 solver.cpp:242] Iteration 5820, loss = 0.25899
I1027 19:22:05.816823  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0800958 (* 1 = 0.0800958 loss)
I1027 19:22:05.816829  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.178894 (* 1 = 0.178894 loss)
I1027 19:22:05.816835  5972 solver.cpp:571] Iteration 5820, lr = 0.001
I1027 19:22:18.108983  5972 solver.cpp:242] Iteration 5840, loss = 0.557136
I1027 19:22:18.109012  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.258538 (* 1 = 0.258538 loss)
I1027 19:22:18.109019  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.298597 (* 1 = 0.298597 loss)
I1027 19:22:18.109025  5972 solver.cpp:571] Iteration 5840, lr = 0.001
I1027 19:22:30.388535  5972 solver.cpp:242] Iteration 5860, loss = 0.0412782
I1027 19:22:30.388563  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0362281 (* 1 = 0.0362281 loss)
I1027 19:22:30.388571  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00505003 (* 1 = 0.00505003 loss)
I1027 19:22:30.388577  5972 solver.cpp:571] Iteration 5860, lr = 0.001
I1027 19:22:42.644942  5972 solver.cpp:242] Iteration 5880, loss = 0.838732
I1027 19:22:42.644971  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.380887 (* 1 = 0.380887 loss)
I1027 19:22:42.644979  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.457845 (* 1 = 0.457845 loss)
I1027 19:22:42.644984  5972 solver.cpp:571] Iteration 5880, lr = 0.001
I1027 19:22:54.684033  5972 solver.cpp:242] Iteration 5900, loss = 0.392976
I1027 19:22:54.684077  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.165986 (* 1 = 0.165986 loss)
I1027 19:22:54.684085  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.22699 (* 1 = 0.22699 loss)
I1027 19:22:54.684103  5972 solver.cpp:571] Iteration 5900, lr = 0.001
I1027 19:23:07.050876  5972 solver.cpp:242] Iteration 5920, loss = 0.4001
I1027 19:23:07.050909  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.204583 (* 1 = 0.204583 loss)
I1027 19:23:07.050916  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.195517 (* 1 = 0.195517 loss)
I1027 19:23:07.050932  5972 solver.cpp:571] Iteration 5920, lr = 0.001
I1027 19:23:19.391163  5972 solver.cpp:242] Iteration 5940, loss = 0.145386
I1027 19:23:19.391213  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704056 (* 1 = 0.0704056 loss)
I1027 19:23:19.391234  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0749802 (* 1 = 0.0749802 loss)
I1027 19:23:19.391249  5972 solver.cpp:571] Iteration 5940, lr = 0.001
I1027 19:23:31.424882  5972 solver.cpp:242] Iteration 5960, loss = 0.186067
I1027 19:23:31.424913  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0784967 (* 1 = 0.0784967 loss)
I1027 19:23:31.424921  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.10757 (* 1 = 0.10757 loss)
I1027 19:23:31.424927  5972 solver.cpp:571] Iteration 5960, lr = 0.001
I1027 19:23:43.823839  5972 solver.cpp:242] Iteration 5980, loss = 0.266242
I1027 19:23:43.823868  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.117685 (* 1 = 0.117685 loss)
I1027 19:23:43.823875  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.148557 (* 1 = 0.148557 loss)
I1027 19:23:43.823881  5972 solver.cpp:571] Iteration 5980, lr = 0.001
speed: 0.592s / iter
I1027 19:23:56.133136  5972 solver.cpp:242] Iteration 6000, loss = 0.279572
I1027 19:23:56.133164  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0983102 (* 1 = 0.0983102 loss)
I1027 19:23:56.133172  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.181262 (* 1 = 0.181262 loss)
I1027 19:23:56.133177  5972 solver.cpp:571] Iteration 6000, lr = 0.001
I1027 19:24:08.112100  5972 solver.cpp:242] Iteration 6020, loss = 0.0603865
I1027 19:24:08.112136  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0249745 (* 1 = 0.0249745 loss)
I1027 19:24:08.112144  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.035412 (* 1 = 0.035412 loss)
I1027 19:24:08.112150  5972 solver.cpp:571] Iteration 6020, lr = 0.001
I1027 19:24:20.365510  5972 solver.cpp:242] Iteration 6040, loss = 0.169889
I1027 19:24:20.365540  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557843 (* 1 = 0.0557843 loss)
I1027 19:24:20.365546  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.114105 (* 1 = 0.114105 loss)
I1027 19:24:20.365552  5972 solver.cpp:571] Iteration 6040, lr = 0.001
I1027 19:24:32.705061  5972 solver.cpp:242] Iteration 6060, loss = 0.0192944
I1027 19:24:32.705094  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00834768 (* 1 = 0.00834768 loss)
I1027 19:24:32.705102  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0109467 (* 1 = 0.0109467 loss)
I1027 19:24:32.705108  5972 solver.cpp:571] Iteration 6060, lr = 0.001
I1027 19:24:44.785267  5972 solver.cpp:242] Iteration 6080, loss = 0.137594
I1027 19:24:44.785302  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0555964 (* 1 = 0.0555964 loss)
I1027 19:24:44.785310  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0819981 (* 1 = 0.0819981 loss)
I1027 19:24:44.785317  5972 solver.cpp:571] Iteration 6080, lr = 0.001
I1027 19:24:57.087201  5972 solver.cpp:242] Iteration 6100, loss = 0.268221
I1027 19:24:57.087232  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.1259 (* 1 = 0.1259 loss)
I1027 19:24:57.087239  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.14232 (* 1 = 0.14232 loss)
I1027 19:24:57.087246  5972 solver.cpp:571] Iteration 6100, lr = 0.001
I1027 19:25:09.316438  5972 solver.cpp:242] Iteration 6120, loss = 0.105393
I1027 19:25:09.316468  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0284299 (* 1 = 0.0284299 loss)
I1027 19:25:09.316475  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0769631 (* 1 = 0.0769631 loss)
I1027 19:25:09.316491  5972 solver.cpp:571] Iteration 6120, lr = 0.001
I1027 19:25:21.747750  5972 solver.cpp:242] Iteration 6140, loss = 0.135508
I1027 19:25:21.747779  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0429391 (* 1 = 0.0429391 loss)
I1027 19:25:21.747786  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.092569 (* 1 = 0.092569 loss)
I1027 19:25:21.747803  5972 solver.cpp:571] Iteration 6140, lr = 0.001
I1027 19:25:33.979238  5972 solver.cpp:242] Iteration 6160, loss = 0.325284
I1027 19:25:33.979267  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.104417 (* 1 = 0.104417 loss)
I1027 19:25:33.979275  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.220867 (* 1 = 0.220867 loss)
I1027 19:25:33.979280  5972 solver.cpp:571] Iteration 6160, lr = 0.001
I1027 19:25:46.341373  5972 solver.cpp:242] Iteration 6180, loss = 0.106937
I1027 19:25:46.341403  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0372406 (* 1 = 0.0372406 loss)
I1027 19:25:46.341409  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0696962 (* 1 = 0.0696962 loss)
I1027 19:25:46.341415  5972 solver.cpp:571] Iteration 6180, lr = 0.001
speed: 0.593s / iter
I1027 19:25:58.621496  5972 solver.cpp:242] Iteration 6200, loss = 0.28126
I1027 19:25:58.621531  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.120032 (* 1 = 0.120032 loss)
I1027 19:25:58.621538  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.161228 (* 1 = 0.161228 loss)
I1027 19:25:58.621554  5972 solver.cpp:571] Iteration 6200, lr = 0.001
I1027 19:26:10.840394  5972 solver.cpp:242] Iteration 6220, loss = 0.266359
I1027 19:26:10.840427  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0719436 (* 1 = 0.0719436 loss)
I1027 19:26:10.840435  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.194416 (* 1 = 0.194416 loss)
I1027 19:26:10.840441  5972 solver.cpp:571] Iteration 6220, lr = 0.001
I1027 19:26:23.097946  5972 solver.cpp:242] Iteration 6240, loss = 0.0173351
I1027 19:26:23.097976  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00297335 (* 1 = 0.00297335 loss)
I1027 19:26:23.097985  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0143617 (* 1 = 0.0143617 loss)
I1027 19:26:23.097990  5972 solver.cpp:571] Iteration 6240, lr = 0.001
I1027 19:26:35.369233  5972 solver.cpp:242] Iteration 6260, loss = 0.0809653
I1027 19:26:35.369263  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306091 (* 1 = 0.0306091 loss)
I1027 19:26:35.369271  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0503562 (* 1 = 0.0503562 loss)
I1027 19:26:35.369287  5972 solver.cpp:571] Iteration 6260, lr = 0.001
I1027 19:26:47.525956  5972 solver.cpp:242] Iteration 6280, loss = 0.370489
I1027 19:26:47.525995  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.162781 (* 1 = 0.162781 loss)
I1027 19:26:47.526000  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.207708 (* 1 = 0.207708 loss)
I1027 19:26:47.526005  5972 solver.cpp:571] Iteration 6280, lr = 0.001
I1027 19:26:59.824959  5972 solver.cpp:242] Iteration 6300, loss = 0.0481214
I1027 19:26:59.824988  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0206797 (* 1 = 0.0206797 loss)
I1027 19:26:59.824995  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0274417 (* 1 = 0.0274417 loss)
I1027 19:26:59.825001  5972 solver.cpp:571] Iteration 6300, lr = 0.001
I1027 19:27:12.090723  5972 solver.cpp:242] Iteration 6320, loss = 0.200278
I1027 19:27:12.090751  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0472591 (* 1 = 0.0472591 loss)
I1027 19:27:12.090759  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.153019 (* 1 = 0.153019 loss)
I1027 19:27:12.090764  5972 solver.cpp:571] Iteration 6320, lr = 0.001
I1027 19:27:24.375109  5972 solver.cpp:242] Iteration 6340, loss = 0.285468
I1027 19:27:24.375159  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.127068 (* 1 = 0.127068 loss)
I1027 19:27:24.375166  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.1584 (* 1 = 0.1584 loss)
I1027 19:27:24.375174  5972 solver.cpp:571] Iteration 6340, lr = 0.001
I1027 19:27:36.739166  5972 solver.cpp:242] Iteration 6360, loss = 0.105305
I1027 19:27:36.739213  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0359556 (* 1 = 0.0359556 loss)
I1027 19:27:36.739222  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0693493 (* 1 = 0.0693493 loss)
I1027 19:27:36.739228  5972 solver.cpp:571] Iteration 6360, lr = 0.001
I1027 19:27:48.981602  5972 solver.cpp:242] Iteration 6380, loss = 0.153062
I1027 19:27:48.981642  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0684015 (* 1 = 0.0684015 loss)
I1027 19:27:48.981647  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0846604 (* 1 = 0.0846604 loss)
I1027 19:27:48.981650  5972 solver.cpp:571] Iteration 6380, lr = 0.001
speed: 0.594s / iter
I1027 19:28:01.264382  5972 solver.cpp:242] Iteration 6400, loss = 0.0409129
I1027 19:28:01.264420  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0202589 (* 1 = 0.0202589 loss)
I1027 19:28:01.264425  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.020654 (* 1 = 0.020654 loss)
I1027 19:28:01.264430  5972 solver.cpp:571] Iteration 6400, lr = 0.001
I1027 19:28:13.491600  5972 solver.cpp:242] Iteration 6420, loss = 0.131944
I1027 19:28:13.491636  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0547777 (* 1 = 0.0547777 loss)
I1027 19:28:13.491641  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0771658 (* 1 = 0.0771658 loss)
I1027 19:28:13.491644  5972 solver.cpp:571] Iteration 6420, lr = 0.001
I1027 19:28:25.730932  5972 solver.cpp:242] Iteration 6440, loss = 0.33211
I1027 19:28:25.730969  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.127837 (* 1 = 0.127837 loss)
I1027 19:28:25.730974  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.204273 (* 1 = 0.204273 loss)
I1027 19:28:25.730978  5972 solver.cpp:571] Iteration 6440, lr = 0.001
I1027 19:28:37.769731  5972 solver.cpp:242] Iteration 6460, loss = 0.314623
I1027 19:28:37.769768  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.150955 (* 1 = 0.150955 loss)
I1027 19:28:37.769773  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.163668 (* 1 = 0.163668 loss)
I1027 19:28:37.769778  5972 solver.cpp:571] Iteration 6460, lr = 0.001
I1027 19:28:49.982003  5972 solver.cpp:242] Iteration 6480, loss = 0.184348
I1027 19:28:49.982041  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0704837 (* 1 = 0.0704837 loss)
I1027 19:28:49.982046  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113864 (* 1 = 0.113864 loss)
I1027 19:28:49.982050  5972 solver.cpp:571] Iteration 6480, lr = 0.001
I1027 19:29:02.116080  5972 solver.cpp:242] Iteration 6500, loss = 0.509353
I1027 19:29:02.116148  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.245683 (* 1 = 0.245683 loss)
I1027 19:29:02.116158  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.26367 (* 1 = 0.26367 loss)
I1027 19:29:02.116165  5972 solver.cpp:571] Iteration 6500, lr = 0.001
I1027 19:29:14.264737  5972 solver.cpp:242] Iteration 6520, loss = 0.238871
I1027 19:29:14.264778  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0528676 (* 1 = 0.0528676 loss)
I1027 19:29:14.264783  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.186003 (* 1 = 0.186003 loss)
I1027 19:29:14.264788  5972 solver.cpp:571] Iteration 6520, lr = 0.001
I1027 19:29:26.356492  5972 solver.cpp:242] Iteration 6540, loss = 0.185148
I1027 19:29:26.356535  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.066881 (* 1 = 0.066881 loss)
I1027 19:29:26.356540  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.118267 (* 1 = 0.118267 loss)
I1027 19:29:26.356545  5972 solver.cpp:571] Iteration 6540, lr = 0.001
I1027 19:29:38.657795  5972 solver.cpp:242] Iteration 6560, loss = 0.153706
I1027 19:29:38.657836  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0405204 (* 1 = 0.0405204 loss)
I1027 19:29:38.657842  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113186 (* 1 = 0.113186 loss)
I1027 19:29:38.657847  5972 solver.cpp:571] Iteration 6560, lr = 0.001
I1027 19:29:51.118255  5972 solver.cpp:242] Iteration 6580, loss = 0.113633
I1027 19:29:51.118294  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0437656 (* 1 = 0.0437656 loss)
I1027 19:29:51.118299  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0698672 (* 1 = 0.0698672 loss)
I1027 19:29:51.118304  5972 solver.cpp:571] Iteration 6580, lr = 0.001
speed: 0.594s / iter
I1027 19:30:03.324664  5972 solver.cpp:242] Iteration 6600, loss = 0.0785596
I1027 19:30:03.324702  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0359566 (* 1 = 0.0359566 loss)
I1027 19:30:03.324707  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.042603 (* 1 = 0.042603 loss)
I1027 19:30:03.324710  5972 solver.cpp:571] Iteration 6600, lr = 0.001
I1027 19:30:15.547231  5972 solver.cpp:242] Iteration 6620, loss = 0.335934
I1027 19:30:15.547271  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0949602 (* 1 = 0.0949602 loss)
I1027 19:30:15.547276  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.240973 (* 1 = 0.240973 loss)
I1027 19:30:15.547279  5972 solver.cpp:571] Iteration 6620, lr = 0.001
I1027 19:30:27.704922  5972 solver.cpp:242] Iteration 6640, loss = 0.0333506
I1027 19:30:27.704962  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00715225 (* 1 = 0.00715225 loss)
I1027 19:30:27.704967  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0261983 (* 1 = 0.0261983 loss)
I1027 19:30:27.704972  5972 solver.cpp:571] Iteration 6640, lr = 0.001
I1027 19:30:39.790740  5972 solver.cpp:242] Iteration 6660, loss = 0.383573
I1027 19:30:39.790779  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.174168 (* 1 = 0.174168 loss)
I1027 19:30:39.790784  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.209406 (* 1 = 0.209406 loss)
I1027 19:30:39.790789  5972 solver.cpp:571] Iteration 6660, lr = 0.001
I1027 19:30:51.951416  5972 solver.cpp:242] Iteration 6680, loss = 0.254901
I1027 19:30:51.951452  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0852364 (* 1 = 0.0852364 loss)
I1027 19:30:51.951457  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.169664 (* 1 = 0.169664 loss)
I1027 19:30:51.951462  5972 solver.cpp:571] Iteration 6680, lr = 0.001
I1027 19:31:04.101258  5972 solver.cpp:242] Iteration 6700, loss = 0.307412
I1027 19:31:04.101294  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.110655 (* 1 = 0.110655 loss)
I1027 19:31:04.101300  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.196757 (* 1 = 0.196757 loss)
I1027 19:31:04.101305  5972 solver.cpp:571] Iteration 6700, lr = 0.001
I1027 19:31:16.263366  5972 solver.cpp:242] Iteration 6720, loss = 0.192623
I1027 19:31:16.263403  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0743959 (* 1 = 0.0743959 loss)
I1027 19:31:16.263408  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.118227 (* 1 = 0.118227 loss)
I1027 19:31:16.263412  5972 solver.cpp:571] Iteration 6720, lr = 0.001
I1027 19:31:28.377032  5972 solver.cpp:242] Iteration 6740, loss = 0.0570463
I1027 19:31:28.377070  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0328269 (* 1 = 0.0328269 loss)
I1027 19:31:28.377075  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0242194 (* 1 = 0.0242194 loss)
I1027 19:31:28.377079  5972 solver.cpp:571] Iteration 6740, lr = 0.001
I1027 19:31:40.553654  5972 solver.cpp:242] Iteration 6760, loss = 0.254771
I1027 19:31:40.553691  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0868038 (* 1 = 0.0868038 loss)
I1027 19:31:40.553696  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.167967 (* 1 = 0.167967 loss)
I1027 19:31:40.553700  5972 solver.cpp:571] Iteration 6760, lr = 0.001
I1027 19:31:52.698163  5972 solver.cpp:242] Iteration 6780, loss = 0.106412
I1027 19:31:52.698201  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0491924 (* 1 = 0.0491924 loss)
I1027 19:31:52.698206  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0572197 (* 1 = 0.0572197 loss)
I1027 19:31:52.698210  5972 solver.cpp:571] Iteration 6780, lr = 0.001
speed: 0.595s / iter
I1027 19:32:05.048619  5972 solver.cpp:242] Iteration 6800, loss = 0.0675727
I1027 19:32:05.048660  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0263146 (* 1 = 0.0263146 loss)
I1027 19:32:05.048666  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0412581 (* 1 = 0.0412581 loss)
I1027 19:32:05.048671  5972 solver.cpp:571] Iteration 6800, lr = 0.001
I1027 19:32:17.257830  5972 solver.cpp:242] Iteration 6820, loss = 0.0905346
I1027 19:32:17.257863  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.037244 (* 1 = 0.037244 loss)
I1027 19:32:17.257869  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0532905 (* 1 = 0.0532905 loss)
I1027 19:32:17.257874  5972 solver.cpp:571] Iteration 6820, lr = 0.001
I1027 19:32:29.375634  5972 solver.cpp:242] Iteration 6840, loss = 0.26564
I1027 19:32:29.375674  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0732048 (* 1 = 0.0732048 loss)
I1027 19:32:29.375679  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.192435 (* 1 = 0.192435 loss)
I1027 19:32:29.375684  5972 solver.cpp:571] Iteration 6840, lr = 0.001
I1027 19:32:41.554023  5972 solver.cpp:242] Iteration 6860, loss = 0.457382
I1027 19:32:41.554060  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.178229 (* 1 = 0.178229 loss)
I1027 19:32:41.554065  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.279153 (* 1 = 0.279153 loss)
I1027 19:32:41.554070  5972 solver.cpp:571] Iteration 6860, lr = 0.001
I1027 19:32:53.634979  5972 solver.cpp:242] Iteration 6880, loss = 0.0554183
I1027 19:32:53.635017  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0199804 (* 1 = 0.0199804 loss)
I1027 19:32:53.635022  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0354379 (* 1 = 0.0354379 loss)
I1027 19:32:53.635036  5972 solver.cpp:571] Iteration 6880, lr = 0.001
I1027 19:33:05.916451  5972 solver.cpp:242] Iteration 6900, loss = 0.0431568
I1027 19:33:05.916489  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0136883 (* 1 = 0.0136883 loss)
I1027 19:33:05.916494  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0294685 (* 1 = 0.0294685 loss)
I1027 19:33:05.916498  5972 solver.cpp:571] Iteration 6900, lr = 0.001
I1027 19:33:18.076581  5972 solver.cpp:242] Iteration 6920, loss = 0.217
I1027 19:33:18.076619  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0694846 (* 1 = 0.0694846 loss)
I1027 19:33:18.076624  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.147515 (* 1 = 0.147515 loss)
I1027 19:33:18.076629  5972 solver.cpp:571] Iteration 6920, lr = 0.001
I1027 19:33:30.375923  5972 solver.cpp:242] Iteration 6940, loss = 0.423412
I1027 19:33:30.375959  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.221502 (* 1 = 0.221502 loss)
I1027 19:33:30.375974  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.20191 (* 1 = 0.20191 loss)
I1027 19:33:30.375979  5972 solver.cpp:571] Iteration 6940, lr = 0.001
I1027 19:33:42.529182  5972 solver.cpp:242] Iteration 6960, loss = 0.313597
I1027 19:33:42.529219  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.115255 (* 1 = 0.115255 loss)
I1027 19:33:42.529224  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.198342 (* 1 = 0.198342 loss)
I1027 19:33:42.529229  5972 solver.cpp:571] Iteration 6960, lr = 0.001
I1027 19:33:54.917029  5972 solver.cpp:242] Iteration 6980, loss = 0.0612294
I1027 19:33:54.917069  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0387291 (* 1 = 0.0387291 loss)
I1027 19:33:54.917074  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0225003 (* 1 = 0.0225003 loss)
I1027 19:33:54.917079  5972 solver.cpp:571] Iteration 6980, lr = 0.001
speed: 0.595s / iter
I1027 19:34:07.234232  5972 solver.cpp:242] Iteration 7000, loss = 0.328203
I1027 19:34:07.234272  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.127338 (* 1 = 0.127338 loss)
I1027 19:34:07.234277  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.200865 (* 1 = 0.200865 loss)
I1027 19:34:07.234282  5972 solver.cpp:571] Iteration 7000, lr = 0.001
I1027 19:34:19.558704  5972 solver.cpp:242] Iteration 7020, loss = 0.251293
I1027 19:34:19.558743  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.120458 (* 1 = 0.120458 loss)
I1027 19:34:19.558748  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.130835 (* 1 = 0.130835 loss)
I1027 19:34:19.558751  5972 solver.cpp:571] Iteration 7020, lr = 0.001
I1027 19:34:31.934643  5972 solver.cpp:242] Iteration 7040, loss = 0.145243
I1027 19:34:31.934680  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.064091 (* 1 = 0.064091 loss)
I1027 19:34:31.934684  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0811522 (* 1 = 0.0811522 loss)
I1027 19:34:31.934689  5972 solver.cpp:571] Iteration 7040, lr = 0.001
I1027 19:34:44.173557  5972 solver.cpp:242] Iteration 7060, loss = 0.0881561
I1027 19:34:44.173595  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0402677 (* 1 = 0.0402677 loss)
I1027 19:34:44.173600  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0478884 (* 1 = 0.0478884 loss)
I1027 19:34:44.173604  5972 solver.cpp:571] Iteration 7060, lr = 0.001
I1027 19:34:56.328651  5972 solver.cpp:242] Iteration 7080, loss = 0.329067
I1027 19:34:56.328690  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.149821 (* 1 = 0.149821 loss)
I1027 19:34:56.328694  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.179246 (* 1 = 0.179246 loss)
I1027 19:34:56.328699  5972 solver.cpp:571] Iteration 7080, lr = 0.001
I1027 19:35:08.512812  5972 solver.cpp:242] Iteration 7100, loss = 0.426232
I1027 19:35:08.512850  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.177533 (* 1 = 0.177533 loss)
I1027 19:35:08.512854  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.248698 (* 1 = 0.248698 loss)
I1027 19:35:08.512858  5972 solver.cpp:571] Iteration 7100, lr = 0.001
I1027 19:35:20.925986  5972 solver.cpp:242] Iteration 7120, loss = 0.0703313
I1027 19:35:20.926028  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0279513 (* 1 = 0.0279513 loss)
I1027 19:35:20.926033  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.04238 (* 1 = 0.04238 loss)
I1027 19:35:20.926038  5972 solver.cpp:571] Iteration 7120, lr = 0.001
I1027 19:35:33.172945  5972 solver.cpp:242] Iteration 7140, loss = 0.128183
I1027 19:35:33.172976  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0590357 (* 1 = 0.0590357 loss)
I1027 19:35:33.172982  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0691468 (* 1 = 0.0691468 loss)
I1027 19:35:33.172987  5972 solver.cpp:571] Iteration 7140, lr = 0.001
I1027 19:35:45.539640  5972 solver.cpp:242] Iteration 7160, loss = 0.224773
I1027 19:35:45.539671  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0868125 (* 1 = 0.0868125 loss)
I1027 19:35:45.539677  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.137961 (* 1 = 0.137961 loss)
I1027 19:35:45.539682  5972 solver.cpp:571] Iteration 7160, lr = 0.001
I1027 19:35:58.016518  5972 solver.cpp:242] Iteration 7180, loss = 0.205884
I1027 19:35:58.016557  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0957719 (* 1 = 0.0957719 loss)
I1027 19:35:58.016563  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.110112 (* 1 = 0.110112 loss)
I1027 19:35:58.016567  5972 solver.cpp:571] Iteration 7180, lr = 0.001
speed: 0.596s / iter
I1027 19:36:10.305181  5972 solver.cpp:242] Iteration 7200, loss = 0.61163
I1027 19:36:10.305218  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.267058 (* 1 = 0.267058 loss)
I1027 19:36:10.305223  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.344573 (* 1 = 0.344573 loss)
I1027 19:36:10.305227  5972 solver.cpp:571] Iteration 7200, lr = 0.001
I1027 19:36:22.589151  5972 solver.cpp:242] Iteration 7220, loss = 0.164375
I1027 19:36:22.589187  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0528095 (* 1 = 0.0528095 loss)
I1027 19:36:22.589192  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.111566 (* 1 = 0.111566 loss)
I1027 19:36:22.589196  5972 solver.cpp:571] Iteration 7220, lr = 0.001
I1027 19:36:34.841526  5972 solver.cpp:242] Iteration 7240, loss = 0.327914
I1027 19:36:34.841562  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.128687 (* 1 = 0.128687 loss)
I1027 19:36:34.841567  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.199227 (* 1 = 0.199227 loss)
I1027 19:36:34.841572  5972 solver.cpp:571] Iteration 7240, lr = 0.001
I1027 19:36:47.048358  5972 solver.cpp:242] Iteration 7260, loss = 0.295666
I1027 19:36:47.048394  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0867038 (* 1 = 0.0867038 loss)
I1027 19:36:47.048399  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.208962 (* 1 = 0.208962 loss)
I1027 19:36:47.048403  5972 solver.cpp:571] Iteration 7260, lr = 0.001
I1027 19:36:59.511371  5972 solver.cpp:242] Iteration 7280, loss = 0.0367398
I1027 19:36:59.511411  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00796498 (* 1 = 0.00796498 loss)
I1027 19:36:59.511417  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0287748 (* 1 = 0.0287748 loss)
I1027 19:36:59.511422  5972 solver.cpp:571] Iteration 7280, lr = 0.001
I1027 19:37:11.655369  5972 solver.cpp:242] Iteration 7300, loss = 0.159441
I1027 19:37:11.655408  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0371265 (* 1 = 0.0371265 loss)
I1027 19:37:11.655413  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.122314 (* 1 = 0.122314 loss)
I1027 19:37:11.655418  5972 solver.cpp:571] Iteration 7300, lr = 0.001
I1027 19:37:23.920107  5972 solver.cpp:242] Iteration 7320, loss = 0.511839
I1027 19:37:23.920145  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.228758 (* 1 = 0.228758 loss)
I1027 19:37:23.920150  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.283081 (* 1 = 0.283081 loss)
I1027 19:37:23.920155  5972 solver.cpp:571] Iteration 7320, lr = 0.001
I1027 19:37:36.116004  5972 solver.cpp:242] Iteration 7340, loss = 0.746734
I1027 19:37:36.116042  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.350468 (* 1 = 0.350468 loss)
I1027 19:37:36.116047  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.396265 (* 1 = 0.396265 loss)
I1027 19:37:36.116051  5972 solver.cpp:571] Iteration 7340, lr = 0.001
I1027 19:37:48.396714  5972 solver.cpp:242] Iteration 7360, loss = 0.154597
I1027 19:37:48.396752  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0643144 (* 1 = 0.0643144 loss)
I1027 19:37:48.396757  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0902826 (* 1 = 0.0902826 loss)
I1027 19:37:48.396761  5972 solver.cpp:571] Iteration 7360, lr = 0.001
I1027 19:38:00.744038  5972 solver.cpp:242] Iteration 7380, loss = 0.0888156
I1027 19:38:00.744076  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0310621 (* 1 = 0.0310621 loss)
I1027 19:38:00.744079  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0577535 (* 1 = 0.0577535 loss)
I1027 19:38:00.744084  5972 solver.cpp:571] Iteration 7380, lr = 0.001
speed: 0.596s / iter
I1027 19:38:13.012821  5972 solver.cpp:242] Iteration 7400, loss = 0.748492
I1027 19:38:13.012857  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.326594 (* 1 = 0.326594 loss)
I1027 19:38:13.012861  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.421898 (* 1 = 0.421898 loss)
I1027 19:38:13.012866  5972 solver.cpp:571] Iteration 7400, lr = 0.001
I1027 19:38:25.408959  5972 solver.cpp:242] Iteration 7420, loss = 0.385002
I1027 19:38:25.408990  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.171213 (* 1 = 0.171213 loss)
I1027 19:38:25.408995  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.21379 (* 1 = 0.21379 loss)
I1027 19:38:25.408999  5972 solver.cpp:571] Iteration 7420, lr = 0.001
I1027 19:38:37.646865  5972 solver.cpp:242] Iteration 7440, loss = 0.521884
I1027 19:38:37.646901  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.284192 (* 1 = 0.284192 loss)
I1027 19:38:37.646916  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.237692 (* 1 = 0.237692 loss)
I1027 19:38:37.646921  5972 solver.cpp:571] Iteration 7440, lr = 0.001
I1027 19:38:49.991783  5972 solver.cpp:242] Iteration 7460, loss = 0.280461
I1027 19:38:49.991821  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.130612 (* 1 = 0.130612 loss)
I1027 19:38:49.991825  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149849 (* 1 = 0.149849 loss)
I1027 19:38:49.991830  5972 solver.cpp:571] Iteration 7460, lr = 0.001
I1027 19:39:02.258728  5972 solver.cpp:242] Iteration 7480, loss = 0.321836
I1027 19:39:02.258764  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.114187 (* 1 = 0.114187 loss)
I1027 19:39:02.258769  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.207649 (* 1 = 0.207649 loss)
I1027 19:39:02.258774  5972 solver.cpp:571] Iteration 7480, lr = 0.001
I1027 19:39:14.357811  5972 solver.cpp:242] Iteration 7500, loss = 0.104053
I1027 19:39:14.357849  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.044493 (* 1 = 0.044493 loss)
I1027 19:39:14.357854  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0595601 (* 1 = 0.0595601 loss)
I1027 19:39:14.357859  5972 solver.cpp:571] Iteration 7500, lr = 0.001
I1027 19:39:26.450340  5972 solver.cpp:242] Iteration 7520, loss = 0.205276
I1027 19:39:26.450376  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0710769 (* 1 = 0.0710769 loss)
I1027 19:39:26.450381  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.134199 (* 1 = 0.134199 loss)
I1027 19:39:26.450387  5972 solver.cpp:571] Iteration 7520, lr = 0.001
I1027 19:39:38.530112  5972 solver.cpp:242] Iteration 7540, loss = 0.272302
I1027 19:39:38.530150  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.138352 (* 1 = 0.138352 loss)
I1027 19:39:38.530154  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.133949 (* 1 = 0.133949 loss)
I1027 19:39:38.530159  5972 solver.cpp:571] Iteration 7540, lr = 0.001
I1027 19:39:50.658219  5972 solver.cpp:242] Iteration 7560, loss = 0.409953
I1027 19:39:50.658257  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.182843 (* 1 = 0.182843 loss)
I1027 19:39:50.658262  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.22711 (* 1 = 0.22711 loss)
I1027 19:39:50.658265  5972 solver.cpp:571] Iteration 7560, lr = 0.001
I1027 19:40:02.997067  5972 solver.cpp:242] Iteration 7580, loss = 0.117045
I1027 19:40:02.997104  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0410025 (* 1 = 0.0410025 loss)
I1027 19:40:02.997110  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0760424 (* 1 = 0.0760424 loss)
I1027 19:40:02.997114  5972 solver.cpp:571] Iteration 7580, lr = 0.001
speed: 0.596s / iter
I1027 19:40:15.280567  5972 solver.cpp:242] Iteration 7600, loss = 0.291084
I1027 19:40:15.280603  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.130388 (* 1 = 0.130388 loss)
I1027 19:40:15.280608  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.160695 (* 1 = 0.160695 loss)
I1027 19:40:15.280612  5972 solver.cpp:571] Iteration 7600, lr = 0.001
I1027 19:40:27.415336  5972 solver.cpp:242] Iteration 7620, loss = 0.102384
I1027 19:40:27.415374  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0332869 (* 1 = 0.0332869 loss)
I1027 19:40:27.415379  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0690969 (* 1 = 0.0690969 loss)
I1027 19:40:27.415382  5972 solver.cpp:571] Iteration 7620, lr = 0.001
I1027 19:40:39.733101  5972 solver.cpp:242] Iteration 7640, loss = 0.44696
I1027 19:40:39.733191  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.164523 (* 1 = 0.164523 loss)
I1027 19:40:39.733198  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.282437 (* 1 = 0.282437 loss)
I1027 19:40:39.733204  5972 solver.cpp:571] Iteration 7640, lr = 0.001
I1027 19:40:52.029006  5972 solver.cpp:242] Iteration 7660, loss = 0.157657
I1027 19:40:52.029047  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0607758 (* 1 = 0.0607758 loss)
I1027 19:40:52.029052  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0968815 (* 1 = 0.0968815 loss)
I1027 19:40:52.029057  5972 solver.cpp:571] Iteration 7660, lr = 0.001
I1027 19:41:04.166383  5972 solver.cpp:242] Iteration 7680, loss = 0.153343
I1027 19:41:04.166424  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0676232 (* 1 = 0.0676232 loss)
I1027 19:41:04.166430  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.08572 (* 1 = 0.08572 loss)
I1027 19:41:04.166435  5972 solver.cpp:571] Iteration 7680, lr = 0.001
I1027 19:41:16.459357  5972 solver.cpp:242] Iteration 7700, loss = 0.555923
I1027 19:41:16.459395  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.256093 (* 1 = 0.256093 loss)
I1027 19:41:16.459401  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.29983 (* 1 = 0.29983 loss)
I1027 19:41:16.459406  5972 solver.cpp:571] Iteration 7700, lr = 0.001
I1027 19:41:28.667515  5972 solver.cpp:242] Iteration 7720, loss = 0.0581222
I1027 19:41:28.667553  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0159329 (* 1 = 0.0159329 loss)
I1027 19:41:28.667558  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0421892 (* 1 = 0.0421892 loss)
I1027 19:41:28.667562  5972 solver.cpp:571] Iteration 7720, lr = 0.001
I1027 19:41:40.784790  5972 solver.cpp:242] Iteration 7740, loss = 0.0775925
I1027 19:41:40.784827  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0116758 (* 1 = 0.0116758 loss)
I1027 19:41:40.784832  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0659167 (* 1 = 0.0659167 loss)
I1027 19:41:40.784837  5972 solver.cpp:571] Iteration 7740, lr = 0.001
I1027 19:41:53.209676  5972 solver.cpp:242] Iteration 7760, loss = 0.373999
I1027 19:41:53.209712  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.139835 (* 1 = 0.139835 loss)
I1027 19:41:53.209717  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.234164 (* 1 = 0.234164 loss)
I1027 19:41:53.209722  5972 solver.cpp:571] Iteration 7760, lr = 0.001
I1027 19:42:05.452847  5972 solver.cpp:242] Iteration 7780, loss = 0.190155
I1027 19:42:05.452884  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0407183 (* 1 = 0.0407183 loss)
I1027 19:42:05.452888  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149437 (* 1 = 0.149437 loss)
I1027 19:42:05.452893  5972 solver.cpp:571] Iteration 7780, lr = 0.001
speed: 0.597s / iter
I1027 19:42:17.774768  5972 solver.cpp:242] Iteration 7800, loss = 0.19239
I1027 19:42:17.774809  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.102269 (* 1 = 0.102269 loss)
I1027 19:42:17.774814  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.090121 (* 1 = 0.090121 loss)
I1027 19:42:17.774819  5972 solver.cpp:571] Iteration 7800, lr = 0.001
I1027 19:42:30.114078  5972 solver.cpp:242] Iteration 7820, loss = 0.0487249
I1027 19:42:30.114115  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0117668 (* 1 = 0.0117668 loss)
I1027 19:42:30.114120  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0369581 (* 1 = 0.0369581 loss)
I1027 19:42:30.114125  5972 solver.cpp:571] Iteration 7820, lr = 0.001
I1027 19:42:42.321733  5972 solver.cpp:242] Iteration 7840, loss = 0.0122838
I1027 19:42:42.321774  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00441791 (* 1 = 0.00441791 loss)
I1027 19:42:42.321777  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00786587 (* 1 = 0.00786587 loss)
I1027 19:42:42.321782  5972 solver.cpp:571] Iteration 7840, lr = 0.001
I1027 19:42:54.564093  5972 solver.cpp:242] Iteration 7860, loss = 0.196489
I1027 19:42:54.564133  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0600075 (* 1 = 0.0600075 loss)
I1027 19:42:54.564138  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.136481 (* 1 = 0.136481 loss)
I1027 19:42:54.564143  5972 solver.cpp:571] Iteration 7860, lr = 0.001
I1027 19:43:06.791548  5972 solver.cpp:242] Iteration 7880, loss = 0.0957664
I1027 19:43:06.791586  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.02996 (* 1 = 0.02996 loss)
I1027 19:43:06.791591  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0658064 (* 1 = 0.0658064 loss)
I1027 19:43:06.791595  5972 solver.cpp:571] Iteration 7880, lr = 0.001
I1027 19:43:18.992112  5972 solver.cpp:242] Iteration 7900, loss = 0.0317292
I1027 19:43:18.992149  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00707403 (* 1 = 0.00707403 loss)
I1027 19:43:18.992154  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0246552 (* 1 = 0.0246552 loss)
I1027 19:43:18.992158  5972 solver.cpp:571] Iteration 7900, lr = 0.001
I1027 19:43:31.191164  5972 solver.cpp:242] Iteration 7920, loss = 0.235312
I1027 19:43:31.191215  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0778109 (* 1 = 0.0778109 loss)
I1027 19:43:31.191220  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.157501 (* 1 = 0.157501 loss)
I1027 19:43:31.191226  5972 solver.cpp:571] Iteration 7920, lr = 0.001
I1027 19:43:43.494526  5972 solver.cpp:242] Iteration 7940, loss = 0.0873387
I1027 19:43:43.494565  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0285529 (* 1 = 0.0285529 loss)
I1027 19:43:43.494570  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0587858 (* 1 = 0.0587858 loss)
I1027 19:43:43.494575  5972 solver.cpp:571] Iteration 7940, lr = 0.001
I1027 19:43:55.817078  5972 solver.cpp:242] Iteration 7960, loss = 0.0416985
I1027 19:43:55.817116  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0232025 (* 1 = 0.0232025 loss)
I1027 19:43:55.817121  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.018496 (* 1 = 0.018496 loss)
I1027 19:43:55.817126  5972 solver.cpp:571] Iteration 7960, lr = 0.001
I1027 19:44:08.141062  5972 solver.cpp:242] Iteration 7980, loss = 0.170102
I1027 19:44:08.141099  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.067918 (* 1 = 0.067918 loss)
I1027 19:44:08.141104  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.102184 (* 1 = 0.102184 loss)
I1027 19:44:08.141109  5972 solver.cpp:571] Iteration 7980, lr = 0.001
speed: 0.597s / iter
I1027 19:44:20.237915  5972 solver.cpp:242] Iteration 8000, loss = 0.283648
I1027 19:44:20.237953  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.132831 (* 1 = 0.132831 loss)
I1027 19:44:20.237958  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.150818 (* 1 = 0.150818 loss)
I1027 19:44:20.237962  5972 solver.cpp:571] Iteration 8000, lr = 0.001
I1027 19:44:32.556408  5972 solver.cpp:242] Iteration 8020, loss = 0.0506074
I1027 19:44:32.556444  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0183244 (* 1 = 0.0183244 loss)
I1027 19:44:32.556449  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0322831 (* 1 = 0.0322831 loss)
I1027 19:44:32.556454  5972 solver.cpp:571] Iteration 8020, lr = 0.001
I1027 19:44:44.766719  5972 solver.cpp:242] Iteration 8040, loss = 0.0870869
I1027 19:44:44.766757  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0274205 (* 1 = 0.0274205 loss)
I1027 19:44:44.766762  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0596664 (* 1 = 0.0596664 loss)
I1027 19:44:44.766765  5972 solver.cpp:571] Iteration 8040, lr = 0.001
I1027 19:44:56.905020  5972 solver.cpp:242] Iteration 8060, loss = 0.353542
I1027 19:44:56.905073  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.168801 (* 1 = 0.168801 loss)
I1027 19:44:56.905078  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.18474 (* 1 = 0.18474 loss)
I1027 19:44:56.905083  5972 solver.cpp:571] Iteration 8060, lr = 0.001
I1027 19:45:09.241612  5972 solver.cpp:242] Iteration 8080, loss = 0.342517
I1027 19:45:09.241654  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.163617 (* 1 = 0.163617 loss)
I1027 19:45:09.241660  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.1789 (* 1 = 0.1789 loss)
I1027 19:45:09.241665  5972 solver.cpp:571] Iteration 8080, lr = 0.001
I1027 19:45:21.612857  5972 solver.cpp:242] Iteration 8100, loss = 0.152583
I1027 19:45:21.612896  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0565614 (* 1 = 0.0565614 loss)
I1027 19:45:21.612902  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0960213 (* 1 = 0.0960213 loss)
I1027 19:45:21.612907  5972 solver.cpp:571] Iteration 8100, lr = 0.001
I1027 19:45:34.029671  5972 solver.cpp:242] Iteration 8120, loss = 0.0273064
I1027 19:45:34.029709  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0084442 (* 1 = 0.0084442 loss)
I1027 19:45:34.029714  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0188622 (* 1 = 0.0188622 loss)
I1027 19:45:34.029718  5972 solver.cpp:571] Iteration 8120, lr = 0.001
I1027 19:45:46.032776  5972 solver.cpp:242] Iteration 8140, loss = 0.457676
I1027 19:45:46.032814  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.207932 (* 1 = 0.207932 loss)
I1027 19:45:46.032819  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.249745 (* 1 = 0.249745 loss)
I1027 19:45:46.032824  5972 solver.cpp:571] Iteration 8140, lr = 0.001
I1027 19:45:58.171290  5972 solver.cpp:242] Iteration 8160, loss = 0.0466245
I1027 19:45:58.171330  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0143477 (* 1 = 0.0143477 loss)
I1027 19:45:58.171335  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0322769 (* 1 = 0.0322769 loss)
I1027 19:45:58.171339  5972 solver.cpp:571] Iteration 8160, lr = 0.001
I1027 19:46:10.574970  5972 solver.cpp:242] Iteration 8180, loss = 0.162582
I1027 19:46:10.575007  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0412235 (* 1 = 0.0412235 loss)
I1027 19:46:10.575012  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.121359 (* 1 = 0.121359 loss)
I1027 19:46:10.575016  5972 solver.cpp:571] Iteration 8180, lr = 0.001
speed: 0.598s / iter
I1027 19:46:22.768364  5972 solver.cpp:242] Iteration 8200, loss = 0.322406
I1027 19:46:22.768405  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.134408 (* 1 = 0.134408 loss)
I1027 19:46:22.768410  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.187998 (* 1 = 0.187998 loss)
I1027 19:46:22.768415  5972 solver.cpp:571] Iteration 8200, lr = 0.001
I1027 19:46:35.074955  5972 solver.cpp:242] Iteration 8220, loss = 0.0280917
I1027 19:46:35.074995  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0193059 (* 1 = 0.0193059 loss)
I1027 19:46:35.075001  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00878574 (* 1 = 0.00878574 loss)
I1027 19:46:35.075006  5972 solver.cpp:571] Iteration 8220, lr = 0.001
I1027 19:46:47.367897  5972 solver.cpp:242] Iteration 8240, loss = 0.522245
I1027 19:46:47.367935  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.20746 (* 1 = 0.20746 loss)
I1027 19:46:47.367940  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.314786 (* 1 = 0.314786 loss)
I1027 19:46:47.367945  5972 solver.cpp:571] Iteration 8240, lr = 0.001
I1027 19:46:59.608747  5972 solver.cpp:242] Iteration 8260, loss = 0.264287
I1027 19:46:59.608785  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.10378 (* 1 = 0.10378 loss)
I1027 19:46:59.608790  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.160507 (* 1 = 0.160507 loss)
I1027 19:46:59.608794  5972 solver.cpp:571] Iteration 8260, lr = 0.001
I1027 19:47:11.760938  5972 solver.cpp:242] Iteration 8280, loss = 0.177227
I1027 19:47:11.760977  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0927061 (* 1 = 0.0927061 loss)
I1027 19:47:11.760980  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0845207 (* 1 = 0.0845207 loss)
I1027 19:47:11.760985  5972 solver.cpp:571] Iteration 8280, lr = 0.001
I1027 19:47:23.825356  5972 solver.cpp:242] Iteration 8300, loss = 0.162861
I1027 19:47:23.825393  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0365099 (* 1 = 0.0365099 loss)
I1027 19:47:23.825398  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.126351 (* 1 = 0.126351 loss)
I1027 19:47:23.825402  5972 solver.cpp:571] Iteration 8300, lr = 0.001
I1027 19:47:36.119963  5972 solver.cpp:242] Iteration 8320, loss = 0.0292548
I1027 19:47:36.120000  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0187761 (* 1 = 0.0187761 loss)
I1027 19:47:36.120005  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0104787 (* 1 = 0.0104787 loss)
I1027 19:47:36.120010  5972 solver.cpp:571] Iteration 8320, lr = 0.001
I1027 19:47:48.553593  5972 solver.cpp:242] Iteration 8340, loss = 0.151088
I1027 19:47:48.553630  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0563171 (* 1 = 0.0563171 loss)
I1027 19:47:48.553635  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0947709 (* 1 = 0.0947709 loss)
I1027 19:47:48.553639  5972 solver.cpp:571] Iteration 8340, lr = 0.001
I1027 19:48:00.787403  5972 solver.cpp:242] Iteration 8360, loss = 0.0543436
I1027 19:48:00.787441  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0115267 (* 1 = 0.0115267 loss)
I1027 19:48:00.787446  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0428169 (* 1 = 0.0428169 loss)
I1027 19:48:00.787449  5972 solver.cpp:571] Iteration 8360, lr = 0.001
I1027 19:48:12.749574  5972 solver.cpp:242] Iteration 8380, loss = 0.27108
I1027 19:48:12.749613  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.114958 (* 1 = 0.114958 loss)
I1027 19:48:12.749619  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.156122 (* 1 = 0.156122 loss)
I1027 19:48:12.749622  5972 solver.cpp:571] Iteration 8380, lr = 0.001
speed: 0.598s / iter
I1027 19:48:25.074926  5972 solver.cpp:242] Iteration 8400, loss = 0.156443
I1027 19:48:25.074981  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0595725 (* 1 = 0.0595725 loss)
I1027 19:48:25.074987  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0968705 (* 1 = 0.0968705 loss)
I1027 19:48:25.074992  5972 solver.cpp:571] Iteration 8400, lr = 0.001
I1027 19:48:37.486634  5972 solver.cpp:242] Iteration 8420, loss = 0.126404
I1027 19:48:37.486675  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0423409 (* 1 = 0.0423409 loss)
I1027 19:48:37.486680  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0840628 (* 1 = 0.0840628 loss)
I1027 19:48:37.486685  5972 solver.cpp:571] Iteration 8420, lr = 0.001
I1027 19:48:49.775331  5972 solver.cpp:242] Iteration 8440, loss = 0.260881
I1027 19:48:49.775368  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.084927 (* 1 = 0.084927 loss)
I1027 19:48:49.775373  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.175954 (* 1 = 0.175954 loss)
I1027 19:48:49.775378  5972 solver.cpp:571] Iteration 8440, lr = 0.001
I1027 19:49:01.858186  5972 solver.cpp:242] Iteration 8460, loss = 0.327443
I1027 19:49:01.858225  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.165945 (* 1 = 0.165945 loss)
I1027 19:49:01.858230  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.161498 (* 1 = 0.161498 loss)
I1027 19:49:01.858234  5972 solver.cpp:571] Iteration 8460, lr = 0.001
I1027 19:49:14.141752  5972 solver.cpp:242] Iteration 8480, loss = 0.211754
I1027 19:49:14.141789  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0985726 (* 1 = 0.0985726 loss)
I1027 19:49:14.141795  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113181 (* 1 = 0.113181 loss)
I1027 19:49:14.141799  5972 solver.cpp:571] Iteration 8480, lr = 0.001
I1027 19:49:26.426082  5972 solver.cpp:242] Iteration 8500, loss = 0.0649117
I1027 19:49:26.426118  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0226893 (* 1 = 0.0226893 loss)
I1027 19:49:26.426123  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0422224 (* 1 = 0.0422224 loss)
I1027 19:49:26.426127  5972 solver.cpp:571] Iteration 8500, lr = 0.001
I1027 19:49:38.761454  5972 solver.cpp:242] Iteration 8520, loss = 0.0247597
I1027 19:49:38.761492  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.014822 (* 1 = 0.014822 loss)
I1027 19:49:38.761497  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0099377 (* 1 = 0.0099377 loss)
I1027 19:49:38.761500  5972 solver.cpp:571] Iteration 8520, lr = 0.001
I1027 19:49:51.034000  5972 solver.cpp:242] Iteration 8540, loss = 0.296832
I1027 19:49:51.034059  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.181433 (* 1 = 0.181433 loss)
I1027 19:49:51.034063  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.115399 (* 1 = 0.115399 loss)
I1027 19:49:51.034068  5972 solver.cpp:571] Iteration 8540, lr = 0.001
I1027 19:50:03.219279  5972 solver.cpp:242] Iteration 8560, loss = 0.474151
I1027 19:50:03.219321  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.125712 (* 1 = 0.125712 loss)
I1027 19:50:03.219326  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.348439 (* 1 = 0.348439 loss)
I1027 19:50:03.219331  5972 solver.cpp:571] Iteration 8560, lr = 0.001
I1027 19:50:15.489485  5972 solver.cpp:242] Iteration 8580, loss = 0.0338547
I1027 19:50:15.489522  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0106697 (* 1 = 0.0106697 loss)
I1027 19:50:15.489527  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.023185 (* 1 = 0.023185 loss)
I1027 19:50:15.489531  5972 solver.cpp:571] Iteration 8580, lr = 0.001
speed: 0.598s / iter
I1027 19:50:27.751730  5972 solver.cpp:242] Iteration 8600, loss = 0.0995228
I1027 19:50:27.751780  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479512 (* 1 = 0.0479512 loss)
I1027 19:50:27.751785  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0515716 (* 1 = 0.0515716 loss)
I1027 19:50:27.751790  5972 solver.cpp:571] Iteration 8600, lr = 0.001
I1027 19:50:40.100224  5972 solver.cpp:242] Iteration 8620, loss = 0.128692
I1027 19:50:40.100261  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0376792 (* 1 = 0.0376792 loss)
I1027 19:50:40.100266  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0910133 (* 1 = 0.0910133 loss)
I1027 19:50:40.100270  5972 solver.cpp:571] Iteration 8620, lr = 0.001
I1027 19:50:52.167865  5972 solver.cpp:242] Iteration 8640, loss = 0.228757
I1027 19:50:52.167903  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0585217 (* 1 = 0.0585217 loss)
I1027 19:50:52.167908  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.170236 (* 1 = 0.170236 loss)
I1027 19:50:52.167913  5972 solver.cpp:571] Iteration 8640, lr = 0.001
I1027 19:51:04.347287  5972 solver.cpp:242] Iteration 8660, loss = 0.214109
I1027 19:51:04.347326  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.074475 (* 1 = 0.074475 loss)
I1027 19:51:04.347332  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.139634 (* 1 = 0.139634 loss)
I1027 19:51:04.347335  5972 solver.cpp:571] Iteration 8660, lr = 0.001
I1027 19:51:16.630902  5972 solver.cpp:242] Iteration 8680, loss = 0.0291751
I1027 19:51:16.630937  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00758404 (* 1 = 0.00758404 loss)
I1027 19:51:16.630942  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0215911 (* 1 = 0.0215911 loss)
I1027 19:51:16.630946  5972 solver.cpp:571] Iteration 8680, lr = 0.001
I1027 19:51:28.761983  5972 solver.cpp:242] Iteration 8700, loss = 0.288266
I1027 19:51:28.762020  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.125432 (* 1 = 0.125432 loss)
I1027 19:51:28.762024  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.162833 (* 1 = 0.162833 loss)
I1027 19:51:28.762028  5972 solver.cpp:571] Iteration 8700, lr = 0.001
I1027 19:51:41.149485  5972 solver.cpp:242] Iteration 8720, loss = 0.469692
I1027 19:51:41.149524  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.219365 (* 1 = 0.219365 loss)
I1027 19:51:41.149530  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.250327 (* 1 = 0.250327 loss)
I1027 19:51:41.149534  5972 solver.cpp:571] Iteration 8720, lr = 0.001
I1027 19:51:53.471082  5972 solver.cpp:242] Iteration 8740, loss = 0.25763
I1027 19:51:53.471119  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11122 (* 1 = 0.11122 loss)
I1027 19:51:53.471124  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.14641 (* 1 = 0.14641 loss)
I1027 19:51:53.471129  5972 solver.cpp:571] Iteration 8740, lr = 0.001
I1027 19:52:05.657847  5972 solver.cpp:242] Iteration 8760, loss = 0.115874
I1027 19:52:05.657884  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0569309 (* 1 = 0.0569309 loss)
I1027 19:52:05.657889  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0589428 (* 1 = 0.0589428 loss)
I1027 19:52:05.657894  5972 solver.cpp:571] Iteration 8760, lr = 0.001
I1027 19:52:17.811803  5972 solver.cpp:242] Iteration 8780, loss = 0.634081
I1027 19:52:17.811841  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.277526 (* 1 = 0.277526 loss)
I1027 19:52:17.811846  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.356555 (* 1 = 0.356555 loss)
I1027 19:52:17.811851  5972 solver.cpp:571] Iteration 8780, lr = 0.001
speed: 0.599s / iter
I1027 19:52:29.850929  5972 solver.cpp:242] Iteration 8800, loss = 0.229503
I1027 19:52:29.850965  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.082334 (* 1 = 0.082334 loss)
I1027 19:52:29.850970  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.147169 (* 1 = 0.147169 loss)
I1027 19:52:29.850975  5972 solver.cpp:571] Iteration 8800, lr = 0.001
I1027 19:52:42.101825  5972 solver.cpp:242] Iteration 8820, loss = 0.217753
I1027 19:52:42.101863  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.104706 (* 1 = 0.104706 loss)
I1027 19:52:42.101879  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.113047 (* 1 = 0.113047 loss)
I1027 19:52:42.101884  5972 solver.cpp:571] Iteration 8820, lr = 0.001
I1027 19:52:54.469807  5972 solver.cpp:242] Iteration 8840, loss = 0.106095
I1027 19:52:54.469844  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0396756 (* 1 = 0.0396756 loss)
I1027 19:52:54.469848  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0664195 (* 1 = 0.0664195 loss)
I1027 19:52:54.469853  5972 solver.cpp:571] Iteration 8840, lr = 0.001
I1027 19:53:06.809576  5972 solver.cpp:242] Iteration 8860, loss = 0.259007
I1027 19:53:06.809612  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0759931 (* 1 = 0.0759931 loss)
I1027 19:53:06.809617  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.183014 (* 1 = 0.183014 loss)
I1027 19:53:06.809622  5972 solver.cpp:571] Iteration 8860, lr = 0.001
I1027 19:53:19.005319  5972 solver.cpp:242] Iteration 8880, loss = 0.362417
I1027 19:53:19.005355  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.19241 (* 1 = 0.19241 loss)
I1027 19:53:19.005360  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.170007 (* 1 = 0.170007 loss)
I1027 19:53:19.005364  5972 solver.cpp:571] Iteration 8880, lr = 0.001
I1027 19:53:31.131929  5972 solver.cpp:242] Iteration 8900, loss = 0.444097
I1027 19:53:31.131974  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.223111 (* 1 = 0.223111 loss)
I1027 19:53:31.131980  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.220986 (* 1 = 0.220986 loss)
I1027 19:53:31.131985  5972 solver.cpp:571] Iteration 8900, lr = 0.001
I1027 19:53:43.518944  5972 solver.cpp:242] Iteration 8920, loss = 0.109905
I1027 19:53:43.518985  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0478259 (* 1 = 0.0478259 loss)
I1027 19:53:43.518990  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0620786 (* 1 = 0.0620786 loss)
I1027 19:53:43.518995  5972 solver.cpp:571] Iteration 8920, lr = 0.001
I1027 19:53:55.916254  5972 solver.cpp:242] Iteration 8940, loss = 0.0368906
I1027 19:53:55.916291  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0279879 (* 1 = 0.0279879 loss)
I1027 19:53:55.916296  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0089027 (* 1 = 0.0089027 loss)
I1027 19:53:55.916301  5972 solver.cpp:571] Iteration 8940, lr = 0.001
I1027 19:54:08.142712  5972 solver.cpp:242] Iteration 8960, loss = 0.310743
I1027 19:54:08.142750  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.161438 (* 1 = 0.161438 loss)
I1027 19:54:08.142755  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.149305 (* 1 = 0.149305 loss)
I1027 19:54:08.142758  5972 solver.cpp:571] Iteration 8960, lr = 0.001
I1027 19:54:20.293054  5972 solver.cpp:242] Iteration 8980, loss = 0.146275
I1027 19:54:20.293092  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0562147 (* 1 = 0.0562147 loss)
I1027 19:54:20.293097  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0900607 (* 1 = 0.0900607 loss)
I1027 19:54:20.293100  5972 solver.cpp:571] Iteration 8980, lr = 0.001
speed: 0.599s / iter
I1027 19:54:32.471462  5972 solver.cpp:242] Iteration 9000, loss = 0.509687
I1027 19:54:32.471498  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.219731 (* 1 = 0.219731 loss)
I1027 19:54:32.471503  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.289955 (* 1 = 0.289955 loss)
I1027 19:54:32.471506  5972 solver.cpp:571] Iteration 9000, lr = 0.001
I1027 19:54:44.852447  5972 solver.cpp:242] Iteration 9020, loss = 0.0714419
I1027 19:54:44.852488  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0291598 (* 1 = 0.0291598 loss)
I1027 19:54:44.852493  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0422821 (* 1 = 0.0422821 loss)
I1027 19:54:44.852497  5972 solver.cpp:571] Iteration 9020, lr = 0.001
I1027 19:54:57.137997  5972 solver.cpp:242] Iteration 9040, loss = 0.178807
I1027 19:54:57.138038  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0991523 (* 1 = 0.0991523 loss)
I1027 19:54:57.138044  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0796544 (* 1 = 0.0796544 loss)
I1027 19:54:57.138048  5972 solver.cpp:571] Iteration 9040, lr = 0.001
I1027 19:55:09.378031  5972 solver.cpp:242] Iteration 9060, loss = 0.0600115
I1027 19:55:09.378068  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0176518 (* 1 = 0.0176518 loss)
I1027 19:55:09.378073  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0423597 (* 1 = 0.0423597 loss)
I1027 19:55:09.378077  5972 solver.cpp:571] Iteration 9060, lr = 0.001
I1027 19:55:21.584650  5972 solver.cpp:242] Iteration 9080, loss = 0.318123
I1027 19:55:21.584686  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.12289 (* 1 = 0.12289 loss)
I1027 19:55:21.584692  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.195233 (* 1 = 0.195233 loss)
I1027 19:55:21.584697  5972 solver.cpp:571] Iteration 9080, lr = 0.001
I1027 19:55:34.018817  5972 solver.cpp:242] Iteration 9100, loss = 0.411278
I1027 19:55:34.018854  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.186168 (* 1 = 0.186168 loss)
I1027 19:55:34.018859  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.22511 (* 1 = 0.22511 loss)
I1027 19:55:34.018863  5972 solver.cpp:571] Iteration 9100, lr = 0.001
I1027 19:55:46.043896  5972 solver.cpp:242] Iteration 9120, loss = 0.125005
I1027 19:55:46.043933  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0753596 (* 1 = 0.0753596 loss)
I1027 19:55:46.043938  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0496458 (* 1 = 0.0496458 loss)
I1027 19:55:46.043942  5972 solver.cpp:571] Iteration 9120, lr = 0.001
I1027 19:55:58.345974  5972 solver.cpp:242] Iteration 9140, loss = 0.0344329
I1027 19:55:58.346011  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0195753 (* 1 = 0.0195753 loss)
I1027 19:55:58.346016  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0148575 (* 1 = 0.0148575 loss)
I1027 19:55:58.346021  5972 solver.cpp:571] Iteration 9140, lr = 0.001
I1027 19:56:10.670912  5972 solver.cpp:242] Iteration 9160, loss = 0.00778678
I1027 19:56:10.670970  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00235456 (* 1 = 0.00235456 loss)
I1027 19:56:10.670976  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00543222 (* 1 = 0.00543222 loss)
I1027 19:56:10.670981  5972 solver.cpp:571] Iteration 9160, lr = 0.001
I1027 19:56:23.036221  5972 solver.cpp:242] Iteration 9180, loss = 0.195809
I1027 19:56:23.036253  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0951602 (* 1 = 0.0951602 loss)
I1027 19:56:23.036259  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.100649 (* 1 = 0.100649 loss)
I1027 19:56:23.036263  5972 solver.cpp:571] Iteration 9180, lr = 0.001
speed: 0.599s / iter
I1027 19:56:35.324458  5972 solver.cpp:242] Iteration 9200, loss = 0.0611059
I1027 19:56:35.324496  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0127426 (* 1 = 0.0127426 loss)
I1027 19:56:35.324501  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0483633 (* 1 = 0.0483633 loss)
I1027 19:56:35.324506  5972 solver.cpp:571] Iteration 9200, lr = 0.001
I1027 19:56:47.499534  5972 solver.cpp:242] Iteration 9220, loss = 0.353089
I1027 19:56:47.499572  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.103217 (* 1 = 0.103217 loss)
I1027 19:56:47.499577  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.249872 (* 1 = 0.249872 loss)
I1027 19:56:47.499582  5972 solver.cpp:571] Iteration 9220, lr = 0.001
I1027 19:56:59.643355  5972 solver.cpp:242] Iteration 9240, loss = 0.127051
I1027 19:56:59.643393  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0574088 (* 1 = 0.0574088 loss)
I1027 19:56:59.643398  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0696426 (* 1 = 0.0696426 loss)
I1027 19:56:59.643401  5972 solver.cpp:571] Iteration 9240, lr = 0.001
I1027 19:57:11.905884  5972 solver.cpp:242] Iteration 9260, loss = 0.0492459
I1027 19:57:11.905912  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0159913 (* 1 = 0.0159913 loss)
I1027 19:57:11.905916  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0332546 (* 1 = 0.0332546 loss)
I1027 19:57:11.905921  5972 solver.cpp:571] Iteration 9260, lr = 0.001
I1027 19:57:24.213205  5972 solver.cpp:242] Iteration 9280, loss = 0.262527
I1027 19:57:24.213233  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834076 (* 1 = 0.0834076 loss)
I1027 19:57:24.213238  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.17912 (* 1 = 0.17912 loss)
I1027 19:57:24.213243  5972 solver.cpp:571] Iteration 9280, lr = 0.001
I1027 19:57:36.426714  5972 solver.cpp:242] Iteration 9300, loss = 0.211793
I1027 19:57:36.426743  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.111963 (* 1 = 0.111963 loss)
I1027 19:57:36.426748  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0998305 (* 1 = 0.0998305 loss)
I1027 19:57:36.426751  5972 solver.cpp:571] Iteration 9300, lr = 0.001
I1027 19:57:48.700803  5972 solver.cpp:242] Iteration 9320, loss = 0.329979
I1027 19:57:48.700829  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.137413 (* 1 = 0.137413 loss)
I1027 19:57:48.700834  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.192566 (* 1 = 0.192566 loss)
I1027 19:57:48.700837  5972 solver.cpp:571] Iteration 9320, lr = 0.001
I1027 19:58:00.825801  5972 solver.cpp:242] Iteration 9340, loss = 0.0510003
I1027 19:58:00.825850  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0385539 (* 1 = 0.0385539 loss)
I1027 19:58:00.825855  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0124464 (* 1 = 0.0124464 loss)
I1027 19:58:00.825860  5972 solver.cpp:571] Iteration 9340, lr = 0.001
I1027 19:58:13.290357  5972 solver.cpp:242] Iteration 9360, loss = 0.0196398
I1027 19:58:13.290400  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00632989 (* 1 = 0.00632989 loss)
I1027 19:58:13.290405  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0133099 (* 1 = 0.0133099 loss)
I1027 19:58:13.290410  5972 solver.cpp:571] Iteration 9360, lr = 0.001
I1027 19:58:25.623978  5972 solver.cpp:242] Iteration 9380, loss = 0.138339
I1027 19:58:25.624017  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0401871 (* 1 = 0.0401871 loss)
I1027 19:58:25.624022  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0981514 (* 1 = 0.0981514 loss)
I1027 19:58:25.624025  5972 solver.cpp:571] Iteration 9380, lr = 0.001
speed: 0.600s / iter
I1027 19:58:37.662431  5972 solver.cpp:242] Iteration 9400, loss = 0.152993
I1027 19:58:37.662469  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0544451 (* 1 = 0.0544451 loss)
I1027 19:58:37.662474  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0985476 (* 1 = 0.0985476 loss)
I1027 19:58:37.662478  5972 solver.cpp:571] Iteration 9400, lr = 0.001
I1027 19:58:49.775156  5972 solver.cpp:242] Iteration 9420, loss = 0.0544316
I1027 19:58:49.775193  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0371509 (* 1 = 0.0371509 loss)
I1027 19:58:49.775198  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0172808 (* 1 = 0.0172808 loss)
I1027 19:58:49.775202  5972 solver.cpp:571] Iteration 9420, lr = 0.001
I1027 19:59:01.990703  5972 solver.cpp:242] Iteration 9440, loss = 0.227963
I1027 19:59:01.990742  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.100486 (* 1 = 0.100486 loss)
I1027 19:59:01.990747  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.127478 (* 1 = 0.127478 loss)
I1027 19:59:01.990751  5972 solver.cpp:571] Iteration 9440, lr = 0.001
I1027 19:59:14.261047  5972 solver.cpp:242] Iteration 9460, loss = 0.108182
I1027 19:59:14.261083  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0342108 (* 1 = 0.0342108 loss)
I1027 19:59:14.261088  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0739712 (* 1 = 0.0739712 loss)
I1027 19:59:14.261092  5972 solver.cpp:571] Iteration 9460, lr = 0.001
I1027 19:59:26.613693  5972 solver.cpp:242] Iteration 9480, loss = 0.404673
I1027 19:59:26.613732  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.181963 (* 1 = 0.181963 loss)
I1027 19:59:26.613737  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.222709 (* 1 = 0.222709 loss)
I1027 19:59:26.613742  5972 solver.cpp:571] Iteration 9480, lr = 0.001
I1027 19:59:38.859393  5972 solver.cpp:242] Iteration 9500, loss = 0.0477084
I1027 19:59:38.859432  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0146217 (* 1 = 0.0146217 loss)
I1027 19:59:38.859437  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0330867 (* 1 = 0.0330867 loss)
I1027 19:59:38.859442  5972 solver.cpp:571] Iteration 9500, lr = 0.001
I1027 19:59:50.985788  5972 solver.cpp:242] Iteration 9520, loss = 0.259148
I1027 19:59:50.985818  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.120949 (* 1 = 0.120949 loss)
I1027 19:59:50.985826  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.138199 (* 1 = 0.138199 loss)
I1027 19:59:50.985843  5972 solver.cpp:571] Iteration 9520, lr = 0.001
I1027 20:00:03.210325  5972 solver.cpp:242] Iteration 9540, loss = 0.575218
I1027 20:00:03.210355  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.229483 (* 1 = 0.229483 loss)
I1027 20:00:03.210362  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.345735 (* 1 = 0.345735 loss)
I1027 20:00:03.210379  5972 solver.cpp:571] Iteration 9540, lr = 0.001
I1027 20:00:15.533076  5972 solver.cpp:242] Iteration 9560, loss = 0.102624
I1027 20:00:15.533113  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0276266 (* 1 = 0.0276266 loss)
I1027 20:00:15.533121  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0749975 (* 1 = 0.0749975 loss)
I1027 20:00:15.533138  5972 solver.cpp:571] Iteration 9560, lr = 0.001
I1027 20:00:27.870146  5972 solver.cpp:242] Iteration 9580, loss = 0.0514057
I1027 20:00:27.870173  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0226832 (* 1 = 0.0226832 loss)
I1027 20:00:27.870182  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0287225 (* 1 = 0.0287225 loss)
I1027 20:00:27.870198  5972 solver.cpp:571] Iteration 9580, lr = 0.001
speed: 0.600s / iter
I1027 20:00:40.147702  5972 solver.cpp:242] Iteration 9600, loss = 0.273098
I1027 20:00:40.147732  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0721236 (* 1 = 0.0721236 loss)
I1027 20:00:40.147739  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.200975 (* 1 = 0.200975 loss)
I1027 20:00:40.147755  5972 solver.cpp:571] Iteration 9600, lr = 0.001
I1027 20:00:52.428320  5972 solver.cpp:242] Iteration 9620, loss = 0.238692
I1027 20:00:52.428354  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0798931 (* 1 = 0.0798931 loss)
I1027 20:00:52.428361  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.158798 (* 1 = 0.158798 loss)
I1027 20:00:52.428378  5972 solver.cpp:571] Iteration 9620, lr = 0.001
I1027 20:01:04.744583  5972 solver.cpp:242] Iteration 9640, loss = 0.0952074
I1027 20:01:04.744616  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0451432 (* 1 = 0.0451432 loss)
I1027 20:01:04.744624  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0500642 (* 1 = 0.0500642 loss)
I1027 20:01:04.744632  5972 solver.cpp:571] Iteration 9640, lr = 0.001
I1027 20:01:16.959396  5972 solver.cpp:242] Iteration 9660, loss = 0.248295
I1027 20:01:16.959425  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.11005 (* 1 = 0.11005 loss)
I1027 20:01:16.959434  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.138245 (* 1 = 0.138245 loss)
I1027 20:01:16.959450  5972 solver.cpp:571] Iteration 9660, lr = 0.001
I1027 20:01:28.977068  5972 solver.cpp:242] Iteration 9680, loss = 0.0956416
I1027 20:01:28.977100  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0225113 (* 1 = 0.0225113 loss)
I1027 20:01:28.977108  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0731303 (* 1 = 0.0731303 loss)
I1027 20:01:28.977124  5972 solver.cpp:571] Iteration 9680, lr = 0.001
I1027 20:01:41.057507  5972 solver.cpp:242] Iteration 9700, loss = 0.158659
I1027 20:01:41.057538  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0489515 (* 1 = 0.0489515 loss)
I1027 20:01:41.057546  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.109707 (* 1 = 0.109707 loss)
I1027 20:01:41.057564  5972 solver.cpp:571] Iteration 9700, lr = 0.001
I1027 20:01:53.280510  5972 solver.cpp:242] Iteration 9720, loss = 0.249403
I1027 20:01:53.280539  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.106407 (* 1 = 0.106407 loss)
I1027 20:01:53.280547  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.142996 (* 1 = 0.142996 loss)
I1027 20:01:53.280565  5972 solver.cpp:571] Iteration 9720, lr = 0.001
I1027 20:02:05.420447  5972 solver.cpp:242] Iteration 9740, loss = 0.773256
I1027 20:02:05.420476  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.336942 (* 1 = 0.336942 loss)
I1027 20:02:05.420483  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.436314 (* 1 = 0.436314 loss)
I1027 20:02:05.420500  5972 solver.cpp:571] Iteration 9740, lr = 0.001
I1027 20:02:17.567854  5972 solver.cpp:242] Iteration 9760, loss = 0.0311433
I1027 20:02:17.567884  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0167584 (* 1 = 0.0167584 loss)
I1027 20:02:17.567893  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0143849 (* 1 = 0.0143849 loss)
I1027 20:02:17.567909  5972 solver.cpp:571] Iteration 9760, lr = 0.001
I1027 20:02:29.887070  5972 solver.cpp:242] Iteration 9780, loss = 0.462716
I1027 20:02:29.887100  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.174395 (* 1 = 0.174395 loss)
I1027 20:02:29.887107  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.288321 (* 1 = 0.288321 loss)
I1027 20:02:29.887123  5972 solver.cpp:571] Iteration 9780, lr = 0.001
speed: 0.600s / iter
I1027 20:02:42.298149  5972 solver.cpp:242] Iteration 9800, loss = 0.227411
I1027 20:02:42.298195  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0996968 (* 1 = 0.0996968 loss)
I1027 20:02:42.298202  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.127714 (* 1 = 0.127714 loss)
I1027 20:02:42.298210  5972 solver.cpp:571] Iteration 9800, lr = 0.001
I1027 20:02:54.654222  5972 solver.cpp:242] Iteration 9820, loss = 0.119832
I1027 20:02:54.654253  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0325113 (* 1 = 0.0325113 loss)
I1027 20:02:54.654260  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0873204 (* 1 = 0.0873204 loss)
I1027 20:02:54.654278  5972 solver.cpp:571] Iteration 9820, lr = 0.001
I1027 20:03:06.746673  5972 solver.cpp:242] Iteration 9840, loss = 0.0143888
I1027 20:03:06.746702  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.00309963 (* 1 = 0.00309963 loss)
I1027 20:03:06.746711  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0112892 (* 1 = 0.0112892 loss)
I1027 20:03:06.746726  5972 solver.cpp:571] Iteration 9840, lr = 0.001
I1027 20:03:18.939807  5972 solver.cpp:242] Iteration 9860, loss = 0.0212203
I1027 20:03:18.939837  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.014396 (* 1 = 0.014396 loss)
I1027 20:03:18.939844  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.00682425 (* 1 = 0.00682425 loss)
I1027 20:03:18.939851  5972 solver.cpp:571] Iteration 9860, lr = 0.001
I1027 20:03:31.144965  5972 solver.cpp:242] Iteration 9880, loss = 0.0817642
I1027 20:03:31.144997  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0374478 (* 1 = 0.0374478 loss)
I1027 20:03:31.145005  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0443165 (* 1 = 0.0443165 loss)
I1027 20:03:31.145011  5972 solver.cpp:571] Iteration 9880, lr = 0.001
I1027 20:03:43.364801  5972 solver.cpp:242] Iteration 9900, loss = 0.452274
I1027 20:03:43.364837  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.163825 (* 1 = 0.163825 loss)
I1027 20:03:43.364841  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.288449 (* 1 = 0.288449 loss)
I1027 20:03:43.364846  5972 solver.cpp:571] Iteration 9900, lr = 0.001
I1027 20:03:55.589964  5972 solver.cpp:242] Iteration 9920, loss = 0.169464
I1027 20:03:55.590003  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0772044 (* 1 = 0.0772044 loss)
I1027 20:03:55.590008  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0922595 (* 1 = 0.0922595 loss)
I1027 20:03:55.590011  5972 solver.cpp:571] Iteration 9920, lr = 0.001
I1027 20:04:07.806218  5972 solver.cpp:242] Iteration 9940, loss = 0.153767
I1027 20:04:07.806254  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0521669 (* 1 = 0.0521669 loss)
I1027 20:04:07.806259  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.1016 (* 1 = 0.1016 loss)
I1027 20:04:07.806263  5972 solver.cpp:571] Iteration 9940, lr = 0.001
I1027 20:04:19.979920  5972 solver.cpp:242] Iteration 9960, loss = 0.0768638
I1027 20:04:19.979959  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.024073 (* 1 = 0.024073 loss)
I1027 20:04:19.979964  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.0527909 (* 1 = 0.0527909 loss)
I1027 20:04:19.979969  5972 solver.cpp:571] Iteration 9960, lr = 0.001
I1027 20:04:32.084038  5972 solver.cpp:242] Iteration 9980, loss = 0.226264
I1027 20:04:32.084089  5972 solver.cpp:258]     Train net output #0: loss_bbox = 0.0757985 (* 1 = 0.0757985 loss)
I1027 20:04:32.084095  5972 solver.cpp:258]     Train net output #1: loss_cls = 0.150466 (* 1 = 0.150466 loss)
I1027 20:04:32.084100  5972 solver.cpp:571] Iteration 9980, lr = 0.001
speed: 0.600s / iter
Wrote snapshot to: /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_fast_rcnn_stage2_iter_10000.caffemodel
done solving
cp /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/vgg16_fast_rcnn_stage2_iter_10000.caffemodel -> /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/VGG16_faster_rcnn_final.caffemodel
Final model: /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/VGG16_faster_rcnn_final.caffemodel

real	100m21.578s
user	85m44.306s
sys	13m44.291s
+ set +x
+ ./tools/test_net.py --gpu 0 --def models/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt --net /home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/VGG16_faster_rcnn_final.caffemodel --imdb KakouTest --cfg experiments/cfgs/faster_rcnn_alt_opt.yml
Called with args:
Namespace(caffemodel='/home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTrain/VGG16_faster_rcnn_final.caffemodel', cfg_file='experiments/cfgs/faster_rcnn_alt_opt.yml', comp_mode=False, gpu_id=0, imdb_name='KakouTest', prototxt='models/VGG16/faster_rcnn_alt_opt/faster_rcnn_test.pt', set_cfgs=None, wait=True)
Using config:
{'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_alt_opt',
 'GPU_ID': 0,
 'PIXEL_MEANS': array([[[ 130.9801,  130.9465,  130.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/bsl/KITTI-detection',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1250,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 10,
          'RPN_NMS_THRESH': 0.5,
          'RPN_POST_NMS_TOP_N': 2000,
          'RPN_PRE_NMS_TOP_N': 12000,
          'SCALES': [382],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1250,
           'PROPOSAL_METHOD': 'selective_search',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 10,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.5,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [370],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1027 20:04:54.848768  6776 net.cpp:50] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
input: "data"
input: "im_info"
state {
  phase: TEST
}
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}
input_shape {
  dim: 1
  dim: 3
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  inner_product_param {
    num_output: 8
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  inner_product_param {
    num_output: 32
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
I1027 20:04:54.848891  6776 net.cpp:435] Input 0 -> data
I1027 20:04:54.848906  6776 net.cpp:435] Input 1 -> im_info
I1027 20:04:54.848917  6776 layer_factory.hpp:76] Creating layer conv1_1
I1027 20:04:54.848925  6776 net.cpp:110] Creating Layer conv1_1
I1027 20:04:54.848929  6776 net.cpp:477] conv1_1 <- data
I1027 20:04:54.848935  6776 net.cpp:433] conv1_1 -> conv1_1
I1027 20:04:54.910576  6776 net.cpp:155] Setting up conv1_1
I1027 20:04:54.910601  6776 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1027 20:04:54.910619  6776 layer_factory.hpp:76] Creating layer relu1_1
I1027 20:04:54.910631  6776 net.cpp:110] Creating Layer relu1_1
I1027 20:04:54.910640  6776 net.cpp:477] relu1_1 <- conv1_1
I1027 20:04:54.910646  6776 net.cpp:419] relu1_1 -> conv1_1 (in-place)
I1027 20:04:54.910668  6776 net.cpp:155] Setting up relu1_1
I1027 20:04:54.910676  6776 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1027 20:04:54.910679  6776 layer_factory.hpp:76] Creating layer conv1_2
I1027 20:04:54.910689  6776 net.cpp:110] Creating Layer conv1_2
I1027 20:04:54.910696  6776 net.cpp:477] conv1_2 <- conv1_1
I1027 20:04:54.910701  6776 net.cpp:433] conv1_2 -> conv1_2
I1027 20:04:54.910796  6776 net.cpp:155] Setting up conv1_2
I1027 20:04:54.910806  6776 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1027 20:04:54.910816  6776 layer_factory.hpp:76] Creating layer relu1_2
I1027 20:04:54.910823  6776 net.cpp:110] Creating Layer relu1_2
I1027 20:04:54.910828  6776 net.cpp:477] relu1_2 <- conv1_2
I1027 20:04:54.910835  6776 net.cpp:419] relu1_2 -> conv1_2 (in-place)
I1027 20:04:54.910841  6776 net.cpp:155] Setting up relu1_2
I1027 20:04:54.910846  6776 net.cpp:163] Top shape: 1 64 224 224 (3211264)
I1027 20:04:54.910851  6776 layer_factory.hpp:76] Creating layer pool1
I1027 20:04:54.910857  6776 net.cpp:110] Creating Layer pool1
I1027 20:04:54.910861  6776 net.cpp:477] pool1 <- conv1_2
I1027 20:04:54.910868  6776 net.cpp:433] pool1 -> pool1
I1027 20:04:54.910878  6776 net.cpp:155] Setting up pool1
I1027 20:04:54.910884  6776 net.cpp:163] Top shape: 1 64 112 112 (802816)
I1027 20:04:54.910887  6776 layer_factory.hpp:76] Creating layer conv2_1
I1027 20:04:54.910904  6776 net.cpp:110] Creating Layer conv2_1
I1027 20:04:54.910908  6776 net.cpp:477] conv2_1 <- pool1
I1027 20:04:54.910912  6776 net.cpp:433] conv2_1 -> conv2_1
I1027 20:04:54.911550  6776 net.cpp:155] Setting up conv2_1
I1027 20:04:54.911561  6776 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1027 20:04:54.911571  6776 layer_factory.hpp:76] Creating layer relu2_1
I1027 20:04:54.911579  6776 net.cpp:110] Creating Layer relu2_1
I1027 20:04:54.911584  6776 net.cpp:477] relu2_1 <- conv2_1
I1027 20:04:54.911590  6776 net.cpp:419] relu2_1 -> conv2_1 (in-place)
I1027 20:04:54.911598  6776 net.cpp:155] Setting up relu2_1
I1027 20:04:54.911614  6776 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1027 20:04:54.911618  6776 layer_factory.hpp:76] Creating layer conv2_2
I1027 20:04:54.911624  6776 net.cpp:110] Creating Layer conv2_2
I1027 20:04:54.911628  6776 net.cpp:477] conv2_2 <- conv2_1
I1027 20:04:54.911634  6776 net.cpp:433] conv2_2 -> conv2_2
I1027 20:04:54.911764  6776 net.cpp:155] Setting up conv2_2
I1027 20:04:54.911773  6776 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1027 20:04:54.911780  6776 layer_factory.hpp:76] Creating layer relu2_2
I1027 20:04:54.911798  6776 net.cpp:110] Creating Layer relu2_2
I1027 20:04:54.911803  6776 net.cpp:477] relu2_2 <- conv2_2
I1027 20:04:54.911809  6776 net.cpp:419] relu2_2 -> conv2_2 (in-place)
I1027 20:04:54.911816  6776 net.cpp:155] Setting up relu2_2
I1027 20:04:54.911823  6776 net.cpp:163] Top shape: 1 128 112 112 (1605632)
I1027 20:04:54.911826  6776 layer_factory.hpp:76] Creating layer pool2
I1027 20:04:54.911841  6776 net.cpp:110] Creating Layer pool2
I1027 20:04:54.911845  6776 net.cpp:477] pool2 <- conv2_2
I1027 20:04:54.911850  6776 net.cpp:433] pool2 -> pool2
I1027 20:04:54.911859  6776 net.cpp:155] Setting up pool2
I1027 20:04:54.911864  6776 net.cpp:163] Top shape: 1 128 56 56 (401408)
I1027 20:04:54.911867  6776 layer_factory.hpp:76] Creating layer conv3_1
I1027 20:04:54.911872  6776 net.cpp:110] Creating Layer conv3_1
I1027 20:04:54.911876  6776 net.cpp:477] conv3_1 <- pool2
I1027 20:04:54.911881  6776 net.cpp:433] conv3_1 -> conv3_1
I1027 20:04:54.912449  6776 net.cpp:155] Setting up conv3_1
I1027 20:04:54.912461  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.912472  6776 layer_factory.hpp:76] Creating layer relu3_1
I1027 20:04:54.912478  6776 net.cpp:110] Creating Layer relu3_1
I1027 20:04:54.912482  6776 net.cpp:477] relu3_1 <- conv3_1
I1027 20:04:54.912489  6776 net.cpp:419] relu3_1 -> conv3_1 (in-place)
I1027 20:04:54.912497  6776 net.cpp:155] Setting up relu3_1
I1027 20:04:54.912503  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.912508  6776 layer_factory.hpp:76] Creating layer conv3_2
I1027 20:04:54.912513  6776 net.cpp:110] Creating Layer conv3_2
I1027 20:04:54.912518  6776 net.cpp:477] conv3_2 <- conv3_1
I1027 20:04:54.912523  6776 net.cpp:433] conv3_2 -> conv3_2
I1027 20:04:54.913446  6776 net.cpp:155] Setting up conv3_2
I1027 20:04:54.913456  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.913465  6776 layer_factory.hpp:76] Creating layer relu3_2
I1027 20:04:54.913472  6776 net.cpp:110] Creating Layer relu3_2
I1027 20:04:54.913476  6776 net.cpp:477] relu3_2 <- conv3_2
I1027 20:04:54.913482  6776 net.cpp:419] relu3_2 -> conv3_2 (in-place)
I1027 20:04:54.913498  6776 net.cpp:155] Setting up relu3_2
I1027 20:04:54.913503  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.913507  6776 layer_factory.hpp:76] Creating layer conv3_3
I1027 20:04:54.913513  6776 net.cpp:110] Creating Layer conv3_3
I1027 20:04:54.913517  6776 net.cpp:477] conv3_3 <- conv3_2
I1027 20:04:54.913522  6776 net.cpp:433] conv3_3 -> conv3_3
I1027 20:04:54.914408  6776 net.cpp:155] Setting up conv3_3
I1027 20:04:54.914418  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.914425  6776 layer_factory.hpp:76] Creating layer relu3_3
I1027 20:04:54.914432  6776 net.cpp:110] Creating Layer relu3_3
I1027 20:04:54.914436  6776 net.cpp:477] relu3_3 <- conv3_3
I1027 20:04:54.914451  6776 net.cpp:419] relu3_3 -> conv3_3 (in-place)
I1027 20:04:54.914458  6776 net.cpp:155] Setting up relu3_3
I1027 20:04:54.914463  6776 net.cpp:163] Top shape: 1 256 56 56 (802816)
I1027 20:04:54.914466  6776 layer_factory.hpp:76] Creating layer pool3
I1027 20:04:54.914484  6776 net.cpp:110] Creating Layer pool3
I1027 20:04:54.914487  6776 net.cpp:477] pool3 <- conv3_3
I1027 20:04:54.914492  6776 net.cpp:433] pool3 -> pool3
I1027 20:04:54.914501  6776 net.cpp:155] Setting up pool3
I1027 20:04:54.914507  6776 net.cpp:163] Top shape: 1 256 28 28 (200704)
I1027 20:04:54.914511  6776 layer_factory.hpp:76] Creating layer conv4_1
I1027 20:04:54.914520  6776 net.cpp:110] Creating Layer conv4_1
I1027 20:04:54.914523  6776 net.cpp:477] conv4_1 <- pool3
I1027 20:04:54.914530  6776 net.cpp:433] conv4_1 -> conv4_1
I1027 20:04:54.916425  6776 net.cpp:155] Setting up conv4_1
I1027 20:04:54.916443  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.916452  6776 layer_factory.hpp:76] Creating layer relu4_1
I1027 20:04:54.916460  6776 net.cpp:110] Creating Layer relu4_1
I1027 20:04:54.916465  6776 net.cpp:477] relu4_1 <- conv4_1
I1027 20:04:54.916472  6776 net.cpp:419] relu4_1 -> conv4_1 (in-place)
I1027 20:04:54.916481  6776 net.cpp:155] Setting up relu4_1
I1027 20:04:54.916491  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.916496  6776 layer_factory.hpp:76] Creating layer conv4_2
I1027 20:04:54.916502  6776 net.cpp:110] Creating Layer conv4_2
I1027 20:04:54.916506  6776 net.cpp:477] conv4_2 <- conv4_1
I1027 20:04:54.916512  6776 net.cpp:433] conv4_2 -> conv4_2
I1027 20:04:54.920279  6776 net.cpp:155] Setting up conv4_2
I1027 20:04:54.920308  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.920336  6776 layer_factory.hpp:76] Creating layer relu4_2
I1027 20:04:54.920348  6776 net.cpp:110] Creating Layer relu4_2
I1027 20:04:54.920358  6776 net.cpp:477] relu4_2 <- conv4_2
I1027 20:04:54.920372  6776 net.cpp:419] relu4_2 -> conv4_2 (in-place)
I1027 20:04:54.920382  6776 net.cpp:155] Setting up relu4_2
I1027 20:04:54.920389  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.920394  6776 layer_factory.hpp:76] Creating layer conv4_3
I1027 20:04:54.920402  6776 net.cpp:110] Creating Layer conv4_3
I1027 20:04:54.920405  6776 net.cpp:477] conv4_3 <- conv4_2
I1027 20:04:54.920411  6776 net.cpp:433] conv4_3 -> conv4_3
I1027 20:04:54.923671  6776 net.cpp:155] Setting up conv4_3
I1027 20:04:54.923694  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.923715  6776 layer_factory.hpp:76] Creating layer relu4_3
I1027 20:04:54.923728  6776 net.cpp:110] Creating Layer relu4_3
I1027 20:04:54.923738  6776 net.cpp:477] relu4_3 <- conv4_3
I1027 20:04:54.923748  6776 net.cpp:419] relu4_3 -> conv4_3 (in-place)
I1027 20:04:54.923761  6776 net.cpp:155] Setting up relu4_3
I1027 20:04:54.923768  6776 net.cpp:163] Top shape: 1 512 28 28 (401408)
I1027 20:04:54.923773  6776 layer_factory.hpp:76] Creating layer pool4
I1027 20:04:54.923779  6776 net.cpp:110] Creating Layer pool4
I1027 20:04:54.923784  6776 net.cpp:477] pool4 <- conv4_3
I1027 20:04:54.923790  6776 net.cpp:433] pool4 -> pool4
I1027 20:04:54.923800  6776 net.cpp:155] Setting up pool4
I1027 20:04:54.923807  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.923811  6776 layer_factory.hpp:76] Creating layer conv5_1
I1027 20:04:54.923818  6776 net.cpp:110] Creating Layer conv5_1
I1027 20:04:54.923822  6776 net.cpp:477] conv5_1 <- pool4
I1027 20:04:54.923835  6776 net.cpp:433] conv5_1 -> conv5_1
I1027 20:04:54.927175  6776 net.cpp:155] Setting up conv5_1
I1027 20:04:54.927208  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.927222  6776 layer_factory.hpp:76] Creating layer relu5_1
I1027 20:04:54.927232  6776 net.cpp:110] Creating Layer relu5_1
I1027 20:04:54.927238  6776 net.cpp:477] relu5_1 <- conv5_1
I1027 20:04:54.927248  6776 net.cpp:419] relu5_1 -> conv5_1 (in-place)
I1027 20:04:54.927260  6776 net.cpp:155] Setting up relu5_1
I1027 20:04:54.927268  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.927273  6776 layer_factory.hpp:76] Creating layer conv5_2
I1027 20:04:54.927281  6776 net.cpp:110] Creating Layer conv5_2
I1027 20:04:54.927285  6776 net.cpp:477] conv5_2 <- conv5_1
I1027 20:04:54.927291  6776 net.cpp:433] conv5_2 -> conv5_2
I1027 20:04:54.930599  6776 net.cpp:155] Setting up conv5_2
I1027 20:04:54.930621  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.930642  6776 layer_factory.hpp:76] Creating layer relu5_2
I1027 20:04:54.930654  6776 net.cpp:110] Creating Layer relu5_2
I1027 20:04:54.930660  6776 net.cpp:477] relu5_2 <- conv5_2
I1027 20:04:54.930668  6776 net.cpp:419] relu5_2 -> conv5_2 (in-place)
I1027 20:04:54.930681  6776 net.cpp:155] Setting up relu5_2
I1027 20:04:54.930688  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.930692  6776 layer_factory.hpp:76] Creating layer conv5_3
I1027 20:04:54.930701  6776 net.cpp:110] Creating Layer conv5_3
I1027 20:04:54.930704  6776 net.cpp:477] conv5_3 <- conv5_2
I1027 20:04:54.930711  6776 net.cpp:433] conv5_3 -> conv5_3
I1027 20:04:54.934154  6776 net.cpp:155] Setting up conv5_3
I1027 20:04:54.934177  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.934190  6776 layer_factory.hpp:76] Creating layer relu5_3
I1027 20:04:54.934209  6776 net.cpp:110] Creating Layer relu5_3
I1027 20:04:54.934216  6776 net.cpp:477] relu5_3 <- conv5_3
I1027 20:04:54.934223  6776 net.cpp:419] relu5_3 -> conv5_3 (in-place)
I1027 20:04:54.934234  6776 net.cpp:155] Setting up relu5_3
I1027 20:04:54.934242  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.934247  6776 layer_factory.hpp:76] Creating layer conv5_3_relu5_3_0_split
I1027 20:04:54.934258  6776 net.cpp:110] Creating Layer conv5_3_relu5_3_0_split
I1027 20:04:54.934264  6776 net.cpp:477] conv5_3_relu5_3_0_split <- conv5_3
I1027 20:04:54.934269  6776 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I1027 20:04:54.934278  6776 net.cpp:433] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I1027 20:04:54.934285  6776 net.cpp:155] Setting up conv5_3_relu5_3_0_split
I1027 20:04:54.934293  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.934298  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.934301  6776 layer_factory.hpp:76] Creating layer rpn_conv/3x3
I1027 20:04:54.934312  6776 net.cpp:110] Creating Layer rpn_conv/3x3
I1027 20:04:54.934317  6776 net.cpp:477] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I1027 20:04:54.934324  6776 net.cpp:433] rpn_conv/3x3 -> rpn/output
I1027 20:04:54.937713  6776 net.cpp:155] Setting up rpn_conv/3x3
I1027 20:04:54.937738  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.937749  6776 layer_factory.hpp:76] Creating layer rpn_relu/3x3
I1027 20:04:54.937767  6776 net.cpp:110] Creating Layer rpn_relu/3x3
I1027 20:04:54.937779  6776 net.cpp:477] rpn_relu/3x3 <- rpn/output
I1027 20:04:54.937790  6776 net.cpp:419] rpn_relu/3x3 -> rpn/output (in-place)
I1027 20:04:54.937805  6776 net.cpp:155] Setting up rpn_relu/3x3
I1027 20:04:54.937813  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.937818  6776 layer_factory.hpp:76] Creating layer rpn/output_rpn_relu/3x3_0_split
I1027 20:04:54.937824  6776 net.cpp:110] Creating Layer rpn/output_rpn_relu/3x3_0_split
I1027 20:04:54.937829  6776 net.cpp:477] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I1027 20:04:54.937835  6776 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I1027 20:04:54.937842  6776 net.cpp:433] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I1027 20:04:54.937850  6776 net.cpp:155] Setting up rpn/output_rpn_relu/3x3_0_split
I1027 20:04:54.937857  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.937872  6776 net.cpp:163] Top shape: 1 512 14 14 (100352)
I1027 20:04:54.937876  6776 layer_factory.hpp:76] Creating layer rpn_cls_score
I1027 20:04:54.937893  6776 net.cpp:110] Creating Layer rpn_cls_score
I1027 20:04:54.937898  6776 net.cpp:477] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I1027 20:04:54.937906  6776 net.cpp:433] rpn_cls_score -> rpn_cls_score
I1027 20:04:54.937971  6776 net.cpp:155] Setting up rpn_cls_score
I1027 20:04:54.937980  6776 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1027 20:04:54.937988  6776 layer_factory.hpp:76] Creating layer rpn_bbox_pred
I1027 20:04:54.937994  6776 net.cpp:110] Creating Layer rpn_bbox_pred
I1027 20:04:54.937999  6776 net.cpp:477] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I1027 20:04:54.938005  6776 net.cpp:433] rpn_bbox_pred -> rpn_bbox_pred
I1027 20:04:54.938060  6776 net.cpp:155] Setting up rpn_bbox_pred
I1027 20:04:54.938066  6776 net.cpp:163] Top shape: 1 36 14 14 (7056)
I1027 20:04:54.938073  6776 layer_factory.hpp:76] Creating layer rpn_cls_score_reshape
I1027 20:04:54.938081  6776 net.cpp:110] Creating Layer rpn_cls_score_reshape
I1027 20:04:54.938086  6776 net.cpp:477] rpn_cls_score_reshape <- rpn_cls_score
I1027 20:04:54.938091  6776 net.cpp:433] rpn_cls_score_reshape -> rpn_cls_score_reshape
I1027 20:04:54.938102  6776 net.cpp:155] Setting up rpn_cls_score_reshape
I1027 20:04:54.938107  6776 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1027 20:04:54.938112  6776 layer_factory.hpp:76] Creating layer rpn_cls_prob
I1027 20:04:54.938118  6776 net.cpp:110] Creating Layer rpn_cls_prob
I1027 20:04:54.938122  6776 net.cpp:477] rpn_cls_prob <- rpn_cls_score_reshape
I1027 20:04:54.938129  6776 net.cpp:433] rpn_cls_prob -> rpn_cls_prob
I1027 20:04:54.938156  6776 net.cpp:155] Setting up rpn_cls_prob
I1027 20:04:54.938163  6776 net.cpp:163] Top shape: 1 2 126 14 (3528)
I1027 20:04:54.938168  6776 layer_factory.hpp:76] Creating layer rpn_cls_prob_reshape
I1027 20:04:54.938174  6776 net.cpp:110] Creating Layer rpn_cls_prob_reshape
I1027 20:04:54.938177  6776 net.cpp:477] rpn_cls_prob_reshape <- rpn_cls_prob
I1027 20:04:54.938185  6776 net.cpp:433] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I1027 20:04:54.938194  6776 net.cpp:155] Setting up rpn_cls_prob_reshape
I1027 20:04:54.938199  6776 net.cpp:163] Top shape: 1 18 14 14 (3528)
I1027 20:04:54.938204  6776 layer_factory.hpp:76] Creating layer proposal
I1027 20:04:54.955591  6776 net.cpp:110] Creating Layer proposal
I1027 20:04:54.955606  6776 net.cpp:477] proposal <- rpn_cls_prob_reshape
I1027 20:04:54.955621  6776 net.cpp:477] proposal <- rpn_bbox_pred
I1027 20:04:54.955624  6776 net.cpp:477] proposal <- im_info
I1027 20:04:54.955628  6776 net.cpp:433] proposal -> rois
I1027 20:04:54.956068  6776 net.cpp:155] Setting up proposal
I1027 20:04:54.956089  6776 net.cpp:163] Top shape: 1 5 (5)
I1027 20:04:54.956092  6776 layer_factory.hpp:76] Creating layer roi_pool5
I1027 20:04:54.956102  6776 net.cpp:110] Creating Layer roi_pool5
I1027 20:04:54.956107  6776 net.cpp:477] roi_pool5 <- conv5_3_relu5_3_0_split_1
I1027 20:04:54.956112  6776 net.cpp:477] roi_pool5 <- rois
I1027 20:04:54.956118  6776 net.cpp:433] roi_pool5 -> pool5
I1027 20:04:54.956126  6776 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I1027 20:04:54.956140  6776 net.cpp:155] Setting up roi_pool5
I1027 20:04:54.956146  6776 net.cpp:163] Top shape: 1 512 7 7 (25088)
I1027 20:04:54.956149  6776 layer_factory.hpp:76] Creating layer fc6
I1027 20:04:54.956156  6776 net.cpp:110] Creating Layer fc6
I1027 20:04:54.956159  6776 net.cpp:477] fc6 <- pool5
I1027 20:04:54.956166  6776 net.cpp:433] fc6 -> fc6
I1027 20:04:55.093112  6776 net.cpp:155] Setting up fc6
I1027 20:04:55.093142  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.093180  6776 layer_factory.hpp:76] Creating layer relu6
I1027 20:04:55.093191  6776 net.cpp:110] Creating Layer relu6
I1027 20:04:55.093197  6776 net.cpp:477] relu6 <- fc6
I1027 20:04:55.093204  6776 net.cpp:419] relu6 -> fc6 (in-place)
I1027 20:04:55.093219  6776 net.cpp:155] Setting up relu6
I1027 20:04:55.093225  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.093227  6776 layer_factory.hpp:76] Creating layer fc7
I1027 20:04:55.093235  6776 net.cpp:110] Creating Layer fc7
I1027 20:04:55.093237  6776 net.cpp:477] fc7 <- fc6
I1027 20:04:55.093242  6776 net.cpp:433] fc7 -> fc7
I1027 20:04:55.115880  6776 net.cpp:155] Setting up fc7
I1027 20:04:55.115908  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.115918  6776 layer_factory.hpp:76] Creating layer relu7
I1027 20:04:55.115938  6776 net.cpp:110] Creating Layer relu7
I1027 20:04:55.115943  6776 net.cpp:477] relu7 <- fc7
I1027 20:04:55.115949  6776 net.cpp:419] relu7 -> fc7 (in-place)
I1027 20:04:55.115960  6776 net.cpp:155] Setting up relu7
I1027 20:04:55.115965  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.115969  6776 layer_factory.hpp:76] Creating layer fc7_relu7_0_split
I1027 20:04:55.115975  6776 net.cpp:110] Creating Layer fc7_relu7_0_split
I1027 20:04:55.115979  6776 net.cpp:477] fc7_relu7_0_split <- fc7
I1027 20:04:55.115986  6776 net.cpp:433] fc7_relu7_0_split -> fc7_relu7_0_split_0
I1027 20:04:55.115993  6776 net.cpp:433] fc7_relu7_0_split -> fc7_relu7_0_split_1
I1027 20:04:55.116005  6776 net.cpp:155] Setting up fc7_relu7_0_split
I1027 20:04:55.116011  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.116015  6776 net.cpp:163] Top shape: 1 4096 (4096)
I1027 20:04:55.116019  6776 layer_factory.hpp:76] Creating layer cls_score
I1027 20:04:55.116025  6776 net.cpp:110] Creating Layer cls_score
I1027 20:04:55.116029  6776 net.cpp:477] cls_score <- fc7_relu7_0_split_0
I1027 20:04:55.116036  6776 net.cpp:433] cls_score -> cls_score
I1027 20:04:55.116106  6776 net.cpp:155] Setting up cls_score
I1027 20:04:55.116112  6776 net.cpp:163] Top shape: 1 8 (8)
I1027 20:04:55.116118  6776 layer_factory.hpp:76] Creating layer bbox_pred
I1027 20:04:55.116134  6776 net.cpp:110] Creating Layer bbox_pred
I1027 20:04:55.116138  6776 net.cpp:477] bbox_pred <- fc7_relu7_0_split_1
I1027 20:04:55.116145  6776 net.cpp:433] bbox_pred -> bbox_pred
I1027 20:04:55.116602  6776 net.cpp:155] Setting up bbox_pred
I1027 20:04:55.116611  6776 net.cpp:163] Top shape: 1 32 (32)
I1027 20:04:55.116618  6776 layer_factory.hpp:76] Creating layer cls_prob
I1027 20:04:55.116624  6776 net.cpp:110] Creating Layer cls_prob
I1027 20:04:55.116628  6776 net.cpp:477] cls_prob <- cls_score
I1027 20:04:55.116636  6776 net.cpp:433] cls_prob -> cls_prob
I1027 20:04:55.116657  6776 net.cpp:155] Setting up cls_prob
I1027 20:04:55.116662  6776 net.cpp:163] Top shape: 1 8 (8)
I1027 20:04:55.116667  6776 net.cpp:240] cls_prob does not need backward computation.
I1027 20:04:55.116670  6776 net.cpp:240] bbox_pred does not need backward computation.
I1027 20:04:55.116674  6776 net.cpp:240] cls_score does not need backward computation.
I1027 20:04:55.116678  6776 net.cpp:240] fc7_relu7_0_split does not need backward computation.
I1027 20:04:55.116681  6776 net.cpp:240] relu7 does not need backward computation.
I1027 20:04:55.116684  6776 net.cpp:240] fc7 does not need backward computation.
I1027 20:04:55.116688  6776 net.cpp:240] relu6 does not need backward computation.
I1027 20:04:55.116693  6776 net.cpp:240] fc6 does not need backward computation.
I1027 20:04:55.116696  6776 net.cpp:240] roi_pool5 does not need backward computation.
I1027 20:04:55.116700  6776 net.cpp:240] proposal does not need backward computation.
I1027 20:04:55.116704  6776 net.cpp:240] rpn_cls_prob_reshape does not need backward computation.
I1027 20:04:55.116708  6776 net.cpp:240] rpn_cls_prob does not need backward computation.
I1027 20:04:55.116713  6776 net.cpp:240] rpn_cls_score_reshape does not need backward computation.
I1027 20:04:55.116716  6776 net.cpp:240] rpn_bbox_pred does not need backward computation.
I1027 20:04:55.116720  6776 net.cpp:240] rpn_cls_score does not need backward computation.
I1027 20:04:55.116724  6776 net.cpp:240] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I1027 20:04:55.116729  6776 net.cpp:240] rpn_relu/3x3 does not need backward computation.
I1027 20:04:55.116732  6776 net.cpp:240] rpn_conv/3x3 does not need backward computation.
I1027 20:04:55.116736  6776 net.cpp:240] conv5_3_relu5_3_0_split does not need backward computation.
I1027 20:04:55.116740  6776 net.cpp:240] relu5_3 does not need backward computation.
I1027 20:04:55.116744  6776 net.cpp:240] conv5_3 does not need backward computation.
I1027 20:04:55.116749  6776 net.cpp:240] relu5_2 does not need backward computation.
I1027 20:04:55.116751  6776 net.cpp:240] conv5_2 does not need backward computation.
I1027 20:04:55.116755  6776 net.cpp:240] relu5_1 does not need backward computation.
I1027 20:04:55.116760  6776 net.cpp:240] conv5_1 does not need backward computation.
I1027 20:04:55.116762  6776 net.cpp:240] pool4 does not need backward computation.
I1027 20:04:55.116765  6776 net.cpp:240] relu4_3 does not need backward computation.
I1027 20:04:55.116770  6776 net.cpp:240] conv4_3 does not need backward computation.
I1027 20:04:55.116772  6776 net.cpp:240] relu4_2 does not need backward computation.
I1027 20:04:55.116776  6776 net.cpp:240] conv4_2 does not need backward computation.
I1027 20:04:55.116780  6776 net.cpp:240] relu4_1 does not need backward computation.
I1027 20:04:55.116783  6776 net.cpp:240] conv4_1 does not need backward computation.
I1027 20:04:55.116787  6776 net.cpp:240] pool3 does not need backward computation.
I1027 20:04:55.116791  6776 net.cpp:240] relu3_3 does not need backward computation.
I1027 20:04:55.116796  6776 net.cpp:240] conv3_3 does not need backward computation.
I1027 20:04:55.116798  6776 net.cpp:240] relu3_2 does not need backward computation.
I1027 20:04:55.116802  6776 net.cpp:240] conv3_2 does not need backward computation.
I1027 20:04:55.116806  6776 net.cpp:240] relu3_1 does not need backward computation.
I1027 20:04:55.116809  6776 net.cpp:240] conv3_1 does not need backward computation.
I1027 20:04:55.116813  6776 net.cpp:240] pool2 does not need backward computation.
I1027 20:04:55.116817  6776 net.cpp:240] relu2_2 does not need backward computation.
I1027 20:04:55.116821  6776 net.cpp:240] conv2_2 does not need backward computation.
I1027 20:04:55.116827  6776 net.cpp:240] relu2_1 does not need backward computation.
I1027 20:04:55.116830  6776 net.cpp:240] conv2_1 does not need backward computation.
I1027 20:04:55.116833  6776 net.cpp:240] pool1 does not need backward computation.
I1027 20:04:55.116837  6776 net.cpp:240] relu1_2 does not need backward computation.
I1027 20:04:55.116840  6776 net.cpp:240] conv1_2 does not need backward computation.
I1027 20:04:55.116844  6776 net.cpp:240] relu1_1 does not need backward computation.
I1027 20:04:55.116848  6776 net.cpp:240] conv1_1 does not need backward computation.
I1027 20:04:55.116852  6776 net.cpp:283] This network produces output bbox_pred
I1027 20:04:55.116855  6776 net.cpp:283] This network produces output cls_prob
I1027 20:04:55.116883  6776 net.cpp:297] Network initialization done.
I1027 20:04:55.116888  6776 net.cpp:298] Memory required for data: 117093268
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 1026092617
im_detect: 1/2245 0.618s 0.001s
im_detect: 2/2245 0.537s 0.001s
im_detect: 3/2245 0.524s 0.001s
im_detect: 4/2245 0.499s 0.001s
im_detect: 5/2245 0.496s 0.001s
im_detect: 6/2245 0.483s 0.001s
im_detect: 7/2245 0.466s 0.001s
im_detect: 8/2245 0.464s 0.001s
im_detect: 9/2245 0.462s 0.001s
im_detect: 10/2245 0.462s 0.001s
im_detect: 11/2245 0.463s 0.001s
im_detect: 12/2245 0.461s 0.001s
im_detect: 13/2245 0.460s 0.001s
im_detect: 14/2245 0.456s 0.001s
im_detect: 15/2245 0.449s 0.001s
im_detect: 16/2245 0.451s 0.001s
im_detect: 17/2245 0.453s 0.001s
im_detect: 18/2245 0.450s 0.001s
im_detect: 19/2245 0.449s 0.001s
im_detect: 20/2245 0.445s 0.001s
im_detect: 21/2245 0.445s 0.001s
im_detect: 22/2245 0.447s 0.001s
im_detect: 23/2245 0.446s 0.001s
im_detect: 24/2245 0.447s 0.001s
im_detect: 25/2245 0.445s 0.001s
im_detect: 26/2245 0.443s 0.001s
im_detect: 27/2245 0.445s 0.001s
im_detect: 28/2245 0.446s 0.001s
im_detect: 29/2245 0.444s 0.001s
im_detect: 30/2245 0.446s 0.001s
im_detect: 31/2245 0.446s 0.001s
im_detect: 32/2245 0.447s 0.001s
im_detect: 33/2245 0.449s 0.001s
im_detect: 34/2245 0.447s 0.001s
im_detect: 35/2245 0.447s 0.001s
im_detect: 36/2245 0.447s 0.001s
im_detect: 37/2245 0.446s 0.001s
im_detect: 38/2245 0.447s 0.001s
im_detect: 39/2245 0.448s 0.001s
im_detect: 40/2245 0.448s 0.001s
im_detect: 41/2245 0.448s 0.001s
im_detect: 42/2245 0.446s 0.001s
im_detect: 43/2245 0.446s 0.001s
im_detect: 44/2245 0.446s 0.001s
im_detect: 45/2245 0.444s 0.001s
im_detect: 46/2245 0.446s 0.001s
im_detect: 47/2245 0.446s 0.001s
im_detect: 48/2245 0.445s 0.001s
im_detect: 49/2245 0.445s 0.001s
im_detect: 50/2245 0.445s 0.001s
im_detect: 51/2245 0.444s 0.001s
im_detect: 52/2245 0.444s 0.001s
im_detect: 53/2245 0.443s 0.001s
im_detect: 54/2245 0.444s 0.001s
im_detect: 55/2245 0.443s 0.001s
im_detect: 56/2245 0.443s 0.001s
im_detect: 57/2245 0.443s 0.001s
im_detect: 58/2245 0.443s 0.001s
im_detect: 59/2245 0.442s 0.001s
im_detect: 60/2245 0.443s 0.001s
im_detect: 61/2245 0.443s 0.001s
im_detect: 62/2245 0.442s 0.001s
im_detect: 63/2245 0.442s 0.001s
im_detect: 64/2245 0.442s 0.001s
im_detect: 65/2245 0.442s 0.001s
im_detect: 66/2245 0.443s 0.001s
im_detect: 67/2245 0.443s 0.001s
im_detect: 68/2245 0.442s 0.001s
im_detect: 69/2245 0.442s 0.001s
im_detect: 70/2245 0.443s 0.001s
im_detect: 71/2245 0.443s 0.001s
im_detect: 72/2245 0.443s 0.001s
im_detect: 73/2245 0.443s 0.001s
im_detect: 74/2245 0.444s 0.001s
im_detect: 75/2245 0.444s 0.001s
im_detect: 76/2245 0.445s 0.001s
im_detect: 77/2245 0.445s 0.001s
im_detect: 78/2245 0.445s 0.001s
im_detect: 79/2245 0.444s 0.001s
im_detect: 80/2245 0.444s 0.001s
im_detect: 81/2245 0.444s 0.001s
im_detect: 82/2245 0.444s 0.001s
im_detect: 83/2245 0.444s 0.001s
im_detect: 84/2245 0.444s 0.001s
im_detect: 85/2245 0.444s 0.001s
im_detect: 86/2245 0.444s 0.001s
im_detect: 87/2245 0.444s 0.001s
im_detect: 88/2245 0.444s 0.001s
im_detect: 89/2245 0.444s 0.001s
im_detect: 90/2245 0.444s 0.001s
im_detect: 91/2245 0.444s 0.001s
im_detect: 92/2245 0.444s 0.001s
im_detect: 93/2245 0.444s 0.001s
im_detect: 94/2245 0.444s 0.001s
im_detect: 95/2245 0.444s 0.001s
im_detect: 96/2245 0.445s 0.001s
im_detect: 97/2245 0.445s 0.001s
im_detect: 98/2245 0.444s 0.001s
im_detect: 99/2245 0.445s 0.001s
im_detect: 100/2245 0.444s 0.001s
im_detect: 101/2245 0.444s 0.001s
im_detect: 102/2245 0.444s 0.001s
im_detect: 103/2245 0.443s 0.001s
im_detect: 104/2245 0.444s 0.001s
im_detect: 105/2245 0.444s 0.001s
im_detect: 106/2245 0.444s 0.001s
im_detect: 107/2245 0.444s 0.001s
im_detect: 108/2245 0.444s 0.001s
im_detect: 109/2245 0.444s 0.001s
im_detect: 110/2245 0.444s 0.001s
im_detect: 111/2245 0.444s 0.001s
im_detect: 112/2245 0.444s 0.001s
im_detect: 113/2245 0.444s 0.001s
im_detect: 114/2245 0.444s 0.001s
im_detect: 115/2245 0.444s 0.001s
im_detect: 116/2245 0.444s 0.001s
im_detect: 117/2245 0.444s 0.001s
im_detect: 118/2245 0.443s 0.001s
im_detect: 119/2245 0.443s 0.001s
im_detect: 120/2245 0.443s 0.001s
im_detect: 121/2245 0.442s 0.001s
im_detect: 122/2245 0.442s 0.001s
im_detect: 123/2245 0.442s 0.001s
im_detect: 124/2245 0.443s 0.001s
im_detect: 125/2245 0.442s 0.001s
im_detect: 126/2245 0.443s 0.001s
im_detect: 127/2245 0.443s 0.001s
im_detect: 128/2245 0.443s 0.001s
im_detect: 129/2245 0.443s 0.001s
im_detect: 130/2245 0.443s 0.001s
im_detect: 131/2245 0.442s 0.001s
im_detect: 132/2245 0.442s 0.001s
im_detect: 133/2245 0.442s 0.001s
im_detect: 134/2245 0.441s 0.001s
im_detect: 135/2245 0.442s 0.001s
im_detect: 136/2245 0.441s 0.001s
im_detect: 137/2245 0.441s 0.001s
im_detect: 138/2245 0.441s 0.001s
im_detect: 139/2245 0.441s 0.001s
im_detect: 140/2245 0.441s 0.001s
im_detect: 141/2245 0.441s 0.001s
im_detect: 142/2245 0.441s 0.001s
im_detect: 143/2245 0.441s 0.001s
im_detect: 144/2245 0.442s 0.001s
im_detect: 145/2245 0.442s 0.001s
im_detect: 146/2245 0.442s 0.001s
im_detect: 147/2245 0.442s 0.001s
im_detect: 148/2245 0.442s 0.001s
im_detect: 149/2245 0.442s 0.001s
im_detect: 150/2245 0.442s 0.001s
im_detect: 151/2245 0.442s 0.001s
im_detect: 152/2245 0.442s 0.001s
im_detect: 153/2245 0.442s 0.001s
im_detect: 154/2245 0.442s 0.001s
im_detect: 155/2245 0.442s 0.001s
im_detect: 156/2245 0.443s 0.001s
im_detect: 157/2245 0.442s 0.001s
im_detect: 158/2245 0.443s 0.001s
im_detect: 159/2245 0.442s 0.001s
im_detect: 160/2245 0.442s 0.001s
im_detect: 161/2245 0.442s 0.001s
im_detect: 162/2245 0.443s 0.001s
im_detect: 163/2245 0.443s 0.001s
im_detect: 164/2245 0.443s 0.001s
im_detect: 165/2245 0.443s 0.001s
im_detect: 166/2245 0.442s 0.001s
im_detect: 167/2245 0.442s 0.001s
im_detect: 168/2245 0.442s 0.001s
im_detect: 169/2245 0.442s 0.001s
im_detect: 170/2245 0.442s 0.001s
im_detect: 171/2245 0.442s 0.001s
im_detect: 172/2245 0.442s 0.001s
im_detect: 173/2245 0.442s 0.001s
im_detect: 174/2245 0.442s 0.001s
im_detect: 175/2245 0.442s 0.001s
im_detect: 176/2245 0.442s 0.001s
im_detect: 177/2245 0.442s 0.001s
im_detect: 178/2245 0.442s 0.001s
im_detect: 179/2245 0.443s 0.001s
im_detect: 180/2245 0.443s 0.001s
im_detect: 181/2245 0.443s 0.001s
im_detect: 182/2245 0.442s 0.001s
im_detect: 183/2245 0.443s 0.001s
im_detect: 184/2245 0.443s 0.001s
im_detect: 185/2245 0.442s 0.001s
im_detect: 186/2245 0.442s 0.001s
im_detect: 187/2245 0.442s 0.001s
im_detect: 188/2245 0.442s 0.001s
im_detect: 189/2245 0.442s 0.001s
im_detect: 190/2245 0.442s 0.001s
im_detect: 191/2245 0.442s 0.001s
im_detect: 192/2245 0.442s 0.001s
im_detect: 193/2245 0.442s 0.001s
im_detect: 194/2245 0.441s 0.001s
im_detect: 195/2245 0.441s 0.001s
im_detect: 196/2245 0.441s 0.001s
im_detect: 197/2245 0.441s 0.001s
im_detect: 198/2245 0.441s 0.001s
im_detect: 199/2245 0.441s 0.001s
im_detect: 200/2245 0.441s 0.001s
im_detect: 201/2245 0.441s 0.001s
im_detect: 202/2245 0.440s 0.001s
im_detect: 203/2245 0.440s 0.001s
im_detect: 204/2245 0.440s 0.001s
im_detect: 205/2245 0.440s 0.001s
im_detect: 206/2245 0.440s 0.001s
im_detect: 207/2245 0.440s 0.001s
im_detect: 208/2245 0.440s 0.001s
im_detect: 209/2245 0.440s 0.001s
im_detect: 210/2245 0.440s 0.001s
im_detect: 211/2245 0.440s 0.001s
im_detect: 212/2245 0.440s 0.001s
im_detect: 213/2245 0.440s 0.001s
im_detect: 214/2245 0.440s 0.001s
im_detect: 215/2245 0.441s 0.001s
im_detect: 216/2245 0.441s 0.001s
im_detect: 217/2245 0.441s 0.001s
im_detect: 218/2245 0.441s 0.001s
im_detect: 219/2245 0.441s 0.001s
im_detect: 220/2245 0.441s 0.001s
im_detect: 221/2245 0.441s 0.001s
im_detect: 222/2245 0.441s 0.001s
im_detect: 223/2245 0.441s 0.001s
im_detect: 224/2245 0.441s 0.001s
im_detect: 225/2245 0.441s 0.001s
im_detect: 226/2245 0.441s 0.001s
im_detect: 227/2245 0.441s 0.001s
im_detect: 228/2245 0.441s 0.001s
im_detect: 229/2245 0.441s 0.001s
im_detect: 230/2245 0.441s 0.001s
im_detect: 231/2245 0.441s 0.001s
im_detect: 232/2245 0.441s 0.001s
im_detect: 233/2245 0.441s 0.001s
im_detect: 234/2245 0.441s 0.001s
im_detect: 235/2245 0.441s 0.001s
im_detect: 236/2245 0.441s 0.001s
im_detect: 237/2245 0.441s 0.001s
im_detect: 238/2245 0.441s 0.001s
im_detect: 239/2245 0.441s 0.001s
im_detect: 240/2245 0.440s 0.001s
im_detect: 241/2245 0.441s 0.001s
im_detect: 242/2245 0.441s 0.001s
im_detect: 243/2245 0.441s 0.001s
im_detect: 244/2245 0.441s 0.001s
im_detect: 245/2245 0.441s 0.001s
im_detect: 246/2245 0.441s 0.001s
im_detect: 247/2245 0.441s 0.001s
im_detect: 248/2245 0.441s 0.001s
im_detect: 249/2245 0.441s 0.001s
im_detect: 250/2245 0.441s 0.001s
im_detect: 251/2245 0.441s 0.001s
im_detect: 252/2245 0.441s 0.001s
im_detect: 253/2245 0.441s 0.001s
im_detect: 254/2245 0.441s 0.001s
im_detect: 255/2245 0.441s 0.001s
im_detect: 256/2245 0.441s 0.001s
im_detect: 257/2245 0.441s 0.001s
im_detect: 258/2245 0.441s 0.001s
im_detect: 259/2245 0.441s 0.001s
im_detect: 260/2245 0.441s 0.001s
im_detect: 261/2245 0.441s 0.001s
im_detect: 262/2245 0.442s 0.001s
im_detect: 263/2245 0.442s 0.001s
im_detect: 264/2245 0.442s 0.001s
im_detect: 265/2245 0.442s 0.001s
im_detect: 266/2245 0.441s 0.001s
im_detect: 267/2245 0.441s 0.001s
im_detect: 268/2245 0.442s 0.001s
im_detect: 269/2245 0.442s 0.001s
im_detect: 270/2245 0.442s 0.001s
im_detect: 271/2245 0.442s 0.001s
im_detect: 272/2245 0.442s 0.001s
im_detect: 273/2245 0.442s 0.001s
im_detect: 274/2245 0.442s 0.001s
im_detect: 275/2245 0.442s 0.001s
im_detect: 276/2245 0.442s 0.001s
im_detect: 277/2245 0.442s 0.001s
im_detect: 278/2245 0.442s 0.001s
im_detect: 279/2245 0.442s 0.001s
im_detect: 280/2245 0.442s 0.001s
im_detect: 281/2245 0.442s 0.001s
im_detect: 282/2245 0.442s 0.001s
im_detect: 283/2245 0.442s 0.001s
im_detect: 284/2245 0.442s 0.001s
im_detect: 285/2245 0.442s 0.001s
im_detect: 286/2245 0.442s 0.001s
im_detect: 287/2245 0.442s 0.001s
im_detect: 288/2245 0.442s 0.001s
im_detect: 289/2245 0.442s 0.001s
im_detect: 290/2245 0.442s 0.001s
im_detect: 291/2245 0.442s 0.001s
im_detect: 292/2245 0.442s 0.001s
im_detect: 293/2245 0.442s 0.001s
im_detect: 294/2245 0.442s 0.001s
im_detect: 295/2245 0.442s 0.001s
im_detect: 296/2245 0.442s 0.001s
im_detect: 297/2245 0.442s 0.001s
im_detect: 298/2245 0.442s 0.001s
im_detect: 299/2245 0.442s 0.001s
im_detect: 300/2245 0.442s 0.001s
im_detect: 301/2245 0.442s 0.001s
im_detect: 302/2245 0.442s 0.001s
im_detect: 303/2245 0.442s 0.001s
im_detect: 304/2245 0.442s 0.001s
im_detect: 305/2245 0.442s 0.001s
im_detect: 306/2245 0.442s 0.001s
im_detect: 307/2245 0.442s 0.001s
im_detect: 308/2245 0.442s 0.001s
im_detect: 309/2245 0.442s 0.001s
im_detect: 310/2245 0.442s 0.001s
im_detect: 311/2245 0.442s 0.001s
im_detect: 312/2245 0.442s 0.001s
im_detect: 313/2245 0.442s 0.001s
im_detect: 314/2245 0.442s 0.001s
im_detect: 315/2245 0.442s 0.001s
im_detect: 316/2245 0.442s 0.001s
im_detect: 317/2245 0.442s 0.001s
im_detect: 318/2245 0.442s 0.001s
im_detect: 319/2245 0.442s 0.001s
im_detect: 320/2245 0.442s 0.001s
im_detect: 321/2245 0.442s 0.001s
im_detect: 322/2245 0.442s 0.001s
im_detect: 323/2245 0.442s 0.001s
im_detect: 324/2245 0.442s 0.001s
im_detect: 325/2245 0.442s 0.001s
im_detect: 326/2245 0.442s 0.001s
im_detect: 327/2245 0.442s 0.001s
im_detect: 328/2245 0.442s 0.001s
im_detect: 329/2245 0.442s 0.001s
im_detect: 330/2245 0.442s 0.001s
im_detect: 331/2245 0.442s 0.001s
im_detect: 332/2245 0.442s 0.001s
im_detect: 333/2245 0.442s 0.001s
im_detect: 334/2245 0.442s 0.001s
im_detect: 335/2245 0.442s 0.001s
im_detect: 336/2245 0.442s 0.001s
im_detect: 337/2245 0.442s 0.001s
im_detect: 338/2245 0.442s 0.001s
im_detect: 339/2245 0.442s 0.001s
im_detect: 340/2245 0.442s 0.001s
im_detect: 341/2245 0.442s 0.001s
im_detect: 342/2245 0.442s 0.001s
im_detect: 343/2245 0.442s 0.001s
im_detect: 344/2245 0.442s 0.001s
im_detect: 345/2245 0.442s 0.001s
im_detect: 346/2245 0.442s 0.001s
im_detect: 347/2245 0.441s 0.001s
im_detect: 348/2245 0.442s 0.001s
im_detect: 349/2245 0.442s 0.001s
im_detect: 350/2245 0.441s 0.001s
im_detect: 351/2245 0.442s 0.001s
im_detect: 352/2245 0.441s 0.001s
im_detect: 353/2245 0.441s 0.001s
im_detect: 354/2245 0.441s 0.001s
im_detect: 355/2245 0.441s 0.001s
im_detect: 356/2245 0.441s 0.001s
im_detect: 357/2245 0.441s 0.001s
im_detect: 358/2245 0.441s 0.001s
im_detect: 359/2245 0.441s 0.001s
im_detect: 360/2245 0.441s 0.001s
im_detect: 361/2245 0.441s 0.001s
im_detect: 362/2245 0.442s 0.001s
im_detect: 363/2245 0.442s 0.001s
im_detect: 364/2245 0.442s 0.001s
im_detect: 365/2245 0.442s 0.001s
im_detect: 366/2245 0.441s 0.001s
im_detect: 367/2245 0.441s 0.001s
im_detect: 368/2245 0.441s 0.001s
im_detect: 369/2245 0.441s 0.001s
im_detect: 370/2245 0.441s 0.001s
im_detect: 371/2245 0.441s 0.001s
im_detect: 372/2245 0.441s 0.001s
im_detect: 373/2245 0.441s 0.001s
im_detect: 374/2245 0.441s 0.001s
im_detect: 375/2245 0.441s 0.001s
im_detect: 376/2245 0.441s 0.001s
im_detect: 377/2245 0.441s 0.001s
im_detect: 378/2245 0.441s 0.001s
im_detect: 379/2245 0.442s 0.001s
im_detect: 380/2245 0.442s 0.001s
im_detect: 381/2245 0.442s 0.001s
im_detect: 382/2245 0.442s 0.001s
im_detect: 383/2245 0.442s 0.001s
im_detect: 384/2245 0.442s 0.001s
im_detect: 385/2245 0.442s 0.001s
im_detect: 386/2245 0.442s 0.001s
im_detect: 387/2245 0.442s 0.001s
im_detect: 388/2245 0.441s 0.001s
im_detect: 389/2245 0.441s 0.001s
im_detect: 390/2245 0.441s 0.001s
im_detect: 391/2245 0.441s 0.001s
im_detect: 392/2245 0.441s 0.001s
im_detect: 393/2245 0.441s 0.001s
im_detect: 394/2245 0.442s 0.001s
im_detect: 395/2245 0.442s 0.001s
im_detect: 396/2245 0.442s 0.001s
im_detect: 397/2245 0.442s 0.001s
im_detect: 398/2245 0.442s 0.001s
im_detect: 399/2245 0.442s 0.001s
im_detect: 400/2245 0.442s 0.001s
im_detect: 401/2245 0.442s 0.001s
im_detect: 402/2245 0.442s 0.001s
im_detect: 403/2245 0.442s 0.001s
im_detect: 404/2245 0.442s 0.001s
im_detect: 405/2245 0.442s 0.001s
im_detect: 406/2245 0.442s 0.001s
im_detect: 407/2245 0.442s 0.001s
im_detect: 408/2245 0.442s 0.001s
im_detect: 409/2245 0.442s 0.001s
im_detect: 410/2245 0.442s 0.001s
im_detect: 411/2245 0.442s 0.001s
im_detect: 412/2245 0.442s 0.001s
im_detect: 413/2245 0.442s 0.001s
im_detect: 414/2245 0.442s 0.001s
im_detect: 415/2245 0.442s 0.001s
im_detect: 416/2245 0.442s 0.001s
im_detect: 417/2245 0.442s 0.001s
im_detect: 418/2245 0.442s 0.001s
im_detect: 419/2245 0.442s 0.001s
im_detect: 420/2245 0.442s 0.001s
im_detect: 421/2245 0.442s 0.001s
im_detect: 422/2245 0.442s 0.001s
im_detect: 423/2245 0.442s 0.001s
im_detect: 424/2245 0.442s 0.001s
im_detect: 425/2245 0.442s 0.001s
im_detect: 426/2245 0.442s 0.001s
im_detect: 427/2245 0.442s 0.001s
im_detect: 428/2245 0.442s 0.001s
im_detect: 429/2245 0.442s 0.001s
im_detect: 430/2245 0.442s 0.001s
im_detect: 431/2245 0.442s 0.001s
im_detect: 432/2245 0.442s 0.001s
im_detect: 433/2245 0.442s 0.001s
im_detect: 434/2245 0.442s 0.001s
im_detect: 435/2245 0.442s 0.001s
im_detect: 436/2245 0.442s 0.001s
im_detect: 437/2245 0.442s 0.001s
im_detect: 438/2245 0.442s 0.001s
im_detect: 439/2245 0.442s 0.001s
im_detect: 440/2245 0.442s 0.001s
im_detect: 441/2245 0.442s 0.001s
im_detect: 442/2245 0.442s 0.001s
im_detect: 443/2245 0.442s 0.001s
im_detect: 444/2245 0.442s 0.001s
im_detect: 445/2245 0.442s 0.001s
im_detect: 446/2245 0.442s 0.001s
im_detect: 447/2245 0.442s 0.001s
im_detect: 448/2245 0.442s 0.001s
im_detect: 449/2245 0.442s 0.001s
im_detect: 450/2245 0.442s 0.001s
im_detect: 451/2245 0.442s 0.001s
im_detect: 452/2245 0.442s 0.001s
im_detect: 453/2245 0.442s 0.001s
im_detect: 454/2245 0.442s 0.001s
im_detect: 455/2245 0.442s 0.001s
im_detect: 456/2245 0.442s 0.001s
im_detect: 457/2245 0.442s 0.001s
im_detect: 458/2245 0.442s 0.001s
im_detect: 459/2245 0.442s 0.001s
im_detect: 460/2245 0.442s 0.001s
im_detect: 461/2245 0.442s 0.001s
im_detect: 462/2245 0.442s 0.001s
im_detect: 463/2245 0.442s 0.001s
im_detect: 464/2245 0.442s 0.001s
im_detect: 465/2245 0.442s 0.001s
im_detect: 466/2245 0.442s 0.001s
im_detect: 467/2245 0.442s 0.001s
im_detect: 468/2245 0.442s 0.001s
im_detect: 469/2245 0.442s 0.001s
im_detect: 470/2245 0.442s 0.001s
im_detect: 471/2245 0.442s 0.001s
im_detect: 472/2245 0.442s 0.001s
im_detect: 473/2245 0.442s 0.001s
im_detect: 474/2245 0.442s 0.001s
im_detect: 475/2245 0.442s 0.001s
im_detect: 476/2245 0.442s 0.001s
im_detect: 477/2245 0.442s 0.001s
im_detect: 478/2245 0.442s 0.001s
im_detect: 479/2245 0.442s 0.001s
im_detect: 480/2245 0.442s 0.001s
im_detect: 481/2245 0.442s 0.001s
im_detect: 482/2245 0.442s 0.001s
im_detect: 483/2245 0.442s 0.001s
im_detect: 484/2245 0.442s 0.001s
im_detect: 485/2245 0.442s 0.001s
im_detect: 486/2245 0.442s 0.001s
im_detect: 487/2245 0.442s 0.001s
im_detect: 488/2245 0.442s 0.001s
im_detect: 489/2245 0.442s 0.001s
im_detect: 490/2245 0.442s 0.001s
im_detect: 491/2245 0.442s 0.001s
im_detect: 492/2245 0.442s 0.001s
im_detect: 493/2245 0.442s 0.001s
im_detect: 494/2245 0.442s 0.001s
im_detect: 495/2245 0.442s 0.001s
im_detect: 496/2245 0.442s 0.001s
im_detect: 497/2245 0.442s 0.001s
im_detect: 498/2245 0.442s 0.001s
im_detect: 499/2245 0.442s 0.001s
im_detect: 500/2245 0.442s 0.001s
im_detect: 501/2245 0.442s 0.001s
im_detect: 502/2245 0.442s 0.001s
im_detect: 503/2245 0.442s 0.001s
im_detect: 504/2245 0.442s 0.001s
im_detect: 505/2245 0.442s 0.001s
im_detect: 506/2245 0.442s 0.001s
im_detect: 507/2245 0.442s 0.001s
im_detect: 508/2245 0.442s 0.001s
im_detect: 509/2245 0.442s 0.001s
im_detect: 510/2245 0.442s 0.001s
im_detect: 511/2245 0.442s 0.001s
im_detect: 512/2245 0.442s 0.001s
im_detect: 513/2245 0.442s 0.001s
im_detect: 514/2245 0.442s 0.001s
im_detect: 515/2245 0.442s 0.001s
im_detect: 516/2245 0.442s 0.001s
im_detect: 517/2245 0.442s 0.001s
im_detect: 518/2245 0.442s 0.001s
im_detect: 519/2245 0.442s 0.001s
im_detect: 520/2245 0.442s 0.001s
im_detect: 521/2245 0.442s 0.001s
im_detect: 522/2245 0.442s 0.001s
im_detect: 523/2245 0.442s 0.001s
im_detect: 524/2245 0.442s 0.001s
im_detect: 525/2245 0.442s 0.001s
im_detect: 526/2245 0.442s 0.001s
im_detect: 527/2245 0.442s 0.001s
im_detect: 528/2245 0.442s 0.001s
im_detect: 529/2245 0.442s 0.001s
im_detect: 530/2245 0.442s 0.001s
im_detect: 531/2245 0.442s 0.001s
im_detect: 532/2245 0.442s 0.001s
im_detect: 533/2245 0.442s 0.001s
im_detect: 534/2245 0.442s 0.001s
im_detect: 535/2245 0.441s 0.001s
im_detect: 536/2245 0.442s 0.001s
im_detect: 537/2245 0.441s 0.001s
im_detect: 538/2245 0.441s 0.001s
im_detect: 539/2245 0.441s 0.001s
im_detect: 540/2245 0.441s 0.001s
im_detect: 541/2245 0.442s 0.001s
im_detect: 542/2245 0.442s 0.001s
im_detect: 543/2245 0.441s 0.001s
im_detect: 544/2245 0.442s 0.001s
im_detect: 545/2245 0.442s 0.001s
im_detect: 546/2245 0.442s 0.001s
im_detect: 547/2245 0.442s 0.001s
im_detect: 548/2245 0.442s 0.001s
im_detect: 549/2245 0.442s 0.001s
im_detect: 550/2245 0.441s 0.001s
im_detect: 551/2245 0.441s 0.001s
im_detect: 552/2245 0.441s 0.001s
im_detect: 553/2245 0.441s 0.001s
im_detect: 554/2245 0.441s 0.001s
im_detect: 555/2245 0.441s 0.001s
im_detect: 556/2245 0.442s 0.001s
im_detect: 557/2245 0.442s 0.001s
im_detect: 558/2245 0.442s 0.001s
im_detect: 559/2245 0.442s 0.001s
im_detect: 560/2245 0.442s 0.001s
im_detect: 561/2245 0.442s 0.001s
im_detect: 562/2245 0.442s 0.001s
im_detect: 563/2245 0.442s 0.001s
im_detect: 564/2245 0.442s 0.001s
im_detect: 565/2245 0.442s 0.001s
im_detect: 566/2245 0.442s 0.001s
im_detect: 567/2245 0.442s 0.001s
im_detect: 568/2245 0.442s 0.001s
im_detect: 569/2245 0.442s 0.001s
im_detect: 570/2245 0.442s 0.001s
im_detect: 571/2245 0.442s 0.001s
im_detect: 572/2245 0.442s 0.001s
im_detect: 573/2245 0.442s 0.001s
im_detect: 574/2245 0.442s 0.001s
im_detect: 575/2245 0.442s 0.001s
im_detect: 576/2245 0.442s 0.001s
im_detect: 577/2245 0.442s 0.001s
im_detect: 578/2245 0.442s 0.001s
im_detect: 579/2245 0.442s 0.001s
im_detect: 580/2245 0.442s 0.001s
im_detect: 581/2245 0.442s 0.001s
im_detect: 582/2245 0.442s 0.001s
im_detect: 583/2245 0.442s 0.001s
im_detect: 584/2245 0.442s 0.001s
im_detect: 585/2245 0.442s 0.001s
im_detect: 586/2245 0.442s 0.001s
im_detect: 587/2245 0.442s 0.001s
im_detect: 588/2245 0.442s 0.001s
im_detect: 589/2245 0.442s 0.001s
im_detect: 590/2245 0.442s 0.001s
im_detect: 591/2245 0.442s 0.001s
im_detect: 592/2245 0.442s 0.001s
im_detect: 593/2245 0.442s 0.001s
im_detect: 594/2245 0.442s 0.001s
im_detect: 595/2245 0.442s 0.001s
im_detect: 596/2245 0.442s 0.001s
im_detect: 597/2245 0.442s 0.001s
im_detect: 598/2245 0.442s 0.001s
im_detect: 599/2245 0.442s 0.001s
im_detect: 600/2245 0.442s 0.001s
im_detect: 601/2245 0.442s 0.001s
im_detect: 602/2245 0.442s 0.001s
im_detect: 603/2245 0.442s 0.001s
im_detect: 604/2245 0.442s 0.001s
im_detect: 605/2245 0.442s 0.001s
im_detect: 606/2245 0.442s 0.001s
im_detect: 607/2245 0.442s 0.001s
im_detect: 608/2245 0.442s 0.001s
im_detect: 609/2245 0.442s 0.001s
im_detect: 610/2245 0.442s 0.001s
im_detect: 611/2245 0.442s 0.001s
im_detect: 612/2245 0.442s 0.001s
im_detect: 613/2245 0.442s 0.001s
im_detect: 614/2245 0.442s 0.001s
im_detect: 615/2245 0.442s 0.001s
im_detect: 616/2245 0.442s 0.001s
im_detect: 617/2245 0.442s 0.001s
im_detect: 618/2245 0.442s 0.001s
im_detect: 619/2245 0.442s 0.001s
im_detect: 620/2245 0.442s 0.001s
im_detect: 621/2245 0.442s 0.001s
im_detect: 622/2245 0.442s 0.001s
im_detect: 623/2245 0.442s 0.001s
im_detect: 624/2245 0.442s 0.001s
im_detect: 625/2245 0.442s 0.001s
im_detect: 626/2245 0.442s 0.001s
im_detect: 627/2245 0.442s 0.001s
im_detect: 628/2245 0.442s 0.001s
im_detect: 629/2245 0.442s 0.001s
im_detect: 630/2245 0.442s 0.001s
im_detect: 631/2245 0.442s 0.001s
im_detect: 632/2245 0.442s 0.001s
im_detect: 633/2245 0.442s 0.001s
im_detect: 634/2245 0.442s 0.001s
im_detect: 635/2245 0.442s 0.001s
im_detect: 636/2245 0.442s 0.001s
im_detect: 637/2245 0.442s 0.001s
im_detect: 638/2245 0.442s 0.001s
im_detect: 639/2245 0.442s 0.001s
im_detect: 640/2245 0.442s 0.001s
im_detect: 641/2245 0.442s 0.001s
im_detect: 642/2245 0.442s 0.001s
im_detect: 643/2245 0.442s 0.001s
im_detect: 644/2245 0.442s 0.001s
im_detect: 645/2245 0.442s 0.001s
im_detect: 646/2245 0.442s 0.001s
im_detect: 647/2245 0.442s 0.001s
im_detect: 648/2245 0.442s 0.001s
im_detect: 649/2245 0.442s 0.001s
im_detect: 650/2245 0.442s 0.001s
im_detect: 651/2245 0.442s 0.001s
im_detect: 652/2245 0.442s 0.001s
im_detect: 653/2245 0.442s 0.001s
im_detect: 654/2245 0.442s 0.001s
im_detect: 655/2245 0.442s 0.001s
im_detect: 656/2245 0.442s 0.001s
im_detect: 657/2245 0.442s 0.001s
im_detect: 658/2245 0.442s 0.001s
im_detect: 659/2245 0.442s 0.001s
im_detect: 660/2245 0.442s 0.001s
im_detect: 661/2245 0.442s 0.001s
im_detect: 662/2245 0.442s 0.001s
im_detect: 663/2245 0.442s 0.001s
im_detect: 664/2245 0.442s 0.001s
im_detect: 665/2245 0.442s 0.001s
im_detect: 666/2245 0.442s 0.001s
im_detect: 667/2245 0.442s 0.001s
im_detect: 668/2245 0.442s 0.001s
im_detect: 669/2245 0.442s 0.001s
im_detect: 670/2245 0.442s 0.001s
im_detect: 671/2245 0.442s 0.001s
im_detect: 672/2245 0.442s 0.001s
im_detect: 673/2245 0.442s 0.001s
im_detect: 674/2245 0.442s 0.001s
im_detect: 675/2245 0.442s 0.001s
im_detect: 676/2245 0.442s 0.001s
im_detect: 677/2245 0.442s 0.001s
im_detect: 678/2245 0.442s 0.001s
im_detect: 679/2245 0.442s 0.001s
im_detect: 680/2245 0.442s 0.001s
im_detect: 681/2245 0.442s 0.001s
im_detect: 682/2245 0.442s 0.001s
im_detect: 683/2245 0.442s 0.001s
im_detect: 684/2245 0.442s 0.001s
im_detect: 685/2245 0.442s 0.001s
im_detect: 686/2245 0.442s 0.001s
im_detect: 687/2245 0.442s 0.001s
im_detect: 688/2245 0.442s 0.001s
im_detect: 689/2245 0.442s 0.001s
im_detect: 690/2245 0.442s 0.001s
im_detect: 691/2245 0.442s 0.001s
im_detect: 692/2245 0.442s 0.001s
im_detect: 693/2245 0.442s 0.001s
im_detect: 694/2245 0.442s 0.001s
im_detect: 695/2245 0.442s 0.001s
im_detect: 696/2245 0.442s 0.001s
im_detect: 697/2245 0.442s 0.001s
im_detect: 698/2245 0.442s 0.001s
im_detect: 699/2245 0.442s 0.001s
im_detect: 700/2245 0.442s 0.001s
im_detect: 701/2245 0.442s 0.001s
im_detect: 702/2245 0.442s 0.001s
im_detect: 703/2245 0.442s 0.001s
im_detect: 704/2245 0.442s 0.001s
im_detect: 705/2245 0.442s 0.001s
im_detect: 706/2245 0.442s 0.001s
im_detect: 707/2245 0.442s 0.001s
im_detect: 708/2245 0.442s 0.001s
im_detect: 709/2245 0.442s 0.001s
im_detect: 710/2245 0.442s 0.001s
im_detect: 711/2245 0.442s 0.001s
im_detect: 712/2245 0.442s 0.001s
im_detect: 713/2245 0.442s 0.001s
im_detect: 714/2245 0.442s 0.001s
im_detect: 715/2245 0.442s 0.001s
im_detect: 716/2245 0.442s 0.001s
im_detect: 717/2245 0.442s 0.001s
im_detect: 718/2245 0.442s 0.001s
im_detect: 719/2245 0.442s 0.001s
im_detect: 720/2245 0.442s 0.001s
im_detect: 721/2245 0.442s 0.001s
im_detect: 722/2245 0.442s 0.001s
im_detect: 723/2245 0.442s 0.001s
im_detect: 724/2245 0.442s 0.001s
im_detect: 725/2245 0.442s 0.001s
im_detect: 726/2245 0.442s 0.001s
im_detect: 727/2245 0.442s 0.001s
im_detect: 728/2245 0.442s 0.001s
im_detect: 729/2245 0.442s 0.001s
im_detect: 730/2245 0.442s 0.001s
im_detect: 731/2245 0.442s 0.001s
im_detect: 732/2245 0.442s 0.001s
im_detect: 733/2245 0.442s 0.001s
im_detect: 734/2245 0.442s 0.001s
im_detect: 735/2245 0.442s 0.001s
im_detect: 736/2245 0.442s 0.001s
im_detect: 737/2245 0.442s 0.001s
im_detect: 738/2245 0.442s 0.001s
im_detect: 739/2245 0.442s 0.001s
im_detect: 740/2245 0.442s 0.001s
im_detect: 741/2245 0.442s 0.001s
im_detect: 742/2245 0.442s 0.001s
im_detect: 743/2245 0.442s 0.001s
im_detect: 744/2245 0.442s 0.001s
im_detect: 745/2245 0.442s 0.001s
im_detect: 746/2245 0.442s 0.001s
im_detect: 747/2245 0.442s 0.001s
im_detect: 748/2245 0.442s 0.001s
im_detect: 749/2245 0.442s 0.001s
im_detect: 750/2245 0.442s 0.001s
im_detect: 751/2245 0.442s 0.001s
im_detect: 752/2245 0.442s 0.001s
im_detect: 753/2245 0.442s 0.001s
im_detect: 754/2245 0.443s 0.001s
im_detect: 755/2245 0.443s 0.001s
im_detect: 756/2245 0.443s 0.001s
im_detect: 757/2245 0.443s 0.001s
im_detect: 758/2245 0.443s 0.001s
im_detect: 759/2245 0.443s 0.001s
im_detect: 760/2245 0.443s 0.001s
im_detect: 761/2245 0.443s 0.001s
im_detect: 762/2245 0.443s 0.001s
im_detect: 763/2245 0.443s 0.001s
im_detect: 764/2245 0.443s 0.001s
im_detect: 765/2245 0.443s 0.001s
im_detect: 766/2245 0.443s 0.001s
im_detect: 767/2245 0.442s 0.001s
im_detect: 768/2245 0.442s 0.001s
im_detect: 769/2245 0.443s 0.001s
im_detect: 770/2245 0.443s 0.001s
im_detect: 771/2245 0.443s 0.001s
im_detect: 772/2245 0.443s 0.001s
im_detect: 773/2245 0.443s 0.001s
im_detect: 774/2245 0.442s 0.001s
im_detect: 775/2245 0.443s 0.001s
im_detect: 776/2245 0.443s 0.001s
im_detect: 777/2245 0.443s 0.001s
im_detect: 778/2245 0.443s 0.001s
im_detect: 779/2245 0.443s 0.001s
im_detect: 780/2245 0.443s 0.001s
im_detect: 781/2245 0.443s 0.001s
im_detect: 782/2245 0.443s 0.001s
im_detect: 783/2245 0.443s 0.001s
im_detect: 784/2245 0.443s 0.001s
im_detect: 785/2245 0.443s 0.001s
im_detect: 786/2245 0.443s 0.001s
im_detect: 787/2245 0.443s 0.001s
im_detect: 788/2245 0.443s 0.001s
im_detect: 789/2245 0.443s 0.001s
im_detect: 790/2245 0.443s 0.001s
im_detect: 791/2245 0.443s 0.001s
im_detect: 792/2245 0.443s 0.001s
im_detect: 793/2245 0.443s 0.001s
im_detect: 794/2245 0.443s 0.001s
im_detect: 795/2245 0.443s 0.001s
im_detect: 796/2245 0.443s 0.001s
im_detect: 797/2245 0.443s 0.001s
im_detect: 798/2245 0.443s 0.001s
im_detect: 799/2245 0.443s 0.001s
im_detect: 800/2245 0.443s 0.001s
im_detect: 801/2245 0.443s 0.001s
im_detect: 802/2245 0.443s 0.001s
im_detect: 803/2245 0.443s 0.001s
im_detect: 804/2245 0.443s 0.001s
im_detect: 805/2245 0.443s 0.001s
im_detect: 806/2245 0.443s 0.001s
im_detect: 807/2245 0.443s 0.001s
im_detect: 808/2245 0.443s 0.001s
im_detect: 809/2245 0.443s 0.001s
im_detect: 810/2245 0.443s 0.001s
im_detect: 811/2245 0.443s 0.001s
im_detect: 812/2245 0.443s 0.001s
im_detect: 813/2245 0.443s 0.001s
im_detect: 814/2245 0.442s 0.001s
im_detect: 815/2245 0.442s 0.001s
im_detect: 816/2245 0.442s 0.001s
im_detect: 817/2245 0.442s 0.001s
im_detect: 818/2245 0.442s 0.001s
im_detect: 819/2245 0.442s 0.001s
im_detect: 820/2245 0.442s 0.001s
im_detect: 821/2245 0.442s 0.001s
im_detect: 822/2245 0.442s 0.001s
im_detect: 823/2245 0.442s 0.001s
im_detect: 824/2245 0.442s 0.001s
im_detect: 825/2245 0.442s 0.001s
im_detect: 826/2245 0.442s 0.001s
im_detect: 827/2245 0.442s 0.001s
im_detect: 828/2245 0.442s 0.001s
im_detect: 829/2245 0.442s 0.001s
im_detect: 830/2245 0.443s 0.001s
im_detect: 831/2245 0.442s 0.001s
im_detect: 832/2245 0.443s 0.001s
im_detect: 833/2245 0.442s 0.001s
im_detect: 834/2245 0.442s 0.001s
im_detect: 835/2245 0.442s 0.001s
im_detect: 836/2245 0.442s 0.001s
im_detect: 837/2245 0.442s 0.001s
im_detect: 838/2245 0.442s 0.001s
im_detect: 839/2245 0.442s 0.001s
im_detect: 840/2245 0.442s 0.001s
im_detect: 841/2245 0.442s 0.001s
im_detect: 842/2245 0.442s 0.001s
im_detect: 843/2245 0.442s 0.001s
im_detect: 844/2245 0.443s 0.001s
im_detect: 845/2245 0.443s 0.001s
im_detect: 846/2245 0.442s 0.001s
im_detect: 847/2245 0.442s 0.001s
im_detect: 848/2245 0.442s 0.001s
im_detect: 849/2245 0.442s 0.001s
im_detect: 850/2245 0.442s 0.001s
im_detect: 851/2245 0.442s 0.001s
im_detect: 852/2245 0.442s 0.001s
im_detect: 853/2245 0.442s 0.001s
im_detect: 854/2245 0.442s 0.001s
im_detect: 855/2245 0.442s 0.001s
im_detect: 856/2245 0.442s 0.001s
im_detect: 857/2245 0.442s 0.001s
im_detect: 858/2245 0.442s 0.001s
im_detect: 859/2245 0.442s 0.001s
im_detect: 860/2245 0.442s 0.001s
im_detect: 861/2245 0.442s 0.001s
im_detect: 862/2245 0.442s 0.001s
im_detect: 863/2245 0.442s 0.001s
im_detect: 864/2245 0.442s 0.001s
im_detect: 865/2245 0.442s 0.001s
im_detect: 866/2245 0.442s 0.001s
im_detect: 867/2245 0.442s 0.001s
im_detect: 868/2245 0.442s 0.001s
im_detect: 869/2245 0.442s 0.001s
im_detect: 870/2245 0.442s 0.001s
im_detect: 871/2245 0.442s 0.001s
im_detect: 872/2245 0.442s 0.001s
im_detect: 873/2245 0.442s 0.001s
im_detect: 874/2245 0.442s 0.001s
im_detect: 875/2245 0.442s 0.001s
im_detect: 876/2245 0.442s 0.001s
im_detect: 877/2245 0.442s 0.001s
im_detect: 878/2245 0.442s 0.001s
im_detect: 879/2245 0.442s 0.001s
im_detect: 880/2245 0.442s 0.001s
im_detect: 881/2245 0.442s 0.001s
im_detect: 882/2245 0.442s 0.001s
im_detect: 883/2245 0.442s 0.001s
im_detect: 884/2245 0.442s 0.001s
im_detect: 885/2245 0.442s 0.001s
im_detect: 886/2245 0.442s 0.001s
im_detect: 887/2245 0.442s 0.001s
im_detect: 888/2245 0.442s 0.001s
im_detect: 889/2245 0.442s 0.001s
im_detect: 890/2245 0.442s 0.001s
im_detect: 891/2245 0.442s 0.001s
im_detect: 892/2245 0.442s 0.001s
im_detect: 893/2245 0.442s 0.001s
im_detect: 894/2245 0.442s 0.001s
im_detect: 895/2245 0.442s 0.001s
im_detect: 896/2245 0.442s 0.001s
im_detect: 897/2245 0.442s 0.001s
im_detect: 898/2245 0.442s 0.001s
im_detect: 899/2245 0.442s 0.001s
im_detect: 900/2245 0.442s 0.001s
im_detect: 901/2245 0.442s 0.001s
im_detect: 902/2245 0.442s 0.001s
im_detect: 903/2245 0.442s 0.001s
im_detect: 904/2245 0.442s 0.001s
im_detect: 905/2245 0.442s 0.001s
im_detect: 906/2245 0.442s 0.001s
im_detect: 907/2245 0.442s 0.001s
im_detect: 908/2245 0.442s 0.001s
im_detect: 909/2245 0.442s 0.001s
im_detect: 910/2245 0.442s 0.001s
im_detect: 911/2245 0.442s 0.001s
im_detect: 912/2245 0.442s 0.001s
im_detect: 913/2245 0.442s 0.001s
im_detect: 914/2245 0.442s 0.001s
im_detect: 915/2245 0.442s 0.001s
im_detect: 916/2245 0.442s 0.001s
im_detect: 917/2245 0.442s 0.001s
im_detect: 918/2245 0.442s 0.001s
im_detect: 919/2245 0.442s 0.001s
im_detect: 920/2245 0.442s 0.001s
im_detect: 921/2245 0.442s 0.001s
im_detect: 922/2245 0.442s 0.001s
im_detect: 923/2245 0.442s 0.001s
im_detect: 924/2245 0.442s 0.001s
im_detect: 925/2245 0.442s 0.001s
im_detect: 926/2245 0.442s 0.001s
im_detect: 927/2245 0.442s 0.001s
im_detect: 928/2245 0.442s 0.001s
im_detect: 929/2245 0.442s 0.001s
im_detect: 930/2245 0.442s 0.001s
im_detect: 931/2245 0.442s 0.001s
im_detect: 932/2245 0.442s 0.001s
im_detect: 933/2245 0.442s 0.001s
im_detect: 934/2245 0.442s 0.001s
im_detect: 935/2245 0.442s 0.001s
im_detect: 936/2245 0.442s 0.001s
im_detect: 937/2245 0.442s 0.001s
im_detect: 938/2245 0.442s 0.001s
im_detect: 939/2245 0.443s 0.001s
im_detect: 940/2245 0.442s 0.001s
im_detect: 941/2245 0.442s 0.001s
im_detect: 942/2245 0.442s 0.001s
im_detect: 943/2245 0.442s 0.001s
im_detect: 944/2245 0.442s 0.001s
im_detect: 945/2245 0.442s 0.001s
im_detect: 946/2245 0.443s 0.001s
im_detect: 947/2245 0.443s 0.001s
im_detect: 948/2245 0.443s 0.001s
im_detect: 949/2245 0.443s 0.001s
im_detect: 950/2245 0.443s 0.001s
im_detect: 951/2245 0.443s 0.001s
im_detect: 952/2245 0.443s 0.001s
im_detect: 953/2245 0.443s 0.001s
im_detect: 954/2245 0.443s 0.001s
im_detect: 955/2245 0.443s 0.001s
im_detect: 956/2245 0.443s 0.001s
im_detect: 957/2245 0.443s 0.001s
im_detect: 958/2245 0.443s 0.001s
im_detect: 959/2245 0.443s 0.001s
im_detect: 960/2245 0.443s 0.001s
im_detect: 961/2245 0.443s 0.001s
im_detect: 962/2245 0.443s 0.001s
im_detect: 963/2245 0.443s 0.001s
im_detect: 964/2245 0.443s 0.001s
im_detect: 965/2245 0.443s 0.001s
im_detect: 966/2245 0.443s 0.001s
im_detect: 967/2245 0.443s 0.001s
im_detect: 968/2245 0.443s 0.001s
im_detect: 969/2245 0.443s 0.001s
im_detect: 970/2245 0.443s 0.001s
im_detect: 971/2245 0.443s 0.001s
im_detect: 972/2245 0.443s 0.001s
im_detect: 973/2245 0.443s 0.001s
im_detect: 974/2245 0.443s 0.001s
im_detect: 975/2245 0.443s 0.001s
im_detect: 976/2245 0.443s 0.001s
im_detect: 977/2245 0.443s 0.001s
im_detect: 978/2245 0.443s 0.001s
im_detect: 979/2245 0.443s 0.001s
im_detect: 980/2245 0.443s 0.001s
im_detect: 981/2245 0.443s 0.001s
im_detect: 982/2245 0.443s 0.001s
im_detect: 983/2245 0.443s 0.001s
im_detect: 984/2245 0.443s 0.001s
im_detect: 985/2245 0.443s 0.001s
im_detect: 986/2245 0.443s 0.001s
im_detect: 987/2245 0.443s 0.001s
im_detect: 988/2245 0.443s 0.001s
im_detect: 989/2245 0.443s 0.001s
im_detect: 990/2245 0.443s 0.001s
im_detect: 991/2245 0.443s 0.001s
im_detect: 992/2245 0.443s 0.001s
im_detect: 993/2245 0.443s 0.001s
im_detect: 994/2245 0.443s 0.001s
im_detect: 995/2245 0.443s 0.001s
im_detect: 996/2245 0.443s 0.001s
im_detect: 997/2245 0.443s 0.001s
im_detect: 998/2245 0.443s 0.001s
im_detect: 999/2245 0.443s 0.001s
im_detect: 1000/2245 0.443s 0.001s
im_detect: 1001/2245 0.443s 0.001s
im_detect: 1002/2245 0.443s 0.001s
im_detect: 1003/2245 0.443s 0.001s
im_detect: 1004/2245 0.443s 0.001s
im_detect: 1005/2245 0.443s 0.001s
im_detect: 1006/2245 0.443s 0.001s
im_detect: 1007/2245 0.443s 0.001s
im_detect: 1008/2245 0.443s 0.001s
im_detect: 1009/2245 0.443s 0.001s
im_detect: 1010/2245 0.443s 0.001s
im_detect: 1011/2245 0.443s 0.001s
im_detect: 1012/2245 0.443s 0.001s
im_detect: 1013/2245 0.443s 0.001s
im_detect: 1014/2245 0.443s 0.001s
im_detect: 1015/2245 0.443s 0.001s
im_detect: 1016/2245 0.443s 0.001s
im_detect: 1017/2245 0.443s 0.001s
im_detect: 1018/2245 0.443s 0.001s
im_detect: 1019/2245 0.443s 0.001s
im_detect: 1020/2245 0.443s 0.001s
im_detect: 1021/2245 0.443s 0.001s
im_detect: 1022/2245 0.443s 0.001s
im_detect: 1023/2245 0.443s 0.001s
im_detect: 1024/2245 0.443s 0.001s
im_detect: 1025/2245 0.443s 0.001s
im_detect: 1026/2245 0.443s 0.001s
im_detect: 1027/2245 0.443s 0.001s
im_detect: 1028/2245 0.443s 0.001s
im_detect: 1029/2245 0.443s 0.001s
im_detect: 1030/2245 0.443s 0.001s
im_detect: 1031/2245 0.443s 0.001s
im_detect: 1032/2245 0.443s 0.001s
im_detect: 1033/2245 0.443s 0.001s
im_detect: 1034/2245 0.443s 0.001s
im_detect: 1035/2245 0.443s 0.001s
im_detect: 1036/2245 0.443s 0.001s
im_detect: 1037/2245 0.443s 0.001s
im_detect: 1038/2245 0.443s 0.001s
im_detect: 1039/2245 0.443s 0.001s
im_detect: 1040/2245 0.443s 0.001s
im_detect: 1041/2245 0.443s 0.001s
im_detect: 1042/2245 0.443s 0.001s
im_detect: 1043/2245 0.443s 0.001s
im_detect: 1044/2245 0.443s 0.001s
im_detect: 1045/2245 0.443s 0.001s
im_detect: 1046/2245 0.443s 0.001s
im_detect: 1047/2245 0.443s 0.001s
im_detect: 1048/2245 0.443s 0.001s
im_detect: 1049/2245 0.443s 0.001s
im_detect: 1050/2245 0.443s 0.001s
im_detect: 1051/2245 0.443s 0.001s
im_detect: 1052/2245 0.443s 0.001s
im_detect: 1053/2245 0.443s 0.001s
im_detect: 1054/2245 0.443s 0.001s
im_detect: 1055/2245 0.443s 0.001s
im_detect: 1056/2245 0.443s 0.001s
im_detect: 1057/2245 0.443s 0.001s
im_detect: 1058/2245 0.443s 0.001s
im_detect: 1059/2245 0.443s 0.001s
im_detect: 1060/2245 0.443s 0.001s
im_detect: 1061/2245 0.443s 0.001s
im_detect: 1062/2245 0.443s 0.001s
im_detect: 1063/2245 0.443s 0.001s
im_detect: 1064/2245 0.443s 0.001s
im_detect: 1065/2245 0.443s 0.001s
im_detect: 1066/2245 0.443s 0.001s
im_detect: 1067/2245 0.443s 0.001s
im_detect: 1068/2245 0.443s 0.001s
im_detect: 1069/2245 0.443s 0.001s
im_detect: 1070/2245 0.443s 0.001s
im_detect: 1071/2245 0.443s 0.001s
im_detect: 1072/2245 0.443s 0.001s
im_detect: 1073/2245 0.443s 0.001s
im_detect: 1074/2245 0.443s 0.001s
im_detect: 1075/2245 0.443s 0.001s
im_detect: 1076/2245 0.443s 0.001s
im_detect: 1077/2245 0.443s 0.001s
im_detect: 1078/2245 0.443s 0.001s
im_detect: 1079/2245 0.443s 0.001s
im_detect: 1080/2245 0.443s 0.001s
im_detect: 1081/2245 0.443s 0.001s
im_detect: 1082/2245 0.443s 0.001s
im_detect: 1083/2245 0.443s 0.001s
im_detect: 1084/2245 0.443s 0.001s
im_detect: 1085/2245 0.443s 0.001s
im_detect: 1086/2245 0.443s 0.001s
im_detect: 1087/2245 0.443s 0.001s
im_detect: 1088/2245 0.443s 0.001s
im_detect: 1089/2245 0.443s 0.001s
im_detect: 1090/2245 0.443s 0.001s
im_detect: 1091/2245 0.443s 0.001s
im_detect: 1092/2245 0.443s 0.001s
im_detect: 1093/2245 0.443s 0.001s
im_detect: 1094/2245 0.443s 0.001s
im_detect: 1095/2245 0.443s 0.001s
im_detect: 1096/2245 0.443s 0.001s
im_detect: 1097/2245 0.443s 0.001s
im_detect: 1098/2245 0.443s 0.001s
im_detect: 1099/2245 0.443s 0.001s
im_detect: 1100/2245 0.443s 0.001s
im_detect: 1101/2245 0.443s 0.001s
im_detect: 1102/2245 0.443s 0.001s
im_detect: 1103/2245 0.443s 0.001s
im_detect: 1104/2245 0.443s 0.001s
im_detect: 1105/2245 0.443s 0.001s
im_detect: 1106/2245 0.443s 0.001s
im_detect: 1107/2245 0.443s 0.001s
im_detect: 1108/2245 0.443s 0.001s
im_detect: 1109/2245 0.443s 0.001s
im_detect: 1110/2245 0.443s 0.001s
im_detect: 1111/2245 0.443s 0.001s
im_detect: 1112/2245 0.443s 0.001s
im_detect: 1113/2245 0.443s 0.001s
im_detect: 1114/2245 0.443s 0.001s
im_detect: 1115/2245 0.443s 0.001s
im_detect: 1116/2245 0.443s 0.001s
im_detect: 1117/2245 0.443s 0.001s
im_detect: 1118/2245 0.443s 0.001s
im_detect: 1119/2245 0.443s 0.001s
im_detect: 1120/2245 0.443s 0.001s
im_detect: 1121/2245 0.443s 0.001s
im_detect: 1122/2245 0.443s 0.001s
im_detect: 1123/2245 0.443s 0.001s
im_detect: 1124/2245 0.443s 0.001s
im_detect: 1125/2245 0.443s 0.001s
im_detect: 1126/2245 0.443s 0.001s
im_detect: 1127/2245 0.443s 0.001s
im_detect: 1128/2245 0.443s 0.001s
im_detect: 1129/2245 0.443s 0.001s
im_detect: 1130/2245 0.443s 0.001s
im_detect: 1131/2245 0.443s 0.001s
im_detect: 1132/2245 0.443s 0.001s
im_detect: 1133/2245 0.443s 0.001s
im_detect: 1134/2245 0.443s 0.001s
im_detect: 1135/2245 0.443s 0.001s
im_detect: 1136/2245 0.443s 0.001s
im_detect: 1137/2245 0.443s 0.001s
im_detect: 1138/2245 0.443s 0.001s
im_detect: 1139/2245 0.443s 0.001s
im_detect: 1140/2245 0.443s 0.001s
im_detect: 1141/2245 0.443s 0.001s
im_detect: 1142/2245 0.443s 0.001s
im_detect: 1143/2245 0.443s 0.001s
im_detect: 1144/2245 0.443s 0.001s
im_detect: 1145/2245 0.443s 0.001s
im_detect: 1146/2245 0.443s 0.001s
im_detect: 1147/2245 0.443s 0.001s
im_detect: 1148/2245 0.443s 0.001s
im_detect: 1149/2245 0.443s 0.001s
im_detect: 1150/2245 0.443s 0.001s
im_detect: 1151/2245 0.443s 0.001s
im_detect: 1152/2245 0.443s 0.001s
im_detect: 1153/2245 0.443s 0.001s
im_detect: 1154/2245 0.443s 0.001s
im_detect: 1155/2245 0.443s 0.001s
im_detect: 1156/2245 0.443s 0.001s
im_detect: 1157/2245 0.443s 0.001s
im_detect: 1158/2245 0.443s 0.001s
im_detect: 1159/2245 0.443s 0.001s
im_detect: 1160/2245 0.443s 0.001s
im_detect: 1161/2245 0.443s 0.001s
im_detect: 1162/2245 0.443s 0.001s
im_detect: 1163/2245 0.443s 0.001s
im_detect: 1164/2245 0.443s 0.001s
im_detect: 1165/2245 0.443s 0.001s
im_detect: 1166/2245 0.443s 0.001s
im_detect: 1167/2245 0.443s 0.001s
im_detect: 1168/2245 0.443s 0.001s
im_detect: 1169/2245 0.443s 0.001s
im_detect: 1170/2245 0.443s 0.001s
im_detect: 1171/2245 0.443s 0.001s
im_detect: 1172/2245 0.443s 0.001s
im_detect: 1173/2245 0.443s 0.001s
im_detect: 1174/2245 0.443s 0.001s
im_detect: 1175/2245 0.443s 0.001s
im_detect: 1176/2245 0.443s 0.001s
im_detect: 1177/2245 0.443s 0.001s
im_detect: 1178/2245 0.443s 0.001s
im_detect: 1179/2245 0.443s 0.001s
im_detect: 1180/2245 0.443s 0.001s
im_detect: 1181/2245 0.443s 0.001s
im_detect: 1182/2245 0.443s 0.001s
im_detect: 1183/2245 0.443s 0.001s
im_detect: 1184/2245 0.443s 0.001s
im_detect: 1185/2245 0.443s 0.001s
im_detect: 1186/2245 0.443s 0.001s
im_detect: 1187/2245 0.443s 0.001s
im_detect: 1188/2245 0.443s 0.001s
im_detect: 1189/2245 0.443s 0.001s
im_detect: 1190/2245 0.443s 0.001s
im_detect: 1191/2245 0.443s 0.001s
im_detect: 1192/2245 0.443s 0.001s
im_detect: 1193/2245 0.443s 0.001s
im_detect: 1194/2245 0.443s 0.001s
im_detect: 1195/2245 0.443s 0.001s
im_detect: 1196/2245 0.443s 0.001s
im_detect: 1197/2245 0.443s 0.001s
im_detect: 1198/2245 0.443s 0.001s
im_detect: 1199/2245 0.443s 0.001s
im_detect: 1200/2245 0.443s 0.001s
im_detect: 1201/2245 0.443s 0.001s
im_detect: 1202/2245 0.443s 0.001s
im_detect: 1203/2245 0.443s 0.001s
im_detect: 1204/2245 0.443s 0.001s
im_detect: 1205/2245 0.443s 0.001s
im_detect: 1206/2245 0.443s 0.001s
im_detect: 1207/2245 0.443s 0.001s
im_detect: 1208/2245 0.443s 0.001s
im_detect: 1209/2245 0.443s 0.001s
im_detect: 1210/2245 0.443s 0.001s
im_detect: 1211/2245 0.443s 0.001s
im_detect: 1212/2245 0.443s 0.001s
im_detect: 1213/2245 0.443s 0.001s
im_detect: 1214/2245 0.443s 0.001s
im_detect: 1215/2245 0.443s 0.001s
im_detect: 1216/2245 0.443s 0.001s
im_detect: 1217/2245 0.443s 0.001s
im_detect: 1218/2245 0.443s 0.001s
im_detect: 1219/2245 0.443s 0.001s
im_detect: 1220/2245 0.443s 0.001s
im_detect: 1221/2245 0.443s 0.001s
im_detect: 1222/2245 0.443s 0.001s
im_detect: 1223/2245 0.443s 0.001s
im_detect: 1224/2245 0.443s 0.001s
im_detect: 1225/2245 0.443s 0.001s
im_detect: 1226/2245 0.443s 0.001s
im_detect: 1227/2245 0.443s 0.001s
im_detect: 1228/2245 0.443s 0.001s
im_detect: 1229/2245 0.443s 0.001s
im_detect: 1230/2245 0.443s 0.001s
im_detect: 1231/2245 0.443s 0.001s
im_detect: 1232/2245 0.443s 0.001s
im_detect: 1233/2245 0.443s 0.001s
im_detect: 1234/2245 0.443s 0.001s
im_detect: 1235/2245 0.443s 0.001s
im_detect: 1236/2245 0.443s 0.001s
im_detect: 1237/2245 0.443s 0.001s
im_detect: 1238/2245 0.443s 0.001s
im_detect: 1239/2245 0.443s 0.001s
im_detect: 1240/2245 0.443s 0.001s
im_detect: 1241/2245 0.443s 0.001s
im_detect: 1242/2245 0.443s 0.001s
im_detect: 1243/2245 0.443s 0.001s
im_detect: 1244/2245 0.443s 0.001s
im_detect: 1245/2245 0.443s 0.001s
im_detect: 1246/2245 0.443s 0.001s
im_detect: 1247/2245 0.443s 0.001s
im_detect: 1248/2245 0.443s 0.001s
im_detect: 1249/2245 0.443s 0.001s
im_detect: 1250/2245 0.443s 0.001s
im_detect: 1251/2245 0.443s 0.001s
im_detect: 1252/2245 0.443s 0.001s
im_detect: 1253/2245 0.443s 0.001s
im_detect: 1254/2245 0.443s 0.001s
im_detect: 1255/2245 0.443s 0.001s
im_detect: 1256/2245 0.443s 0.001s
im_detect: 1257/2245 0.443s 0.001s
im_detect: 1258/2245 0.443s 0.001s
im_detect: 1259/2245 0.443s 0.001s
im_detect: 1260/2245 0.443s 0.001s
im_detect: 1261/2245 0.443s 0.001s
im_detect: 1262/2245 0.443s 0.001s
im_detect: 1263/2245 0.443s 0.001s
im_detect: 1264/2245 0.443s 0.001s
im_detect: 1265/2245 0.443s 0.001s
im_detect: 1266/2245 0.443s 0.001s
im_detect: 1267/2245 0.443s 0.001s
im_detect: 1268/2245 0.443s 0.001s
im_detect: 1269/2245 0.443s 0.001s
im_detect: 1270/2245 0.443s 0.001s
im_detect: 1271/2245 0.443s 0.001s
im_detect: 1272/2245 0.443s 0.001s
im_detect: 1273/2245 0.443s 0.001s
im_detect: 1274/2245 0.443s 0.001s
im_detect: 1275/2245 0.443s 0.001s
im_detect: 1276/2245 0.443s 0.001s
im_detect: 1277/2245 0.443s 0.001s
im_detect: 1278/2245 0.443s 0.001s
im_detect: 1279/2245 0.443s 0.001s
im_detect: 1280/2245 0.443s 0.001s
im_detect: 1281/2245 0.443s 0.001s
im_detect: 1282/2245 0.443s 0.001s
im_detect: 1283/2245 0.443s 0.001s
im_detect: 1284/2245 0.443s 0.001s
im_detect: 1285/2245 0.443s 0.001s
im_detect: 1286/2245 0.443s 0.001s
im_detect: 1287/2245 0.443s 0.001s
im_detect: 1288/2245 0.443s 0.001s
im_detect: 1289/2245 0.443s 0.001s
im_detect: 1290/2245 0.443s 0.001s
im_detect: 1291/2245 0.443s 0.001s
im_detect: 1292/2245 0.443s 0.001s
im_detect: 1293/2245 0.443s 0.001s
im_detect: 1294/2245 0.443s 0.001s
im_detect: 1295/2245 0.443s 0.001s
im_detect: 1296/2245 0.443s 0.001s
im_detect: 1297/2245 0.443s 0.001s
im_detect: 1298/2245 0.443s 0.001s
im_detect: 1299/2245 0.443s 0.001s
im_detect: 1300/2245 0.443s 0.001s
im_detect: 1301/2245 0.443s 0.001s
im_detect: 1302/2245 0.443s 0.001s
im_detect: 1303/2245 0.443s 0.001s
im_detect: 1304/2245 0.443s 0.001s
im_detect: 1305/2245 0.443s 0.001s
im_detect: 1306/2245 0.443s 0.001s
im_detect: 1307/2245 0.443s 0.001s
im_detect: 1308/2245 0.443s 0.001s
im_detect: 1309/2245 0.443s 0.001s
im_detect: 1310/2245 0.443s 0.001s
im_detect: 1311/2245 0.443s 0.001s
im_detect: 1312/2245 0.443s 0.001s
im_detect: 1313/2245 0.443s 0.001s
im_detect: 1314/2245 0.443s 0.001s
im_detect: 1315/2245 0.443s 0.001s
im_detect: 1316/2245 0.443s 0.001s
im_detect: 1317/2245 0.443s 0.001s
im_detect: 1318/2245 0.443s 0.001s
im_detect: 1319/2245 0.443s 0.001s
im_detect: 1320/2245 0.443s 0.001s
im_detect: 1321/2245 0.443s 0.001s
im_detect: 1322/2245 0.443s 0.001s
im_detect: 1323/2245 0.443s 0.001s
im_detect: 1324/2245 0.443s 0.001s
im_detect: 1325/2245 0.443s 0.001s
im_detect: 1326/2245 0.443s 0.001s
im_detect: 1327/2245 0.443s 0.001s
im_detect: 1328/2245 0.443s 0.001s
im_detect: 1329/2245 0.443s 0.001s
im_detect: 1330/2245 0.443s 0.001s
im_detect: 1331/2245 0.443s 0.001s
im_detect: 1332/2245 0.443s 0.001s
im_detect: 1333/2245 0.443s 0.001s
im_detect: 1334/2245 0.443s 0.001s
im_detect: 1335/2245 0.443s 0.001s
im_detect: 1336/2245 0.443s 0.001s
im_detect: 1337/2245 0.443s 0.001s
im_detect: 1338/2245 0.443s 0.001s
im_detect: 1339/2245 0.443s 0.001s
im_detect: 1340/2245 0.443s 0.001s
im_detect: 1341/2245 0.443s 0.001s
im_detect: 1342/2245 0.443s 0.001s
im_detect: 1343/2245 0.443s 0.001s
im_detect: 1344/2245 0.443s 0.001s
im_detect: 1345/2245 0.443s 0.001s
im_detect: 1346/2245 0.443s 0.001s
im_detect: 1347/2245 0.443s 0.001s
im_detect: 1348/2245 0.443s 0.001s
im_detect: 1349/2245 0.443s 0.001s
im_detect: 1350/2245 0.443s 0.001s
im_detect: 1351/2245 0.443s 0.001s
im_detect: 1352/2245 0.443s 0.001s
im_detect: 1353/2245 0.443s 0.001s
im_detect: 1354/2245 0.443s 0.001s
im_detect: 1355/2245 0.443s 0.001s
im_detect: 1356/2245 0.443s 0.001s
im_detect: 1357/2245 0.442s 0.001s
im_detect: 1358/2245 0.442s 0.001s
im_detect: 1359/2245 0.442s 0.001s
im_detect: 1360/2245 0.442s 0.001s
im_detect: 1361/2245 0.442s 0.001s
im_detect: 1362/2245 0.443s 0.001s
im_detect: 1363/2245 0.442s 0.001s
im_detect: 1364/2245 0.442s 0.001s
im_detect: 1365/2245 0.443s 0.001s
im_detect: 1366/2245 0.443s 0.001s
im_detect: 1367/2245 0.443s 0.001s
im_detect: 1368/2245 0.443s 0.001s
im_detect: 1369/2245 0.443s 0.001s
im_detect: 1370/2245 0.443s 0.001s
im_detect: 1371/2245 0.443s 0.001s
im_detect: 1372/2245 0.443s 0.001s
im_detect: 1373/2245 0.443s 0.001s
im_detect: 1374/2245 0.443s 0.001s
im_detect: 1375/2245 0.442s 0.001s
im_detect: 1376/2245 0.443s 0.001s
im_detect: 1377/2245 0.443s 0.001s
im_detect: 1378/2245 0.443s 0.001s
im_detect: 1379/2245 0.443s 0.001s
im_detect: 1380/2245 0.442s 0.001s
im_detect: 1381/2245 0.443s 0.001s
im_detect: 1382/2245 0.443s 0.001s
im_detect: 1383/2245 0.443s 0.001s
im_detect: 1384/2245 0.443s 0.001s
im_detect: 1385/2245 0.443s 0.001s
im_detect: 1386/2245 0.443s 0.001s
im_detect: 1387/2245 0.443s 0.001s
im_detect: 1388/2245 0.443s 0.001s
im_detect: 1389/2245 0.443s 0.001s
im_detect: 1390/2245 0.443s 0.001s
im_detect: 1391/2245 0.443s 0.001s
im_detect: 1392/2245 0.443s 0.001s
im_detect: 1393/2245 0.443s 0.001s
im_detect: 1394/2245 0.443s 0.001s
im_detect: 1395/2245 0.443s 0.001s
im_detect: 1396/2245 0.443s 0.001s
im_detect: 1397/2245 0.443s 0.001s
im_detect: 1398/2245 0.443s 0.001s
im_detect: 1399/2245 0.443s 0.001s
im_detect: 1400/2245 0.443s 0.001s
im_detect: 1401/2245 0.443s 0.001s
im_detect: 1402/2245 0.443s 0.001s
im_detect: 1403/2245 0.443s 0.001s
im_detect: 1404/2245 0.443s 0.001s
im_detect: 1405/2245 0.443s 0.001s
im_detect: 1406/2245 0.443s 0.001s
im_detect: 1407/2245 0.443s 0.001s
im_detect: 1408/2245 0.443s 0.001s
im_detect: 1409/2245 0.443s 0.001s
im_detect: 1410/2245 0.443s 0.001s
im_detect: 1411/2245 0.443s 0.001s
im_detect: 1412/2245 0.443s 0.001s
im_detect: 1413/2245 0.443s 0.001s
im_detect: 1414/2245 0.443s 0.001s
im_detect: 1415/2245 0.443s 0.001s
im_detect: 1416/2245 0.443s 0.001s
im_detect: 1417/2245 0.443s 0.001s
im_detect: 1418/2245 0.443s 0.001s
im_detect: 1419/2245 0.443s 0.001s
im_detect: 1420/2245 0.443s 0.001s
im_detect: 1421/2245 0.443s 0.001s
im_detect: 1422/2245 0.443s 0.001s
im_detect: 1423/2245 0.443s 0.001s
im_detect: 1424/2245 0.443s 0.001s
im_detect: 1425/2245 0.443s 0.001s
im_detect: 1426/2245 0.443s 0.001s
im_detect: 1427/2245 0.443s 0.001s
im_detect: 1428/2245 0.443s 0.001s
im_detect: 1429/2245 0.443s 0.001s
im_detect: 1430/2245 0.443s 0.001s
im_detect: 1431/2245 0.443s 0.001s
im_detect: 1432/2245 0.443s 0.001s
im_detect: 1433/2245 0.443s 0.001s
im_detect: 1434/2245 0.443s 0.001s
im_detect: 1435/2245 0.443s 0.001s
im_detect: 1436/2245 0.443s 0.001s
im_detect: 1437/2245 0.443s 0.001s
im_detect: 1438/2245 0.443s 0.001s
im_detect: 1439/2245 0.443s 0.001s
im_detect: 1440/2245 0.443s 0.001s
im_detect: 1441/2245 0.443s 0.001s
im_detect: 1442/2245 0.443s 0.001s
im_detect: 1443/2245 0.442s 0.001s
im_detect: 1444/2245 0.443s 0.001s
im_detect: 1445/2245 0.442s 0.001s
im_detect: 1446/2245 0.443s 0.001s
im_detect: 1447/2245 0.442s 0.001s
im_detect: 1448/2245 0.442s 0.001s
im_detect: 1449/2245 0.442s 0.001s
im_detect: 1450/2245 0.442s 0.001s
im_detect: 1451/2245 0.443s 0.001s
im_detect: 1452/2245 0.443s 0.001s
im_detect: 1453/2245 0.442s 0.001s
im_detect: 1454/2245 0.442s 0.001s
im_detect: 1455/2245 0.442s 0.001s
im_detect: 1456/2245 0.442s 0.001s
im_detect: 1457/2245 0.442s 0.001s
im_detect: 1458/2245 0.443s 0.001s
im_detect: 1459/2245 0.443s 0.001s
im_detect: 1460/2245 0.443s 0.001s
im_detect: 1461/2245 0.442s 0.001s
im_detect: 1462/2245 0.442s 0.001s
im_detect: 1463/2245 0.442s 0.001s
im_detect: 1464/2245 0.442s 0.001s
im_detect: 1465/2245 0.443s 0.001s
im_detect: 1466/2245 0.442s 0.001s
im_detect: 1467/2245 0.442s 0.001s
im_detect: 1468/2245 0.442s 0.001s
im_detect: 1469/2245 0.442s 0.001s
im_detect: 1470/2245 0.442s 0.001s
im_detect: 1471/2245 0.443s 0.001s
im_detect: 1472/2245 0.442s 0.001s
im_detect: 1473/2245 0.443s 0.001s
im_detect: 1474/2245 0.443s 0.001s
im_detect: 1475/2245 0.442s 0.001s
im_detect: 1476/2245 0.442s 0.001s
im_detect: 1477/2245 0.442s 0.001s
im_detect: 1478/2245 0.442s 0.001s
im_detect: 1479/2245 0.442s 0.001s
im_detect: 1480/2245 0.442s 0.001s
im_detect: 1481/2245 0.442s 0.001s
im_detect: 1482/2245 0.442s 0.001s
im_detect: 1483/2245 0.442s 0.001s
im_detect: 1484/2245 0.442s 0.001s
im_detect: 1485/2245 0.443s 0.001s
im_detect: 1486/2245 0.442s 0.001s
im_detect: 1487/2245 0.442s 0.001s
im_detect: 1488/2245 0.442s 0.001s
im_detect: 1489/2245 0.442s 0.001s
im_detect: 1490/2245 0.442s 0.001s
im_detect: 1491/2245 0.442s 0.001s
im_detect: 1492/2245 0.442s 0.001s
im_detect: 1493/2245 0.442s 0.001s
im_detect: 1494/2245 0.442s 0.001s
im_detect: 1495/2245 0.442s 0.001s
im_detect: 1496/2245 0.442s 0.001s
im_detect: 1497/2245 0.442s 0.001s
im_detect: 1498/2245 0.442s 0.001s
im_detect: 1499/2245 0.442s 0.001s
im_detect: 1500/2245 0.442s 0.001s
im_detect: 1501/2245 0.442s 0.001s
im_detect: 1502/2245 0.442s 0.001s
im_detect: 1503/2245 0.442s 0.001s
im_detect: 1504/2245 0.442s 0.001s
im_detect: 1505/2245 0.442s 0.001s
im_detect: 1506/2245 0.442s 0.001s
im_detect: 1507/2245 0.442s 0.001s
im_detect: 1508/2245 0.442s 0.001s
im_detect: 1509/2245 0.442s 0.001s
im_detect: 1510/2245 0.442s 0.001s
im_detect: 1511/2245 0.442s 0.001s
im_detect: 1512/2245 0.442s 0.001s
im_detect: 1513/2245 0.442s 0.001s
im_detect: 1514/2245 0.442s 0.001s
im_detect: 1515/2245 0.442s 0.001s
im_detect: 1516/2245 0.442s 0.001s
im_detect: 1517/2245 0.442s 0.001s
im_detect: 1518/2245 0.442s 0.001s
im_detect: 1519/2245 0.442s 0.001s
im_detect: 1520/2245 0.442s 0.001s
im_detect: 1521/2245 0.442s 0.001s
im_detect: 1522/2245 0.442s 0.001s
im_detect: 1523/2245 0.442s 0.001s
im_detect: 1524/2245 0.442s 0.001s
im_detect: 1525/2245 0.442s 0.001s
im_detect: 1526/2245 0.442s 0.001s
im_detect: 1527/2245 0.442s 0.001s
im_detect: 1528/2245 0.442s 0.001s
im_detect: 1529/2245 0.442s 0.001s
im_detect: 1530/2245 0.442s 0.001s
im_detect: 1531/2245 0.442s 0.001s
im_detect: 1532/2245 0.442s 0.001s
im_detect: 1533/2245 0.442s 0.001s
im_detect: 1534/2245 0.442s 0.001s
im_detect: 1535/2245 0.442s 0.001s
im_detect: 1536/2245 0.442s 0.001s
im_detect: 1537/2245 0.442s 0.001s
im_detect: 1538/2245 0.442s 0.001s
im_detect: 1539/2245 0.442s 0.001s
im_detect: 1540/2245 0.442s 0.001s
im_detect: 1541/2245 0.442s 0.001s
im_detect: 1542/2245 0.442s 0.001s
im_detect: 1543/2245 0.442s 0.001s
im_detect: 1544/2245 0.442s 0.001s
im_detect: 1545/2245 0.442s 0.001s
im_detect: 1546/2245 0.442s 0.001s
im_detect: 1547/2245 0.442s 0.001s
im_detect: 1548/2245 0.442s 0.001s
im_detect: 1549/2245 0.442s 0.001s
im_detect: 1550/2245 0.442s 0.001s
im_detect: 1551/2245 0.442s 0.001s
im_detect: 1552/2245 0.442s 0.001s
im_detect: 1553/2245 0.442s 0.001s
im_detect: 1554/2245 0.442s 0.001s
im_detect: 1555/2245 0.442s 0.001s
im_detect: 1556/2245 0.442s 0.001s
im_detect: 1557/2245 0.442s 0.001s
im_detect: 1558/2245 0.442s 0.001s
im_detect: 1559/2245 0.442s 0.001s
im_detect: 1560/2245 0.442s 0.001s
im_detect: 1561/2245 0.442s 0.001s
im_detect: 1562/2245 0.442s 0.001s
im_detect: 1563/2245 0.442s 0.001s
im_detect: 1564/2245 0.442s 0.001s
im_detect: 1565/2245 0.442s 0.001s
im_detect: 1566/2245 0.442s 0.001s
im_detect: 1567/2245 0.442s 0.001s
im_detect: 1568/2245 0.442s 0.001s
im_detect: 1569/2245 0.442s 0.001s
im_detect: 1570/2245 0.442s 0.001s
im_detect: 1571/2245 0.442s 0.001s
im_detect: 1572/2245 0.442s 0.001s
im_detect: 1573/2245 0.442s 0.001s
im_detect: 1574/2245 0.442s 0.001s
im_detect: 1575/2245 0.442s 0.001s
im_detect: 1576/2245 0.442s 0.001s
im_detect: 1577/2245 0.442s 0.001s
im_detect: 1578/2245 0.442s 0.001s
im_detect: 1579/2245 0.442s 0.001s
im_detect: 1580/2245 0.442s 0.001s
im_detect: 1581/2245 0.442s 0.001s
im_detect: 1582/2245 0.442s 0.001s
im_detect: 1583/2245 0.442s 0.001s
im_detect: 1584/2245 0.442s 0.001s
im_detect: 1585/2245 0.442s 0.001s
im_detect: 1586/2245 0.442s 0.001s
im_detect: 1587/2245 0.442s 0.001s
im_detect: 1588/2245 0.442s 0.001s
im_detect: 1589/2245 0.442s 0.001s
im_detect: 1590/2245 0.442s 0.001s
im_detect: 1591/2245 0.442s 0.001s
im_detect: 1592/2245 0.442s 0.001s
im_detect: 1593/2245 0.442s 0.001s
im_detect: 1594/2245 0.442s 0.001s
im_detect: 1595/2245 0.442s 0.001s
im_detect: 1596/2245 0.442s 0.001s
im_detect: 1597/2245 0.442s 0.001s
im_detect: 1598/2245 0.442s 0.001s
im_detect: 1599/2245 0.442s 0.001s
im_detect: 1600/2245 0.442s 0.001s
im_detect: 1601/2245 0.442s 0.001s
im_detect: 1602/2245 0.442s 0.001s
im_detect: 1603/2245 0.442s 0.001s
im_detect: 1604/2245 0.442s 0.001s
im_detect: 1605/2245 0.442s 0.001s
im_detect: 1606/2245 0.442s 0.001s
im_detect: 1607/2245 0.442s 0.001s
im_detect: 1608/2245 0.442s 0.001s
im_detect: 1609/2245 0.442s 0.001s
im_detect: 1610/2245 0.442s 0.001s
im_detect: 1611/2245 0.442s 0.001s
im_detect: 1612/2245 0.442s 0.001s
im_detect: 1613/2245 0.442s 0.001s
im_detect: 1614/2245 0.442s 0.001s
im_detect: 1615/2245 0.442s 0.001s
im_detect: 1616/2245 0.442s 0.001s
im_detect: 1617/2245 0.442s 0.001s
im_detect: 1618/2245 0.442s 0.001s
im_detect: 1619/2245 0.442s 0.001s
im_detect: 1620/2245 0.442s 0.001s
im_detect: 1621/2245 0.442s 0.001s
im_detect: 1622/2245 0.442s 0.001s
im_detect: 1623/2245 0.442s 0.001s
im_detect: 1624/2245 0.442s 0.001s
im_detect: 1625/2245 0.442s 0.001s
im_detect: 1626/2245 0.442s 0.001s
im_detect: 1627/2245 0.442s 0.001s
im_detect: 1628/2245 0.442s 0.001s
im_detect: 1629/2245 0.442s 0.001s
im_detect: 1630/2245 0.442s 0.001s
im_detect: 1631/2245 0.442s 0.001s
im_detect: 1632/2245 0.442s 0.001s
im_detect: 1633/2245 0.442s 0.001s
im_detect: 1634/2245 0.442s 0.001s
im_detect: 1635/2245 0.442s 0.001s
im_detect: 1636/2245 0.442s 0.001s
im_detect: 1637/2245 0.442s 0.001s
im_detect: 1638/2245 0.442s 0.001s
im_detect: 1639/2245 0.442s 0.001s
im_detect: 1640/2245 0.442s 0.001s
im_detect: 1641/2245 0.442s 0.001s
im_detect: 1642/2245 0.442s 0.001s
im_detect: 1643/2245 0.442s 0.001s
im_detect: 1644/2245 0.442s 0.001s
im_detect: 1645/2245 0.442s 0.001s
im_detect: 1646/2245 0.442s 0.001s
im_detect: 1647/2245 0.442s 0.001s
im_detect: 1648/2245 0.442s 0.001s
im_detect: 1649/2245 0.442s 0.001s
im_detect: 1650/2245 0.442s 0.001s
im_detect: 1651/2245 0.442s 0.001s
im_detect: 1652/2245 0.442s 0.001s
im_detect: 1653/2245 0.442s 0.001s
im_detect: 1654/2245 0.442s 0.001s
im_detect: 1655/2245 0.442s 0.001s
im_detect: 1656/2245 0.442s 0.001s
im_detect: 1657/2245 0.442s 0.001s
im_detect: 1658/2245 0.442s 0.001s
im_detect: 1659/2245 0.442s 0.001s
im_detect: 1660/2245 0.442s 0.001s
im_detect: 1661/2245 0.442s 0.001s
im_detect: 1662/2245 0.442s 0.001s
im_detect: 1663/2245 0.442s 0.001s
im_detect: 1664/2245 0.442s 0.001s
im_detect: 1665/2245 0.442s 0.001s
im_detect: 1666/2245 0.442s 0.001s
im_detect: 1667/2245 0.442s 0.001s
im_detect: 1668/2245 0.442s 0.001s
im_detect: 1669/2245 0.442s 0.001s
im_detect: 1670/2245 0.442s 0.001s
im_detect: 1671/2245 0.442s 0.001s
im_detect: 1672/2245 0.442s 0.001s
im_detect: 1673/2245 0.442s 0.001s
im_detect: 1674/2245 0.442s 0.001s
im_detect: 1675/2245 0.442s 0.001s
im_detect: 1676/2245 0.442s 0.001s
im_detect: 1677/2245 0.442s 0.001s
im_detect: 1678/2245 0.442s 0.001s
im_detect: 1679/2245 0.442s 0.001s
im_detect: 1680/2245 0.442s 0.001s
im_detect: 1681/2245 0.442s 0.001s
im_detect: 1682/2245 0.442s 0.001s
im_detect: 1683/2245 0.442s 0.001s
im_detect: 1684/2245 0.442s 0.001s
im_detect: 1685/2245 0.442s 0.001s
im_detect: 1686/2245 0.442s 0.001s
im_detect: 1687/2245 0.442s 0.001s
im_detect: 1688/2245 0.442s 0.001s
im_detect: 1689/2245 0.442s 0.001s
im_detect: 1690/2245 0.442s 0.001s
im_detect: 1691/2245 0.442s 0.001s
im_detect: 1692/2245 0.442s 0.001s
im_detect: 1693/2245 0.442s 0.001s
im_detect: 1694/2245 0.442s 0.001s
im_detect: 1695/2245 0.442s 0.001s
im_detect: 1696/2245 0.442s 0.001s
im_detect: 1697/2245 0.442s 0.001s
im_detect: 1698/2245 0.442s 0.001s
im_detect: 1699/2245 0.442s 0.001s
im_detect: 1700/2245 0.442s 0.001s
im_detect: 1701/2245 0.442s 0.001s
im_detect: 1702/2245 0.442s 0.001s
im_detect: 1703/2245 0.442s 0.001s
im_detect: 1704/2245 0.442s 0.001s
im_detect: 1705/2245 0.442s 0.001s
im_detect: 1706/2245 0.442s 0.001s
im_detect: 1707/2245 0.442s 0.001s
im_detect: 1708/2245 0.442s 0.001s
im_detect: 1709/2245 0.442s 0.001s
im_detect: 1710/2245 0.442s 0.001s
im_detect: 1711/2245 0.442s 0.001s
im_detect: 1712/2245 0.442s 0.001s
im_detect: 1713/2245 0.442s 0.001s
im_detect: 1714/2245 0.442s 0.001s
im_detect: 1715/2245 0.442s 0.001s
im_detect: 1716/2245 0.442s 0.001s
im_detect: 1717/2245 0.442s 0.001s
im_detect: 1718/2245 0.442s 0.001s
im_detect: 1719/2245 0.442s 0.001s
im_detect: 1720/2245 0.442s 0.001s
im_detect: 1721/2245 0.442s 0.001s
im_detect: 1722/2245 0.442s 0.001s
im_detect: 1723/2245 0.442s 0.001s
im_detect: 1724/2245 0.442s 0.001s
im_detect: 1725/2245 0.442s 0.001s
im_detect: 1726/2245 0.442s 0.001s
im_detect: 1727/2245 0.442s 0.001s
im_detect: 1728/2245 0.442s 0.001s
im_detect: 1729/2245 0.442s 0.001s
im_detect: 1730/2245 0.442s 0.001s
im_detect: 1731/2245 0.442s 0.001s
im_detect: 1732/2245 0.442s 0.001s
im_detect: 1733/2245 0.442s 0.001s
im_detect: 1734/2245 0.442s 0.001s
im_detect: 1735/2245 0.442s 0.001s
im_detect: 1736/2245 0.442s 0.001s
im_detect: 1737/2245 0.442s 0.001s
im_detect: 1738/2245 0.442s 0.001s
im_detect: 1739/2245 0.442s 0.001s
im_detect: 1740/2245 0.442s 0.001s
im_detect: 1741/2245 0.442s 0.001s
im_detect: 1742/2245 0.442s 0.001s
im_detect: 1743/2245 0.442s 0.001s
im_detect: 1744/2245 0.442s 0.001s
im_detect: 1745/2245 0.442s 0.001s
im_detect: 1746/2245 0.442s 0.001s
im_detect: 1747/2245 0.442s 0.001s
im_detect: 1748/2245 0.442s 0.001s
im_detect: 1749/2245 0.442s 0.001s
im_detect: 1750/2245 0.442s 0.001s
im_detect: 1751/2245 0.442s 0.001s
im_detect: 1752/2245 0.442s 0.001s
im_detect: 1753/2245 0.442s 0.001s
im_detect: 1754/2245 0.442s 0.001s
im_detect: 1755/2245 0.442s 0.001s
im_detect: 1756/2245 0.442s 0.001s
im_detect: 1757/2245 0.442s 0.001s
im_detect: 1758/2245 0.442s 0.001s
im_detect: 1759/2245 0.442s 0.001s
im_detect: 1760/2245 0.442s 0.001s
im_detect: 1761/2245 0.442s 0.001s
im_detect: 1762/2245 0.442s 0.001s
im_detect: 1763/2245 0.442s 0.001s
im_detect: 1764/2245 0.442s 0.001s
im_detect: 1765/2245 0.442s 0.001s
im_detect: 1766/2245 0.442s 0.001s
im_detect: 1767/2245 0.442s 0.001s
im_detect: 1768/2245 0.442s 0.001s
im_detect: 1769/2245 0.442s 0.001s
im_detect: 1770/2245 0.442s 0.001s
im_detect: 1771/2245 0.442s 0.001s
im_detect: 1772/2245 0.442s 0.001s
im_detect: 1773/2245 0.442s 0.001s
im_detect: 1774/2245 0.442s 0.001s
im_detect: 1775/2245 0.442s 0.001s
im_detect: 1776/2245 0.442s 0.001s
im_detect: 1777/2245 0.442s 0.001s
im_detect: 1778/2245 0.442s 0.001s
im_detect: 1779/2245 0.442s 0.001s
im_detect: 1780/2245 0.442s 0.001s
im_detect: 1781/2245 0.442s 0.001s
im_detect: 1782/2245 0.442s 0.001s
im_detect: 1783/2245 0.442s 0.001s
im_detect: 1784/2245 0.442s 0.001s
im_detect: 1785/2245 0.442s 0.001s
im_detect: 1786/2245 0.442s 0.001s
im_detect: 1787/2245 0.442s 0.001s
im_detect: 1788/2245 0.442s 0.001s
im_detect: 1789/2245 0.442s 0.001s
im_detect: 1790/2245 0.442s 0.001s
im_detect: 1791/2245 0.442s 0.001s
im_detect: 1792/2245 0.442s 0.001s
im_detect: 1793/2245 0.442s 0.001s
im_detect: 1794/2245 0.442s 0.001s
im_detect: 1795/2245 0.442s 0.001s
im_detect: 1796/2245 0.442s 0.001s
im_detect: 1797/2245 0.442s 0.001s
im_detect: 1798/2245 0.442s 0.001s
im_detect: 1799/2245 0.442s 0.001s
im_detect: 1800/2245 0.442s 0.001s
im_detect: 1801/2245 0.442s 0.001s
im_detect: 1802/2245 0.442s 0.001s
im_detect: 1803/2245 0.442s 0.001s
im_detect: 1804/2245 0.442s 0.001s
im_detect: 1805/2245 0.442s 0.001s
im_detect: 1806/2245 0.442s 0.001s
im_detect: 1807/2245 0.442s 0.001s
im_detect: 1808/2245 0.442s 0.001s
im_detect: 1809/2245 0.442s 0.001s
im_detect: 1810/2245 0.442s 0.001s
im_detect: 1811/2245 0.442s 0.001s
im_detect: 1812/2245 0.442s 0.001s
im_detect: 1813/2245 0.442s 0.001s
im_detect: 1814/2245 0.442s 0.001s
im_detect: 1815/2245 0.442s 0.001s
im_detect: 1816/2245 0.442s 0.001s
im_detect: 1817/2245 0.442s 0.001s
im_detect: 1818/2245 0.442s 0.001s
im_detect: 1819/2245 0.442s 0.001s
im_detect: 1820/2245 0.442s 0.001s
im_detect: 1821/2245 0.442s 0.001s
im_detect: 1822/2245 0.442s 0.001s
im_detect: 1823/2245 0.442s 0.001s
im_detect: 1824/2245 0.442s 0.001s
im_detect: 1825/2245 0.442s 0.001s
im_detect: 1826/2245 0.442s 0.001s
im_detect: 1827/2245 0.442s 0.001s
im_detect: 1828/2245 0.442s 0.001s
im_detect: 1829/2245 0.442s 0.001s
im_detect: 1830/2245 0.442s 0.001s
im_detect: 1831/2245 0.442s 0.001s
im_detect: 1832/2245 0.442s 0.001s
im_detect: 1833/2245 0.442s 0.001s
im_detect: 1834/2245 0.442s 0.001s
im_detect: 1835/2245 0.442s 0.001s
im_detect: 1836/2245 0.442s 0.001s
im_detect: 1837/2245 0.442s 0.001s
im_detect: 1838/2245 0.442s 0.001s
im_detect: 1839/2245 0.442s 0.001s
im_detect: 1840/2245 0.442s 0.001s
im_detect: 1841/2245 0.442s 0.001s
im_detect: 1842/2245 0.442s 0.001s
im_detect: 1843/2245 0.442s 0.001s
im_detect: 1844/2245 0.442s 0.001s
im_detect: 1845/2245 0.442s 0.001s
im_detect: 1846/2245 0.442s 0.001s
im_detect: 1847/2245 0.442s 0.001s
im_detect: 1848/2245 0.442s 0.001s
im_detect: 1849/2245 0.442s 0.001s
im_detect: 1850/2245 0.442s 0.001s
im_detect: 1851/2245 0.442s 0.001s
im_detect: 1852/2245 0.442s 0.001s
im_detect: 1853/2245 0.442s 0.001s
im_detect: 1854/2245 0.442s 0.001s
im_detect: 1855/2245 0.442s 0.001s
im_detect: 1856/2245 0.442s 0.001s
im_detect: 1857/2245 0.442s 0.001s
im_detect: 1858/2245 0.442s 0.001s
im_detect: 1859/2245 0.442s 0.001s
im_detect: 1860/2245 0.442s 0.001s
im_detect: 1861/2245 0.442s 0.001s
im_detect: 1862/2245 0.442s 0.001s
im_detect: 1863/2245 0.442s 0.001s
im_detect: 1864/2245 0.442s 0.001s
im_detect: 1865/2245 0.442s 0.001s
im_detect: 1866/2245 0.442s 0.001s
im_detect: 1867/2245 0.442s 0.001s
im_detect: 1868/2245 0.442s 0.001s
im_detect: 1869/2245 0.442s 0.001s
im_detect: 1870/2245 0.442s 0.001s
im_detect: 1871/2245 0.442s 0.001s
im_detect: 1872/2245 0.442s 0.001s
im_detect: 1873/2245 0.442s 0.001s
im_detect: 1874/2245 0.442s 0.001s
im_detect: 1875/2245 0.442s 0.001s
im_detect: 1876/2245 0.442s 0.001s
im_detect: 1877/2245 0.442s 0.001s
im_detect: 1878/2245 0.442s 0.001s
im_detect: 1879/2245 0.442s 0.001s
im_detect: 1880/2245 0.442s 0.001s
im_detect: 1881/2245 0.442s 0.001s
im_detect: 1882/2245 0.442s 0.001s
im_detect: 1883/2245 0.442s 0.001s
im_detect: 1884/2245 0.442s 0.001s
im_detect: 1885/2245 0.442s 0.001s
im_detect: 1886/2245 0.442s 0.001s
im_detect: 1887/2245 0.442s 0.001s
im_detect: 1888/2245 0.442s 0.001s
im_detect: 1889/2245 0.442s 0.001s
im_detect: 1890/2245 0.442s 0.001s
im_detect: 1891/2245 0.442s 0.001s
im_detect: 1892/2245 0.442s 0.001s
im_detect: 1893/2245 0.442s 0.001s
im_detect: 1894/2245 0.442s 0.001s
im_detect: 1895/2245 0.442s 0.001s
im_detect: 1896/2245 0.442s 0.001s
im_detect: 1897/2245 0.442s 0.001s
im_detect: 1898/2245 0.442s 0.001s
im_detect: 1899/2245 0.442s 0.001s
im_detect: 1900/2245 0.442s 0.001s
im_detect: 1901/2245 0.442s 0.001s
im_detect: 1902/2245 0.442s 0.001s
im_detect: 1903/2245 0.442s 0.001s
im_detect: 1904/2245 0.442s 0.001s
im_detect: 1905/2245 0.442s 0.001s
im_detect: 1906/2245 0.442s 0.001s
im_detect: 1907/2245 0.442s 0.001s
im_detect: 1908/2245 0.442s 0.001s
im_detect: 1909/2245 0.442s 0.001s
im_detect: 1910/2245 0.442s 0.001s
im_detect: 1911/2245 0.442s 0.001s
im_detect: 1912/2245 0.442s 0.001s
im_detect: 1913/2245 0.442s 0.001s
im_detect: 1914/2245 0.442s 0.001s
im_detect: 1915/2245 0.442s 0.001s
im_detect: 1916/2245 0.442s 0.001s
im_detect: 1917/2245 0.442s 0.001s
im_detect: 1918/2245 0.442s 0.001s
im_detect: 1919/2245 0.442s 0.001s
im_detect: 1920/2245 0.442s 0.001s
im_detect: 1921/2245 0.442s 0.001s
im_detect: 1922/2245 0.442s 0.001s
im_detect: 1923/2245 0.442s 0.001s
im_detect: 1924/2245 0.442s 0.001s
im_detect: 1925/2245 0.442s 0.001s
im_detect: 1926/2245 0.442s 0.001s
im_detect: 1927/2245 0.442s 0.001s
im_detect: 1928/2245 0.442s 0.001s
im_detect: 1929/2245 0.442s 0.001s
im_detect: 1930/2245 0.442s 0.001s
im_detect: 1931/2245 0.442s 0.001s
im_detect: 1932/2245 0.442s 0.001s
im_detect: 1933/2245 0.442s 0.001s
im_detect: 1934/2245 0.442s 0.001s
im_detect: 1935/2245 0.442s 0.001s
im_detect: 1936/2245 0.442s 0.001s
im_detect: 1937/2245 0.442s 0.001s
im_detect: 1938/2245 0.442s 0.001s
im_detect: 1939/2245 0.442s 0.001s
im_detect: 1940/2245 0.442s 0.001s
im_detect: 1941/2245 0.442s 0.001s
im_detect: 1942/2245 0.442s 0.001s
im_detect: 1943/2245 0.442s 0.001s
im_detect: 1944/2245 0.442s 0.001s
im_detect: 1945/2245 0.442s 0.001s
im_detect: 1946/2245 0.442s 0.001s
im_detect: 1947/2245 0.442s 0.001s
im_detect: 1948/2245 0.442s 0.001s
im_detect: 1949/2245 0.442s 0.001s
im_detect: 1950/2245 0.442s 0.001s
im_detect: 1951/2245 0.442s 0.001s
im_detect: 1952/2245 0.442s 0.001s
im_detect: 1953/2245 0.442s 0.001s
im_detect: 1954/2245 0.442s 0.001s
im_detect: 1955/2245 0.442s 0.001s
im_detect: 1956/2245 0.442s 0.001s
im_detect: 1957/2245 0.442s 0.001s
im_detect: 1958/2245 0.442s 0.001s
im_detect: 1959/2245 0.442s 0.001s
im_detect: 1960/2245 0.442s 0.001s
im_detect: 1961/2245 0.442s 0.001s
im_detect: 1962/2245 0.442s 0.001s
im_detect: 1963/2245 0.442s 0.001s
im_detect: 1964/2245 0.442s 0.001s
im_detect: 1965/2245 0.442s 0.001s
im_detect: 1966/2245 0.442s 0.001s
im_detect: 1967/2245 0.442s 0.001s
im_detect: 1968/2245 0.442s 0.001s
im_detect: 1969/2245 0.442s 0.001s
im_detect: 1970/2245 0.442s 0.001s
im_detect: 1971/2245 0.442s 0.001s
im_detect: 1972/2245 0.442s 0.001s
im_detect: 1973/2245 0.442s 0.001s
im_detect: 1974/2245 0.442s 0.001s
im_detect: 1975/2245 0.442s 0.001s
im_detect: 1976/2245 0.442s 0.001s
im_detect: 1977/2245 0.442s 0.001s
im_detect: 1978/2245 0.442s 0.001s
im_detect: 1979/2245 0.442s 0.001s
im_detect: 1980/2245 0.442s 0.001s
im_detect: 1981/2245 0.442s 0.001s
im_detect: 1982/2245 0.442s 0.001s
im_detect: 1983/2245 0.442s 0.001s
im_detect: 1984/2245 0.442s 0.001s
im_detect: 1985/2245 0.442s 0.001s
im_detect: 1986/2245 0.442s 0.001s
im_detect: 1987/2245 0.442s 0.001s
im_detect: 1988/2245 0.442s 0.001s
im_detect: 1989/2245 0.442s 0.001s
im_detect: 1990/2245 0.442s 0.001s
im_detect: 1991/2245 0.442s 0.001s
im_detect: 1992/2245 0.442s 0.001s
im_detect: 1993/2245 0.442s 0.001s
im_detect: 1994/2245 0.442s 0.001s
im_detect: 1995/2245 0.442s 0.001s
im_detect: 1996/2245 0.442s 0.001s
im_detect: 1997/2245 0.442s 0.001s
im_detect: 1998/2245 0.442s 0.001s
im_detect: 1999/2245 0.442s 0.001s
im_detect: 2000/2245 0.442s 0.001s
im_detect: 2001/2245 0.442s 0.001s
im_detect: 2002/2245 0.442s 0.001s
im_detect: 2003/2245 0.442s 0.001s
im_detect: 2004/2245 0.442s 0.001s
im_detect: 2005/2245 0.442s 0.001s
im_detect: 2006/2245 0.442s 0.001s
im_detect: 2007/2245 0.442s 0.001s
im_detect: 2008/2245 0.442s 0.001s
im_detect: 2009/2245 0.442s 0.001s
im_detect: 2010/2245 0.442s 0.001s
im_detect: 2011/2245 0.442s 0.001s
im_detect: 2012/2245 0.442s 0.001s
im_detect: 2013/2245 0.442s 0.001s
im_detect: 2014/2245 0.442s 0.001s
im_detect: 2015/2245 0.442s 0.001s
im_detect: 2016/2245 0.442s 0.001s
im_detect: 2017/2245 0.442s 0.001s
im_detect: 2018/2245 0.442s 0.001s
im_detect: 2019/2245 0.442s 0.001s
im_detect: 2020/2245 0.442s 0.001s
im_detect: 2021/2245 0.442s 0.001s
im_detect: 2022/2245 0.442s 0.001s
im_detect: 2023/2245 0.442s 0.001s
im_detect: 2024/2245 0.442s 0.001s
im_detect: 2025/2245 0.442s 0.001s
im_detect: 2026/2245 0.442s 0.001s
im_detect: 2027/2245 0.442s 0.001s
im_detect: 2028/2245 0.442s 0.001s
im_detect: 2029/2245 0.442s 0.001s
im_detect: 2030/2245 0.442s 0.001s
im_detect: 2031/2245 0.442s 0.001s
im_detect: 2032/2245 0.442s 0.001s
im_detect: 2033/2245 0.442s 0.001s
im_detect: 2034/2245 0.442s 0.001s
im_detect: 2035/2245 0.442s 0.001s
im_detect: 2036/2245 0.442s 0.001s
im_detect: 2037/2245 0.442s 0.001s
im_detect: 2038/2245 0.442s 0.001s
im_detect: 2039/2245 0.442s 0.001s
im_detect: 2040/2245 0.442s 0.001s
im_detect: 2041/2245 0.442s 0.001s
im_detect: 2042/2245 0.442s 0.001s
im_detect: 2043/2245 0.442s 0.001s
im_detect: 2044/2245 0.442s 0.001s
im_detect: 2045/2245 0.442s 0.001s
im_detect: 2046/2245 0.442s 0.001s
im_detect: 2047/2245 0.442s 0.001s
im_detect: 2048/2245 0.442s 0.001s
im_detect: 2049/2245 0.442s 0.001s
im_detect: 2050/2245 0.442s 0.001s
im_detect: 2051/2245 0.442s 0.001s
im_detect: 2052/2245 0.442s 0.001s
im_detect: 2053/2245 0.442s 0.001s
im_detect: 2054/2245 0.442s 0.001s
im_detect: 2055/2245 0.442s 0.001s
im_detect: 2056/2245 0.442s 0.001s
im_detect: 2057/2245 0.442s 0.001s
im_detect: 2058/2245 0.442s 0.001s
im_detect: 2059/2245 0.442s 0.001s
im_detect: 2060/2245 0.442s 0.001s
im_detect: 2061/2245 0.442s 0.001s
im_detect: 2062/2245 0.442s 0.001s
im_detect: 2063/2245 0.442s 0.001s
im_detect: 2064/2245 0.442s 0.001s
im_detect: 2065/2245 0.442s 0.001s
im_detect: 2066/2245 0.442s 0.001s
im_detect: 2067/2245 0.442s 0.001s
im_detect: 2068/2245 0.442s 0.001s
im_detect: 2069/2245 0.442s 0.001s
im_detect: 2070/2245 0.442s 0.001s
im_detect: 2071/2245 0.442s 0.001s
im_detect: 2072/2245 0.442s 0.001s
im_detect: 2073/2245 0.442s 0.001s
im_detect: 2074/2245 0.442s 0.001s
im_detect: 2075/2245 0.442s 0.001s
im_detect: 2076/2245 0.442s 0.001s
im_detect: 2077/2245 0.442s 0.001s
im_detect: 2078/2245 0.442s 0.001s
im_detect: 2079/2245 0.442s 0.001s
im_detect: 2080/2245 0.442s 0.001s
im_detect: 2081/2245 0.442s 0.001s
im_detect: 2082/2245 0.442s 0.001s
im_detect: 2083/2245 0.442s 0.001s
im_detect: 2084/2245 0.442s 0.001s
im_detect: 2085/2245 0.442s 0.001s
im_detect: 2086/2245 0.442s 0.001s
im_detect: 2087/2245 0.442s 0.001s
im_detect: 2088/2245 0.442s 0.001s
im_detect: 2089/2245 0.442s 0.001s
im_detect: 2090/2245 0.442s 0.001s
im_detect: 2091/2245 0.442s 0.001s
im_detect: 2092/2245 0.442s 0.001s
im_detect: 2093/2245 0.442s 0.001s
im_detect: 2094/2245 0.442s 0.001s
im_detect: 2095/2245 0.442s 0.001s
im_detect: 2096/2245 0.442s 0.001s
im_detect: 2097/2245 0.442s 0.001s
im_detect: 2098/2245 0.442s 0.001s
im_detect: 2099/2245 0.442s 0.001s
im_detect: 2100/2245 0.442s 0.001s
im_detect: 2101/2245 0.442s 0.001s
im_detect: 2102/2245 0.442s 0.001s
im_detect: 2103/2245 0.442s 0.001s
im_detect: 2104/2245 0.442s 0.001s
im_detect: 2105/2245 0.442s 0.001s
im_detect: 2106/2245 0.442s 0.001s
im_detect: 2107/2245 0.442s 0.001s
im_detect: 2108/2245 0.442s 0.001s
im_detect: 2109/2245 0.442s 0.001s
im_detect: 2110/2245 0.442s 0.001s
im_detect: 2111/2245 0.442s 0.001s
im_detect: 2112/2245 0.442s 0.001s
im_detect: 2113/2245 0.442s 0.001s
im_detect: 2114/2245 0.442s 0.001s
im_detect: 2115/2245 0.442s 0.001s
im_detect: 2116/2245 0.442s 0.001s
im_detect: 2117/2245 0.442s 0.001s
im_detect: 2118/2245 0.442s 0.001s
im_detect: 2119/2245 0.442s 0.001s
im_detect: 2120/2245 0.442s 0.001s
im_detect: 2121/2245 0.442s 0.001s
im_detect: 2122/2245 0.442s 0.001s
im_detect: 2123/2245 0.442s 0.001s
im_detect: 2124/2245 0.442s 0.001s
im_detect: 2125/2245 0.442s 0.001s
im_detect: 2126/2245 0.442s 0.001s
im_detect: 2127/2245 0.442s 0.001s
im_detect: 2128/2245 0.442s 0.001s
im_detect: 2129/2245 0.442s 0.001s
im_detect: 2130/2245 0.442s 0.001s
im_detect: 2131/2245 0.442s 0.001s
im_detect: 2132/2245 0.442s 0.001s
im_detect: 2133/2245 0.442s 0.001s
im_detect: 2134/2245 0.442s 0.001s
im_detect: 2135/2245 0.442s 0.001s
im_detect: 2136/2245 0.442s 0.001s
im_detect: 2137/2245 0.442s 0.001s
im_detect: 2138/2245 0.442s 0.001s
im_detect: 2139/2245 0.442s 0.001s
im_detect: 2140/2245 0.442s 0.001s
im_detect: 2141/2245 0.442s 0.001s
im_detect: 2142/2245 0.442s 0.001s
im_detect: 2143/2245 0.442s 0.001s
im_detect: 2144/2245 0.442s 0.001s
im_detect: 2145/2245 0.442s 0.001s
im_detect: 2146/2245 0.442s 0.001s
im_detect: 2147/2245 0.442s 0.001s
im_detect: 2148/2245 0.442s 0.001s
im_detect: 2149/2245 0.442s 0.001s
im_detect: 2150/2245 0.442s 0.001s
im_detect: 2151/2245 0.442s 0.001s
im_detect: 2152/2245 0.442s 0.001s
im_detect: 2153/2245 0.442s 0.001s
im_detect: 2154/2245 0.442s 0.001s
im_detect: 2155/2245 0.442s 0.001s
im_detect: 2156/2245 0.442s 0.001s
im_detect: 2157/2245 0.442s 0.001s
im_detect: 2158/2245 0.442s 0.001s
im_detect: 2159/2245 0.442s 0.001s
im_detect: 2160/2245 0.442s 0.001s
im_detect: 2161/2245 0.442s 0.001s
im_detect: 2162/2245 0.442s 0.001s
im_detect: 2163/2245 0.442s 0.001s
im_detect: 2164/2245 0.442s 0.001s
im_detect: 2165/2245 0.442s 0.001s
im_detect: 2166/2245 0.442s 0.001s
im_detect: 2167/2245 0.442s 0.001s
im_detect: 2168/2245 0.442s 0.001s
im_detect: 2169/2245 0.442s 0.001s
im_detect: 2170/2245 0.442s 0.001s
im_detect: 2171/2245 0.442s 0.001s
im_detect: 2172/2245 0.442s 0.001s
im_detect: 2173/2245 0.442s 0.001s
im_detect: 2174/2245 0.442s 0.001s
im_detect: 2175/2245 0.442s 0.001s
im_detect: 2176/2245 0.442s 0.001s
im_detect: 2177/2245 0.442s 0.001s
im_detect: 2178/2245 0.442s 0.001s
im_detect: 2179/2245 0.442s 0.001s
im_detect: 2180/2245 0.442s 0.001s
im_detect: 2181/2245 0.442s 0.001s
im_detect: 2182/2245 0.442s 0.001s
im_detect: 2183/2245 0.442s 0.001s
im_detect: 2184/2245 0.442s 0.001s
im_detect: 2185/2245 0.442s 0.001s
im_detect: 2186/2245 0.442s 0.001s
im_detect: 2187/2245 0.442s 0.001s
im_detect: 2188/2245 0.442s 0.001s
im_detect: 2189/2245 0.442s 0.001s
im_detect: 2190/2245 0.442s 0.001s
im_detect: 2191/2245 0.442s 0.001s
im_detect: 2192/2245 0.442s 0.001s
im_detect: 2193/2245 0.442s 0.001s
im_detect: 2194/2245 0.442s 0.001s
im_detect: 2195/2245 0.442s 0.001s
im_detect: 2196/2245 0.442s 0.001s
im_detect: 2197/2245 0.442s 0.001s
im_detect: 2198/2245 0.442s 0.001s
im_detect: 2199/2245 0.442s 0.001s
im_detect: 2200/2245 0.442s 0.001s
im_detect: 2201/2245 0.442s 0.001s
im_detect: 2202/2245 0.442s 0.001s
im_detect: 2203/2245 0.442s 0.001s
im_detect: 2204/2245 0.442s 0.001s
im_detect: 2205/2245 0.442s 0.001s
im_detect: 2206/2245 0.442s 0.001s
im_detect: 2207/2245 0.442s 0.001s
im_detect: 2208/2245 0.442s 0.001s
im_detect: 2209/2245 0.442s 0.001s
im_detect: 2210/2245 0.442s 0.001s
im_detect: 2211/2245 0.442s 0.001s
im_detect: 2212/2245 0.442s 0.001s
im_detect: 2213/2245 0.442s 0.001s
im_detect: 2214/2245 0.442s 0.001s
im_detect: 2215/2245 0.442s 0.001s
im_detect: 2216/2245 0.442s 0.001s
im_detect: 2217/2245 0.442s 0.001s
im_detect: 2218/2245 0.441s 0.001s
im_detect: 2219/2245 0.441s 0.001s
im_detect: 2220/2245 0.441s 0.001s
im_detect: 2221/2245 0.441s 0.001s
im_detect: 2222/2245 0.441s 0.001s
im_detect: 2223/2245 0.441s 0.001s
im_detect: 2224/2245 0.441s 0.001s
im_detect: 2225/2245 0.441s 0.001s
im_detect: 2226/2245 0.441s 0.001s
im_detect: 2227/2245 0.442s 0.001s
im_detect: 2228/2245 0.442s 0.001s
im_detect: 2229/2245 0.442s 0.001s
im_detect: 2230/2245 0.442s 0.001s
im_detect: 2231/2245 0.442s 0.001s
im_detect: 2232/2245 0.442s 0.001s
im_detect: 2233/2245 0.442s 0.001s
im_detect: 2234/2245 0.442s 0.001s
im_detect: 2235/2245 0.442s 0.001s
im_detect: 2236/2245 0.442s 0.001s
im_detect: 2237/2245 0.442s 0.001s
im_detect: 2238/2245 0.442s 0.001s
im_detect: 2239/2245 0.442s 0.001s
im_detect: 2240/2245 0.442s 0.001s
im_detect: 2241/2245 0.442s 0.001s
im_detect: 2242/2245 0.442s 0.001s
im_detect: 2243/2245 0.442s 0.001s
im_detect: 2244/2245 0.442s 0.001s
im_detect: 2245/2245 0.442s 0.001s
Applying NMS to all detections
Evaluating detections
Writing car VOC results file
Writing person VOC results file
Writing bike VOC results file
Writing truck VOC results file
Writing van VOC results file
Writing tram VOC results file
Writing misc VOC results file
Running:
cd /home/bsl/KITTI-detection/tools/../lib/datasets/VOCdevkit-matlab-wrapper && matlab -nodisplay -nodesktop -r "dbstop if error; detection_eval('/home/bsl/KITTI-detection/data','comp4-6776','KakouTest','/home/bsl/KITTI-detection/output/faster_rcnn_alt_opt/KakouTest/VGG16_faster_rcnn_final','KITTI_val_list.txt','KITTI_gt_val.txt'); quit;"
[?1h=
                            < M A T L A B (R) >
                  Copyright 1984-2014 The MathWorks, Inc.
                    R2014a (8.3.0.532) 64-bit (glnxa64)
                             February 11, 2014

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

classes = 

    'car'    'person'    'bike'    'truck'    'van'    'tram'    'misc'


~~~~~~~~~~~~~~~~~~~~
Results:
APs:
78.4
64.7
75.1
86.5
89.6
83.5
74.0
mAP:78.8
~~~~~~~~~~~~~~~~~~~~
[?1l>
real	22m1.676s
user	18m49.182s
sys	2m39.845s
